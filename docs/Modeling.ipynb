{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b3e5676",
   "metadata": {},
   "source": [
    "## Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d37e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8fe862b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9844a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/AFischer/PycharmProjects/cocoon-project')\n",
    "sys.path.append('/Users/AFischer/PycharmProjects/cocoon-project/src_pre_term_database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf44e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import constants as c\n",
    "from src_pre_term_database.load_dataset import build_signal_dataframe, build_clinical_information_dataframe\n",
    "from utils import read_settings, replace_inf_with_zero, replace_na_with_zero\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.signal import butter, filtfilt\n",
    "from src_pre_term_database.visualizing import plot_histogram, plot_distribution_feature\n",
    "from src_pre_term_database.data_processing_and_feature_engineering import create_filtered_channels, remove_first_n_samples_of_signals, remove_last_n_samples_of_signals, train_val_test_split, feature_label_split, pad_sequences_to_fixed_length, pad_sequences_to_fixed_length_df, custom_sort_for_stateful_lstm, NonOverlappingSequencesDataset, calculate_samp_en_over_fixed_time_window\n",
    "from pandas._testing import assert_frame_equal\n",
    "from IPython.display import Latex\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c996523c",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62001d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_path = '/Users/AFischer/PycharmProjects/cocoon-project/references/settings'\n",
    "\n",
    "file_paths = read_settings(settings_path, 'file_paths')\n",
    "\n",
    "SIGNAL_COLUMN_NAMES = ['1', '1_DOCFILT-4-0.08-4', '1_DOCFILT-4-0.3-3', '1_DOCFILT-4-0.3-4',\n",
    "                       '2', '2_DOCFILT-4-0.08-4', '2_DOCFILT-4-0.3-3', '2_DOCFILT-4-0.3-4',\n",
    "                       '3', '3_DOCFILT-4-0.08-4', '3_DOCFILT-4-0.3-3', '3_DOCFILT-4-0.3-4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d960e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = file_paths['data_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aa55e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c9145e62624ff7b53c9204c486fee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_signals = build_signal_dataframe(data_path, settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "472a15ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>channel_1</th>\n",
       "      <th>channel_1_filt_0.08_4_hz</th>\n",
       "      <th>channel_1_filt_0.3_3_hz</th>\n",
       "      <th>channel_1_filt_0.3_4_hz</th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_2_filt_0.08_4_hz</th>\n",
       "      <th>channel_2_filt_0.3_3_hz</th>\n",
       "      <th>channel_2_filt_0.3_4_hz</th>\n",
       "      <th>channel_3</th>\n",
       "      <th>channel_3_filt_0.08_4_hz</th>\n",
       "      <th>channel_3_filt_0.3_3_hz</th>\n",
       "      <th>channel_3_filt_0.3_4_hz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1391</td>\n",
       "      <td>-0.404669</td>\n",
       "      <td>-0.010681</td>\n",
       "      <td>-0.003128</td>\n",
       "      <td>-0.008392</td>\n",
       "      <td>-0.284733</td>\n",
       "      <td>-0.007401</td>\n",
       "      <td>-0.002213</td>\n",
       "      <td>-0.006027</td>\n",
       "      <td>0.555428</td>\n",
       "      <td>0.014954</td>\n",
       "      <td>0.004349</td>\n",
       "      <td>0.011597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1391</td>\n",
       "      <td>-0.407111</td>\n",
       "      <td>-0.061646</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.048142</td>\n",
       "      <td>-0.283513</td>\n",
       "      <td>-0.042725</td>\n",
       "      <td>-0.014725</td>\n",
       "      <td>-0.034409</td>\n",
       "      <td>0.555428</td>\n",
       "      <td>0.086290</td>\n",
       "      <td>0.028305</td>\n",
       "      <td>0.066377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1391</td>\n",
       "      <td>-0.401007</td>\n",
       "      <td>-0.157244</td>\n",
       "      <td>-0.061494</td>\n",
       "      <td>-0.120928</td>\n",
       "      <td>-0.281071</td>\n",
       "      <td>-0.108949</td>\n",
       "      <td>-0.044099</td>\n",
       "      <td>-0.086595</td>\n",
       "      <td>0.549325</td>\n",
       "      <td>0.220035</td>\n",
       "      <td>0.084764</td>\n",
       "      <td>0.166629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1391</td>\n",
       "      <td>-0.394903</td>\n",
       "      <td>-0.239490</td>\n",
       "      <td>-0.115053</td>\n",
       "      <td>-0.179065</td>\n",
       "      <td>-0.276188</td>\n",
       "      <td>-0.165866</td>\n",
       "      <td>-0.082399</td>\n",
       "      <td>-0.128328</td>\n",
       "      <td>0.545663</td>\n",
       "      <td>0.335088</td>\n",
       "      <td>0.158618</td>\n",
       "      <td>0.246662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1391</td>\n",
       "      <td>-0.396124</td>\n",
       "      <td>-0.255055</td>\n",
       "      <td>-0.154498</td>\n",
       "      <td>-0.181201</td>\n",
       "      <td>-0.277409</td>\n",
       "      <td>-0.176089</td>\n",
       "      <td>-0.110399</td>\n",
       "      <td>-0.129778</td>\n",
       "      <td>0.537118</td>\n",
       "      <td>0.356832</td>\n",
       "      <td>0.213169</td>\n",
       "      <td>0.249561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id  channel_1  channel_1_filt_0.08_4_hz  channel_1_filt_0.3_3_hz  \\\n",
       "0    1391  -0.404669                 -0.010681                -0.003128   \n",
       "1    1391  -0.407111                 -0.061646                -0.020523   \n",
       "2    1391  -0.401007                 -0.157244                -0.061494   \n",
       "3    1391  -0.394903                 -0.239490                -0.115053   \n",
       "4    1391  -0.396124                 -0.255055                -0.154498   \n",
       "\n",
       "   channel_1_filt_0.3_4_hz  channel_2  channel_2_filt_0.08_4_hz  \\\n",
       "0                -0.008392  -0.284733                 -0.007401   \n",
       "1                -0.048142  -0.283513                 -0.042725   \n",
       "2                -0.120928  -0.281071                 -0.108949   \n",
       "3                -0.179065  -0.276188                 -0.165866   \n",
       "4                -0.181201  -0.277409                 -0.176089   \n",
       "\n",
       "   channel_2_filt_0.3_3_hz  channel_2_filt_0.3_4_hz  channel_3  \\\n",
       "0                -0.002213                -0.006027   0.555428   \n",
       "1                -0.014725                -0.034409   0.555428   \n",
       "2                -0.044099                -0.086595   0.549325   \n",
       "3                -0.082399                -0.128328   0.545663   \n",
       "4                -0.110399                -0.129778   0.537118   \n",
       "\n",
       "   channel_3_filt_0.08_4_hz  channel_3_filt_0.3_3_hz  channel_3_filt_0.3_4_hz  \n",
       "0                  0.014954                 0.004349                 0.011597  \n",
       "1                  0.086290                 0.028305                 0.066377  \n",
       "2                  0.220035                 0.084764                 0.166629  \n",
       "3                  0.335088                 0.158618                 0.246662  \n",
       "4                  0.356832                 0.213169                 0.249561  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_signals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c407becf",
   "metadata": {},
   "source": [
    "A Butterworth filter with forward and backward filter is used to filter the signals. The combined filter has zero phase. Different bandwidths can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "260d4c8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_signals_new = create_filtered_channels(df_signals, ['channel_1', 'channel_2', 'channel_3'], \n",
    "                                          [[0.08, 4], [0.3, 3], [0.3, 4]], fs=20, order=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "387fcc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4543de",
   "metadata": {},
   "source": [
    "The first and last 180 seconds of the signals should be ignored since these intervals contain transient effects of the filters(source: https://physionet.org/content/tpehgdb/1.0.1/#ref1).\n",
    "\n",
    "The sampling frequency is 20 Hz, so the first and last 20*180 datapoints should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e77ace1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of data points before removing the first 3600 data points (per rec_id) is: 10655901\n",
      "The number of data points after removing the first 3600 data points (per rec_id) is: 9575901\n"
     ]
    }
   ],
   "source": [
    "df_signals_new = remove_first_n_samples_of_signals(df_signals_new, n=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b97d9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of data points before removing the last 3600 data points (per rec_id) is: 9575901\n",
      "The number of data points after removing the last 3600 data points (per rec_id) is: 8495901\n"
     ]
    }
   ],
   "source": [
    "df_signals_new = remove_last_n_samples_of_signals(df_signals_new, n=3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015578bf",
   "metadata": {},
   "source": [
    "We need to check the distribution of the sequence length of all the rec ids. Later on, we will need to pad/truncate every sequence to the same length. Based on the plot we will choose 28800 (which is the mode) as the fixed sequence length we will pad/truncate all the sequences to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c278a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": [
           "rgba(222,45,38,0.8)",
           "rgba(222,45,38,0.8)",
           "rgba(222,45,38,0.8)",
           "rgba(222,45,38,0.8)",
           "rgba(204,204,204,1)",
           "rgba(204,204,204,1)",
           "rgba(204,204,204,1)",
           "rgba(204,204,204,1)",
           "rgba(204,204,204,1)",
           "rgba(204,204,204,1)",
           "rgba(204,204,204,1)",
           "rgba(204,204,204,1)",
           "rgba(204,204,204,1)",
           "rgba(204,204,204,1)",
           "rgba(204,204,204,1)",
           "rgba(204,204,204,1)",
           "rgba(204,204,204,1)",
           "rgba(222,45,38,0.8)",
           "rgba(222,45,38,0.8)",
           "rgba(222,45,38,0.8)",
           "rgba(204,204,204,1)",
           "rgba(204,204,204,1)",
           "rgba(204,204,204,1)",
           "rgba(222,45,38,0.8)",
           "rgba(222,45,38,0.8)"
          ]
         },
         "type": "bar",
         "x": [
          "7860",
          "24105",
          "27880",
          "27900",
          "27940",
          "27960",
          "27980",
          "28000",
          "28020",
          "28040",
          "28060",
          "28080",
          "28100",
          "28120",
          "28140",
          "28160",
          "28180",
          "28200",
          "28220",
          "28240",
          "28260",
          "28799",
          "28800",
          "30856",
          "32673"
         ],
         "y": [
          1,
          1,
          1,
          1,
          2,
          2,
          10,
          13,
          14,
          21,
          21,
          13,
          17,
          21,
          12,
          8,
          3,
          1,
          1,
          1,
          11,
          33,
          90,
          1,
          1
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of count"
        },
        "xaxis": {
         "title": {
          "font": {
           "color": "#7f7f7f",
           "family": "Courier New, monospace",
           "size": 18
          },
          "text": "count"
         }
        },
        "yaxis": {
         "title": {
          "font": {
           "color": "#7f7f7f",
           "family": "Courier New, monospace",
           "size": 18
          },
          "text": "Number of patients"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"a47c1ed9-3e22-499b-8cda-2f2625ab4e6d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a47c1ed9-3e22-499b-8cda-2f2625ab4e6d\")) {                    Plotly.newPlot(                        \"a47c1ed9-3e22-499b-8cda-2f2625ab4e6d\",                        [{\"marker\":{\"color\":[\"rgba(222,45,38,0.8)\",\"rgba(222,45,38,0.8)\",\"rgba(222,45,38,0.8)\",\"rgba(222,45,38,0.8)\",\"rgba(204,204,204,1)\",\"rgba(204,204,204,1)\",\"rgba(204,204,204,1)\",\"rgba(204,204,204,1)\",\"rgba(204,204,204,1)\",\"rgba(204,204,204,1)\",\"rgba(204,204,204,1)\",\"rgba(204,204,204,1)\",\"rgba(204,204,204,1)\",\"rgba(204,204,204,1)\",\"rgba(204,204,204,1)\",\"rgba(204,204,204,1)\",\"rgba(204,204,204,1)\",\"rgba(222,45,38,0.8)\",\"rgba(222,45,38,0.8)\",\"rgba(222,45,38,0.8)\",\"rgba(204,204,204,1)\",\"rgba(204,204,204,1)\",\"rgba(204,204,204,1)\",\"rgba(222,45,38,0.8)\",\"rgba(222,45,38,0.8)\"]},\"type\":\"bar\",\"x\":[\"7860\",\"24105\",\"27880\",\"27900\",\"27940\",\"27960\",\"27980\",\"28000\",\"28020\",\"28040\",\"28060\",\"28080\",\"28100\",\"28120\",\"28140\",\"28160\",\"28180\",\"28200\",\"28220\",\"28240\",\"28260\",\"28799\",\"28800\",\"30856\",\"32673\"],\"y\":[1,1,1,1,2,2,10,13,14,21,21,13,17,21,12,8,3,1,1,1,11,33,90,1,1]}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Distribution of count\"},\"xaxis\":{\"title\":{\"font\":{\"color\":\"#7f7f7f\",\"family\":\"Courier New, monospace\",\"size\":18},\"text\":\"count\"}},\"yaxis\":{\"title\":{\"font\":{\"color\":\"#7f7f7f\",\"family\":\"Courier New, monospace\",\"size\":18},\"text\":\"Number of patients\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('a47c1ed9-3e22-499b-8cda-2f2625ab4e6d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_distribution_feature(df_signals_new.groupby('rec_id', sort=False).agg({'rec_id': 'size'}).rename(columns={'rec_id': 'count'}).reset_index(), 'count', categorical=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eb395c",
   "metadata": {},
   "source": [
    "# This part is to calculate the sample entropy and in effect reduce the sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7a608b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import antropy as ant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43ae4b82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Entropy.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : list or np.array\n",
      "        One-dimensional time series of shape (n_times).\n",
      "    order : int\n",
      "        Embedding dimension. Default is 2.\n",
      "    metric : str\n",
      "        Name of the distance metric function used with\n",
      "        :py:class:`sklearn.neighbors.KDTree`. Default is to use the\n",
      "        `Chebyshev <https://en.wikipedia.org/wiki/Chebyshev_distance>`_\n",
      "        distance.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    se : float\n",
      "        Sample Entropy.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Sample entropy is a modification of approximate entropy, used for assessing\n",
      "    the complexity of physiological time-series signals. It has two advantages\n",
      "    over approximate entropy: data length independence and a relatively\n",
      "    trouble-free implementation. Large values indicate high complexity whereas\n",
      "    smaller values characterize more self-similar and regular signals.\n",
      "\n",
      "    The sample entropy of a signal :math:`x` is defined as:\n",
      "\n",
      "    .. math:: H(x, m, r) = -\\log\\frac{C(m + 1, r)}{C(m, r)}\n",
      "\n",
      "    where :math:`m` is the embedding dimension (= order), :math:`r` is\n",
      "    the radius of the neighbourhood (default = :math:`0.2 * \\text{std}(x)`),\n",
      "    :math:`C(m + 1, r)` is the number of embedded vectors of length\n",
      "    :math:`m + 1` having a\n",
      "    `Chebyshev distance <https://en.wikipedia.org/wiki/Chebyshev_distance>`_\n",
      "    inferior to :math:`r` and :math:`C(m, r)` is the number of embedded\n",
      "    vectors of length :math:`m` having a Chebyshev distance inferior to\n",
      "    :math:`r`.\n",
      "\n",
      "    Note that if ``metric == 'chebyshev'`` and ``len(x) < 5000`` points,\n",
      "    then the sample entropy is computed using a fast custom Numba script.\n",
      "    For other distance metric or longer time-series, the sample entropy is\n",
      "    computed using a code from the\n",
      "    `mne-features <https://mne.tools/mne-features/>`_ package by Jean-Baptiste\n",
      "    Schiratti and Alexandre Gramfort (requires sklearn).\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    Richman, J. S. et al. (2000). Physiological time-series analysis\n",
      "    using approximate entropy and sample entropy. American Journal of\n",
      "    Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.\n",
      "\n",
      "    https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Fractional Gaussian noise with H = 0.5\n",
      "\n",
      "    >>> import numpy as np\n",
      "    >>> import antropy as ant\n",
      "    >>> import stochastic.processes.noise as sn\n",
      "    >>> rng = np.random.default_rng(seed=42)\n",
      "    >>> x = sn.FractionalGaussianNoise(hurst=0.5, rng=rng).sample(10000)\n",
      "    >>> print(f\"{ant.sample_entropy(x, order=2):.4f}\")\n",
      "    2.1819\n",
      "\n",
      "    Same with order = 3 and using the Euclidean distance\n",
      "\n",
      "    >>> print(f\"{ant.sample_entropy(x, order=3, metric='euclidean'):.4f}\")\n",
      "    2.6806\n",
      "\n",
      "    Fractional Gaussian noise with H = 0.9\n",
      "\n",
      "    >>> rng = np.random.default_rng(seed=42)\n",
      "    >>> x = sn.FractionalGaussianNoise(hurst=0.9, rng=rng).sample(10000)\n",
      "    >>> print(f\"{ant.sample_entropy(x):.4f}\")\n",
      "    1.9078\n",
      "\n",
      "    Fractional Gaussian noise with H = 0.1\n",
      "\n",
      "    >>> rng = np.random.default_rng(seed=42)\n",
      "    >>> x = sn.FractionalGaussianNoise(hurst=0.1, rng=rng).sample(10000)\n",
      "    >>> print(f\"{ant.sample_entropy(x):.4f}\")\n",
      "    2.0555\n",
      "\n",
      "    Random\n",
      "\n",
      "    >>> rng = np.random.default_rng(seed=42)\n",
      "    >>> print(f\"{ant.sample_entropy(rng.random(1000)):.4f}\")\n",
      "    2.2017\n",
      "\n",
      "    Pure sine wave\n",
      "\n",
      "    >>> x = np.sin(2 * np.pi * 1 * np.arange(3000) / 100)\n",
      "    >>> print(f\"{ant.sample_entropy(x):.4f}\")\n",
      "    0.1633\n",
      "\n",
      "    Linearly-increasing time-series\n",
      "\n",
      "    >>> x = np.arange(1000)\n",
      "    >>> print(f\"{ant.sample_entropy(x):.4f}\")\n",
      "    -0.0000\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(ant.sample_entropy.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8ed6c6",
   "metadata": {},
   "source": [
    "We calculate the sample entropy over fixed_seq_length time windows. In effect, we reduce the total sequence length to fixed_seq_length.\n",
    "\n",
    "Example: If the total sequence length of a rec_id is 27790 time steps and the fixed_seq_length is set at 300 time steps, then the sample entropy will be calculated over 300 consecutive subsequences. Each subsequence will have approximately the same length (and in this case the total length of the subsequences sums up to 27790). Thus, the subsequences over which the sample entropy is calculated will not have had the exact same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19b60eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samp_en = calculate_samp_en_over_fixed_time_window(df_signals_new, fixed_seq_length = 300, \n",
    "                                                      feature_list = ['channel_1', 'channel_1_filt_0.08_4_hz', \n",
    "                                                                      'channel_1_filt_0.3_3_hz', 'channel_1_filt_0.3_4_hz', \n",
    "                                                                      'channel_2', 'channel_2_filt_0.08_4_hz', \n",
    "                                                                      'channel_2_filt_0.3_3_hz', 'channel_2_filt_0.3_4_hz', \n",
    "                                                                      'channel_3', 'channel_3_filt_0.08_4_hz', \n",
    "                                                                      'channel_3_filt_0.3_3_hz', 'channel_3_filt_0.3_4_hz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59ad4d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>channel_1</th>\n",
       "      <th>channel_1_filt_0.08_4_hz</th>\n",
       "      <th>channel_1_filt_0.3_3_hz</th>\n",
       "      <th>channel_1_filt_0.3_4_hz</th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_2_filt_0.08_4_hz</th>\n",
       "      <th>channel_2_filt_0.3_3_hz</th>\n",
       "      <th>channel_2_filt_0.3_4_hz</th>\n",
       "      <th>channel_3</th>\n",
       "      <th>channel_3_filt_0.08_4_hz</th>\n",
       "      <th>channel_3_filt_0.3_3_hz</th>\n",
       "      <th>channel_3_filt_0.3_4_hz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1391</td>\n",
       "      <td>1.187166</td>\n",
       "      <td>0.995428</td>\n",
       "      <td>0.810930</td>\n",
       "      <td>1.418383</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.845616</td>\n",
       "      <td>0.544112</td>\n",
       "      <td>1.008461</td>\n",
       "      <td>2.043074</td>\n",
       "      <td>0.986134</td>\n",
       "      <td>0.794930</td>\n",
       "      <td>1.193922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1391</td>\n",
       "      <td>1.265666</td>\n",
       "      <td>0.815968</td>\n",
       "      <td>0.628609</td>\n",
       "      <td>0.933533</td>\n",
       "      <td>2.036882</td>\n",
       "      <td>0.765837</td>\n",
       "      <td>0.723179</td>\n",
       "      <td>1.366876</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>0.908468</td>\n",
       "      <td>0.543425</td>\n",
       "      <td>0.972572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1391</td>\n",
       "      <td>2.104134</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.801628</td>\n",
       "      <td>1.292768</td>\n",
       "      <td>1.471817</td>\n",
       "      <td>0.838732</td>\n",
       "      <td>0.674219</td>\n",
       "      <td>0.986908</td>\n",
       "      <td>1.871802</td>\n",
       "      <td>0.918954</td>\n",
       "      <td>0.944462</td>\n",
       "      <td>1.412270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1391</td>\n",
       "      <td>1.185624</td>\n",
       "      <td>0.776325</td>\n",
       "      <td>0.955511</td>\n",
       "      <td>1.023811</td>\n",
       "      <td>1.565635</td>\n",
       "      <td>1.310583</td>\n",
       "      <td>1.043042</td>\n",
       "      <td>1.332227</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>0.727890</td>\n",
       "      <td>0.899484</td>\n",
       "      <td>1.193922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1391</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>1.009817</td>\n",
       "      <td>1.056053</td>\n",
       "      <td>1.289131</td>\n",
       "      <td>1.754019</td>\n",
       "      <td>1.090244</td>\n",
       "      <td>1.133098</td>\n",
       "      <td>1.171183</td>\n",
       "      <td>1.588161</td>\n",
       "      <td>1.071584</td>\n",
       "      <td>0.838329</td>\n",
       "      <td>1.219240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id  channel_1  channel_1_filt_0.08_4_hz  channel_1_filt_0.3_3_hz  \\\n",
       "0    1391   1.187166                  0.995428                 0.810930   \n",
       "1    1391   1.265666                  0.815968                 0.628609   \n",
       "2    1391   2.104134                  0.693147                 0.801628   \n",
       "3    1391   1.185624                  0.776325                 0.955511   \n",
       "4    1391   3.258097                  1.009817                 1.056053   \n",
       "\n",
       "   channel_1_filt_0.3_4_hz  channel_2  channel_2_filt_0.08_4_hz  \\\n",
       "0                 1.418383   2.639057                  0.845616   \n",
       "1                 0.933533   2.036882                  0.765837   \n",
       "2                 1.292768   1.471817                  0.838732   \n",
       "3                 1.023811   1.565635                  1.310583   \n",
       "4                 1.289131   1.754019                  1.090244   \n",
       "\n",
       "   channel_2_filt_0.3_3_hz  channel_2_filt_0.3_4_hz  channel_3  \\\n",
       "0                 0.544112                 1.008461   2.043074   \n",
       "1                 0.723179                 1.366876   3.332205   \n",
       "2                 0.674219                 0.986908   1.871802   \n",
       "3                 1.043042                 1.332227   1.128918   \n",
       "4                 1.133098                 1.171183   1.588161   \n",
       "\n",
       "   channel_3_filt_0.08_4_hz  channel_3_filt_0.3_3_hz  channel_3_filt_0.3_4_hz  \n",
       "0                  0.986134                 0.794930                 1.193922  \n",
       "1                  0.908468                 0.543425                 0.972572  \n",
       "2                  0.918954                 0.944462                 1.412270  \n",
       "3                  0.727890                 0.899484                 1.193922  \n",
       "4                  1.071584                 0.838329                 1.219240  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_samp_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76ea1c0",
   "metadata": {},
   "source": [
    "df_clinical_information contains the labels (the column premature) for each rec_id. We will add this column to the signals dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9df6fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clinical_information = build_clinical_information_dataframe(data_path, settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e952b9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>gestation</th>\n",
       "      <th>gestation_at_rec_time</th>\n",
       "      <th>group</th>\n",
       "      <th>premature</th>\n",
       "      <th>early</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1007</td>\n",
       "      <td>35.00</td>\n",
       "      <td>31.29</td>\n",
       "      <td>&gt;=26-PRE</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>38.57</td>\n",
       "      <td>22.29</td>\n",
       "      <td>&lt;26-TERM</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1022</td>\n",
       "      <td>38.57</td>\n",
       "      <td>31.00</td>\n",
       "      <td>&gt;=26-TERM</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1027</td>\n",
       "      <td>37.14</td>\n",
       "      <td>31.29</td>\n",
       "      <td>&gt;=26-TERM</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1029</td>\n",
       "      <td>38.57</td>\n",
       "      <td>31.00</td>\n",
       "      <td>&gt;=26-TERM</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id  gestation  gestation_at_rec_time        group    premature early\n",
       "0    1007      35.00                  31.29   >=26-PRE     t              f\n",
       "1    1021      38.57                  22.29   <26-TERM     f              t\n",
       "2    1022      38.57                  31.00   >=26-TERM    f              f\n",
       "3    1027      37.14                  31.29   >=26-TERM    f              f\n",
       "4    1029      38.57                  31.00   >=26-TERM    f              f"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clinical_information.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "306f7788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signals = df_signals_new.merge(df_clinical_information[['rec_id', 'premature']], how='left', on='rec_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0817cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samp_en = df_samp_en.merge(df_clinical_information[['rec_id', 'premature']], how='left', on='rec_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4555422",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_signals_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "838a7eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>channel_1</th>\n",
       "      <th>channel_1_filt_0.08_4_hz</th>\n",
       "      <th>channel_1_filt_0.3_3_hz</th>\n",
       "      <th>channel_1_filt_0.3_4_hz</th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_2_filt_0.08_4_hz</th>\n",
       "      <th>channel_2_filt_0.3_3_hz</th>\n",
       "      <th>channel_2_filt_0.3_4_hz</th>\n",
       "      <th>channel_3</th>\n",
       "      <th>channel_3_filt_0.08_4_hz</th>\n",
       "      <th>channel_3_filt_0.3_3_hz</th>\n",
       "      <th>channel_3_filt_0.3_4_hz</th>\n",
       "      <th>premature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.009279</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>-0.013733</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.007248</td>\n",
       "      <td>-0.001619</td>\n",
       "      <td>-0.001963</td>\n",
       "      <td>-0.001452</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.008443</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>0.003158</td>\n",
       "      <td>-0.011292</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.001984</td>\n",
       "      <td>-0.001667</td>\n",
       "      <td>-0.001687</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1391</td>\n",
       "      <td>-0.003052</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>-0.016175</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>-0.009689</td>\n",
       "      <td>-0.001785</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1391</td>\n",
       "      <td>-0.000610</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>-0.001391</td>\n",
       "      <td>-0.013733</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.000704</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1391</td>\n",
       "      <td>-0.007935</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>-0.003590</td>\n",
       "      <td>-0.003500</td>\n",
       "      <td>-0.013733</td>\n",
       "      <td>-0.000657</td>\n",
       "      <td>-0.001069</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.002365</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id  channel_1  channel_1_filt_0.08_4_hz  channel_1_filt_0.3_3_hz  \\\n",
       "0    1391   0.001755                  0.009279                 0.004092   \n",
       "1    1391   0.001755                  0.008443                 0.002888   \n",
       "2    1391  -0.003052                  0.006425                 0.000974   \n",
       "3    1391  -0.000610                  0.003946                -0.001363   \n",
       "4    1391  -0.007935                  0.001862                -0.003590   \n",
       "\n",
       "   channel_1_filt_0.3_4_hz  channel_2  channel_2_filt_0.08_4_hz  \\\n",
       "0                 0.004034  -0.013733                  0.000247   \n",
       "1                 0.003158  -0.011292                  0.000195   \n",
       "2                 0.001114  -0.016175                  0.000300   \n",
       "3                -0.001391  -0.013733                  0.000270   \n",
       "4                -0.003500  -0.013733                 -0.000657   \n",
       "\n",
       "   channel_2_filt_0.3_3_hz  channel_2_filt_0.3_4_hz  channel_3  \\\n",
       "0                 0.000299                -0.000061  -0.007248   \n",
       "1                 0.000392                 0.000072  -0.004807   \n",
       "2                 0.000461                 0.000411  -0.009689   \n",
       "3                 0.000038                 0.000586  -0.004807   \n",
       "4                -0.001069                -0.000200  -0.002365   \n",
       "\n",
       "   channel_3_filt_0.08_4_hz  channel_3_filt_0.3_3_hz  channel_3_filt_0.3_4_hz  \\\n",
       "0                 -0.001619                -0.001963                -0.001452   \n",
       "1                 -0.001984                -0.001667                -0.001687   \n",
       "2                 -0.001785                -0.000909                -0.001365   \n",
       "3                 -0.000704                 0.000281                -0.000165   \n",
       "4                  0.000707                 0.001519                 0.001390   \n",
       "\n",
       "     premature  \n",
       "0   t           \n",
       "1   t           \n",
       "2   t           \n",
       "3   t           \n",
       "4   t           "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_signals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0b2a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign 0 to non-premature cases and assign 1 to premature cases\n",
    "lb = LabelEncoder()\n",
    "df_signals['premature'] = lb.fit_transform(df_signals['premature'])\n",
    "df_samp_en['premature'] = lb.fit_transform(df_samp_en['premature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f06fbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>channel_1</th>\n",
       "      <th>channel_1_filt_0.08_4_hz</th>\n",
       "      <th>channel_1_filt_0.3_3_hz</th>\n",
       "      <th>channel_1_filt_0.3_4_hz</th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_2_filt_0.08_4_hz</th>\n",
       "      <th>channel_2_filt_0.3_3_hz</th>\n",
       "      <th>channel_2_filt_0.3_4_hz</th>\n",
       "      <th>channel_3</th>\n",
       "      <th>channel_3_filt_0.08_4_hz</th>\n",
       "      <th>channel_3_filt_0.3_3_hz</th>\n",
       "      <th>channel_3_filt_0.3_4_hz</th>\n",
       "      <th>premature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.009279</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>-0.013733</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.007248</td>\n",
       "      <td>-0.001619</td>\n",
       "      <td>-0.001963</td>\n",
       "      <td>-0.001452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.008443</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>0.003158</td>\n",
       "      <td>-0.011292</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.001984</td>\n",
       "      <td>-0.001667</td>\n",
       "      <td>-0.001687</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1391</td>\n",
       "      <td>-0.003052</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>-0.016175</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>-0.009689</td>\n",
       "      <td>-0.001785</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1391</td>\n",
       "      <td>-0.000610</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>-0.001391</td>\n",
       "      <td>-0.013733</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.000704</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1391</td>\n",
       "      <td>-0.007935</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>-0.003590</td>\n",
       "      <td>-0.003500</td>\n",
       "      <td>-0.013733</td>\n",
       "      <td>-0.000657</td>\n",
       "      <td>-0.001069</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.002365</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id  channel_1  channel_1_filt_0.08_4_hz  channel_1_filt_0.3_3_hz  \\\n",
       "0    1391   0.001755                  0.009279                 0.004092   \n",
       "1    1391   0.001755                  0.008443                 0.002888   \n",
       "2    1391  -0.003052                  0.006425                 0.000974   \n",
       "3    1391  -0.000610                  0.003946                -0.001363   \n",
       "4    1391  -0.007935                  0.001862                -0.003590   \n",
       "\n",
       "   channel_1_filt_0.3_4_hz  channel_2  channel_2_filt_0.08_4_hz  \\\n",
       "0                 0.004034  -0.013733                  0.000247   \n",
       "1                 0.003158  -0.011292                  0.000195   \n",
       "2                 0.001114  -0.016175                  0.000300   \n",
       "3                -0.001391  -0.013733                  0.000270   \n",
       "4                -0.003500  -0.013733                 -0.000657   \n",
       "\n",
       "   channel_2_filt_0.3_3_hz  channel_2_filt_0.3_4_hz  channel_3  \\\n",
       "0                 0.000299                -0.000061  -0.007248   \n",
       "1                 0.000392                 0.000072  -0.004807   \n",
       "2                 0.000461                 0.000411  -0.009689   \n",
       "3                 0.000038                 0.000586  -0.004807   \n",
       "4                -0.001069                -0.000200  -0.002365   \n",
       "\n",
       "   channel_3_filt_0.08_4_hz  channel_3_filt_0.3_3_hz  channel_3_filt_0.3_4_hz  \\\n",
       "0                 -0.001619                -0.001963                -0.001452   \n",
       "1                 -0.001984                -0.001667                -0.001687   \n",
       "2                 -0.001785                -0.000909                -0.001365   \n",
       "3                 -0.000704                 0.000281                -0.000165   \n",
       "4                  0.000707                 0.001519                 0.001390   \n",
       "\n",
       "   premature  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_signals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "406fd07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>channel_1</th>\n",
       "      <th>channel_1_filt_0.08_4_hz</th>\n",
       "      <th>channel_1_filt_0.3_3_hz</th>\n",
       "      <th>channel_1_filt_0.3_4_hz</th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_2_filt_0.08_4_hz</th>\n",
       "      <th>channel_2_filt_0.3_3_hz</th>\n",
       "      <th>channel_2_filt_0.3_4_hz</th>\n",
       "      <th>channel_3</th>\n",
       "      <th>channel_3_filt_0.08_4_hz</th>\n",
       "      <th>channel_3_filt_0.3_3_hz</th>\n",
       "      <th>channel_3_filt_0.3_4_hz</th>\n",
       "      <th>premature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1391</td>\n",
       "      <td>1.187166</td>\n",
       "      <td>0.995428</td>\n",
       "      <td>0.810930</td>\n",
       "      <td>1.418383</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.845616</td>\n",
       "      <td>0.544112</td>\n",
       "      <td>1.008461</td>\n",
       "      <td>2.043074</td>\n",
       "      <td>0.986134</td>\n",
       "      <td>0.794930</td>\n",
       "      <td>1.193922</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1391</td>\n",
       "      <td>1.265666</td>\n",
       "      <td>0.815968</td>\n",
       "      <td>0.628609</td>\n",
       "      <td>0.933533</td>\n",
       "      <td>2.036882</td>\n",
       "      <td>0.765837</td>\n",
       "      <td>0.723179</td>\n",
       "      <td>1.366876</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>0.908468</td>\n",
       "      <td>0.543425</td>\n",
       "      <td>0.972572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1391</td>\n",
       "      <td>2.104134</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.801628</td>\n",
       "      <td>1.292768</td>\n",
       "      <td>1.471817</td>\n",
       "      <td>0.838732</td>\n",
       "      <td>0.674219</td>\n",
       "      <td>0.986908</td>\n",
       "      <td>1.871802</td>\n",
       "      <td>0.918954</td>\n",
       "      <td>0.944462</td>\n",
       "      <td>1.412270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1391</td>\n",
       "      <td>1.185624</td>\n",
       "      <td>0.776325</td>\n",
       "      <td>0.955511</td>\n",
       "      <td>1.023811</td>\n",
       "      <td>1.565635</td>\n",
       "      <td>1.310583</td>\n",
       "      <td>1.043042</td>\n",
       "      <td>1.332227</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>0.727890</td>\n",
       "      <td>0.899484</td>\n",
       "      <td>1.193922</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1391</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>1.009817</td>\n",
       "      <td>1.056053</td>\n",
       "      <td>1.289131</td>\n",
       "      <td>1.754019</td>\n",
       "      <td>1.090244</td>\n",
       "      <td>1.133098</td>\n",
       "      <td>1.171183</td>\n",
       "      <td>1.588161</td>\n",
       "      <td>1.071584</td>\n",
       "      <td>0.838329</td>\n",
       "      <td>1.219240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id  channel_1  channel_1_filt_0.08_4_hz  channel_1_filt_0.3_3_hz  \\\n",
       "0    1391   1.187166                  0.995428                 0.810930   \n",
       "1    1391   1.265666                  0.815968                 0.628609   \n",
       "2    1391   2.104134                  0.693147                 0.801628   \n",
       "3    1391   1.185624                  0.776325                 0.955511   \n",
       "4    1391   3.258097                  1.009817                 1.056053   \n",
       "\n",
       "   channel_1_filt_0.3_4_hz  channel_2  channel_2_filt_0.08_4_hz  \\\n",
       "0                 1.418383   2.639057                  0.845616   \n",
       "1                 0.933533   2.036882                  0.765837   \n",
       "2                 1.292768   1.471817                  0.838732   \n",
       "3                 1.023811   1.565635                  1.310583   \n",
       "4                 1.289131   1.754019                  1.090244   \n",
       "\n",
       "   channel_2_filt_0.3_3_hz  channel_2_filt_0.3_4_hz  channel_3  \\\n",
       "0                 0.544112                 1.008461   2.043074   \n",
       "1                 0.723179                 1.366876   3.332205   \n",
       "2                 0.674219                 0.986908   1.871802   \n",
       "3                 1.043042                 1.332227   1.128918   \n",
       "4                 1.133098                 1.171183   1.588161   \n",
       "\n",
       "   channel_3_filt_0.08_4_hz  channel_3_filt_0.3_3_hz  channel_3_filt_0.3_4_hz  \\\n",
       "0                  0.986134                 0.794930                 1.193922   \n",
       "1                  0.908468                 0.543425                 0.972572   \n",
       "2                  0.918954                 0.944462                 1.412270   \n",
       "3                  0.727890                 0.899484                 1.193922   \n",
       "4                  1.071584                 0.838329                 1.219240   \n",
       "\n",
       "   premature  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_samp_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb401f",
   "metadata": {},
   "source": [
    "We use df_clinical_information for this operation as this df is much smaller and therefore way faster. Also the\n",
    "order of the dataframe does not matter as each rec_id occurs only once in the data. The train/val/test split is made with stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88df69d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(df_clinical_information, 'premature', test_ratio=0.2, \n",
    "                                                                      shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92070f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>channel_1</th>\n",
       "      <th>channel_1_filt_0.08_4_hz</th>\n",
       "      <th>channel_1_filt_0.3_3_hz</th>\n",
       "      <th>channel_1_filt_0.3_4_hz</th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_2_filt_0.08_4_hz</th>\n",
       "      <th>channel_2_filt_0.3_3_hz</th>\n",
       "      <th>channel_2_filt_0.3_4_hz</th>\n",
       "      <th>channel_3</th>\n",
       "      <th>channel_3_filt_0.08_4_hz</th>\n",
       "      <th>channel_3_filt_0.3_3_hz</th>\n",
       "      <th>channel_3_filt_0.3_4_hz</th>\n",
       "      <th>premature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.009279</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>-0.013733</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.007248</td>\n",
       "      <td>-0.001619</td>\n",
       "      <td>-0.001963</td>\n",
       "      <td>-0.001452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.008443</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>0.003158</td>\n",
       "      <td>-0.011292</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.001984</td>\n",
       "      <td>-0.001667</td>\n",
       "      <td>-0.001687</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1391</td>\n",
       "      <td>-0.003052</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>-0.016175</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>-0.009689</td>\n",
       "      <td>-0.001785</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1391</td>\n",
       "      <td>-0.000610</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>-0.001391</td>\n",
       "      <td>-0.013733</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.000704</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1391</td>\n",
       "      <td>-0.007935</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>-0.003590</td>\n",
       "      <td>-0.003500</td>\n",
       "      <td>-0.013733</td>\n",
       "      <td>-0.000657</td>\n",
       "      <td>-0.001069</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.002365</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id  channel_1  channel_1_filt_0.08_4_hz  channel_1_filt_0.3_3_hz  \\\n",
       "0    1391   0.001755                  0.009279                 0.004092   \n",
       "1    1391   0.001755                  0.008443                 0.002888   \n",
       "2    1391  -0.003052                  0.006425                 0.000974   \n",
       "3    1391  -0.000610                  0.003946                -0.001363   \n",
       "4    1391  -0.007935                  0.001862                -0.003590   \n",
       "\n",
       "   channel_1_filt_0.3_4_hz  channel_2  channel_2_filt_0.08_4_hz  \\\n",
       "0                 0.004034  -0.013733                  0.000247   \n",
       "1                 0.003158  -0.011292                  0.000195   \n",
       "2                 0.001114  -0.016175                  0.000300   \n",
       "3                -0.001391  -0.013733                  0.000270   \n",
       "4                -0.003500  -0.013733                 -0.000657   \n",
       "\n",
       "   channel_2_filt_0.3_3_hz  channel_2_filt_0.3_4_hz  channel_3  \\\n",
       "0                 0.000299                -0.000061  -0.007248   \n",
       "1                 0.000392                 0.000072  -0.004807   \n",
       "2                 0.000461                 0.000411  -0.009689   \n",
       "3                 0.000038                 0.000586  -0.004807   \n",
       "4                -0.001069                -0.000200  -0.002365   \n",
       "\n",
       "   channel_3_filt_0.08_4_hz  channel_3_filt_0.3_3_hz  channel_3_filt_0.3_4_hz  \\\n",
       "0                 -0.001619                -0.001963                -0.001452   \n",
       "1                 -0.001984                -0.001667                -0.001687   \n",
       "2                 -0.001785                -0.000909                -0.001365   \n",
       "3                 -0.000704                 0.000281                -0.000165   \n",
       "4                  0.000707                 0.001519                 0.001390   \n",
       "\n",
       "   premature  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_signals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44b1ff20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['rec_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac4d784e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val['rec_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aafe1810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['rec_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7425da",
   "metadata": {},
   "source": [
    "## This part is to build a LSTM model with the reduced sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ceefeb",
   "metadata": {},
   "source": [
    "We first need to replace the NA and inf values in df_samp_en with zeros. The reason for having NA/inf values is that for some sub sequences you had $log(0)$, which is ill defined. We now convert these values to zero, as the limit of $log(0)$ -> 0 (Source: https://dsp.stackexchange.com/questions/74057/value-of-0-log0-in-entropy-formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f7c3764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows with infinite numbers that will be replaced with zero is: 691\n"
     ]
    }
   ],
   "source": [
    "df_samp_en = replace_inf_with_zero(df_samp_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a735ef05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows with infinite numbers that will be replaced with zero is: 22\n"
     ]
    }
   ],
   "source": [
    "df_samp_en = replace_na_with_zero(df_samp_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ef0feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These dfs contain the sample entropy data\n",
    "X_train_samp_en = df_samp_en[df_samp_en['rec_id'].isin(X_train['rec_id'].unique())].reset_index(drop=True)\n",
    "X_val_samp_en= df_samp_en[df_samp_en['rec_id'].isin(X_val['rec_id'].unique())].reset_index(drop=True)\n",
    "X_test_samp_en = df_samp_en[df_samp_en['rec_id'].isin(X_test['rec_id'].unique())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "449171fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>channel_1</th>\n",
       "      <th>channel_1_filt_0.08_4_hz</th>\n",
       "      <th>channel_1_filt_0.3_3_hz</th>\n",
       "      <th>channel_1_filt_0.3_4_hz</th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_2_filt_0.08_4_hz</th>\n",
       "      <th>channel_2_filt_0.3_3_hz</th>\n",
       "      <th>channel_2_filt_0.3_4_hz</th>\n",
       "      <th>channel_3</th>\n",
       "      <th>channel_3_filt_0.08_4_hz</th>\n",
       "      <th>channel_3_filt_0.3_3_hz</th>\n",
       "      <th>channel_3_filt_0.3_4_hz</th>\n",
       "      <th>premature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1391</td>\n",
       "      <td>1.187166</td>\n",
       "      <td>0.995428</td>\n",
       "      <td>0.810930</td>\n",
       "      <td>1.418383</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.845616</td>\n",
       "      <td>0.544112</td>\n",
       "      <td>1.008461</td>\n",
       "      <td>2.043074</td>\n",
       "      <td>0.986134</td>\n",
       "      <td>0.794930</td>\n",
       "      <td>1.193922</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1391</td>\n",
       "      <td>1.265666</td>\n",
       "      <td>0.815968</td>\n",
       "      <td>0.628609</td>\n",
       "      <td>0.933533</td>\n",
       "      <td>2.036882</td>\n",
       "      <td>0.765837</td>\n",
       "      <td>0.723179</td>\n",
       "      <td>1.366876</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>0.908468</td>\n",
       "      <td>0.543425</td>\n",
       "      <td>0.972572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1391</td>\n",
       "      <td>2.104134</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.801628</td>\n",
       "      <td>1.292768</td>\n",
       "      <td>1.471817</td>\n",
       "      <td>0.838732</td>\n",
       "      <td>0.674219</td>\n",
       "      <td>0.986908</td>\n",
       "      <td>1.871802</td>\n",
       "      <td>0.918954</td>\n",
       "      <td>0.944462</td>\n",
       "      <td>1.412270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1391</td>\n",
       "      <td>1.185624</td>\n",
       "      <td>0.776325</td>\n",
       "      <td>0.955511</td>\n",
       "      <td>1.023811</td>\n",
       "      <td>1.565635</td>\n",
       "      <td>1.310583</td>\n",
       "      <td>1.043042</td>\n",
       "      <td>1.332227</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>0.727890</td>\n",
       "      <td>0.899484</td>\n",
       "      <td>1.193922</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1391</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>1.009817</td>\n",
       "      <td>1.056053</td>\n",
       "      <td>1.289131</td>\n",
       "      <td>1.754019</td>\n",
       "      <td>1.090244</td>\n",
       "      <td>1.133098</td>\n",
       "      <td>1.171183</td>\n",
       "      <td>1.588161</td>\n",
       "      <td>1.071584</td>\n",
       "      <td>0.838329</td>\n",
       "      <td>1.219240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id  channel_1  channel_1_filt_0.08_4_hz  channel_1_filt_0.3_3_hz  \\\n",
       "0    1391   1.187166                  0.995428                 0.810930   \n",
       "1    1391   1.265666                  0.815968                 0.628609   \n",
       "2    1391   2.104134                  0.693147                 0.801628   \n",
       "3    1391   1.185624                  0.776325                 0.955511   \n",
       "4    1391   3.258097                  1.009817                 1.056053   \n",
       "\n",
       "   channel_1_filt_0.3_4_hz  channel_2  channel_2_filt_0.08_4_hz  \\\n",
       "0                 1.418383   2.639057                  0.845616   \n",
       "1                 0.933533   2.036882                  0.765837   \n",
       "2                 1.292768   1.471817                  0.838732   \n",
       "3                 1.023811   1.565635                  1.310583   \n",
       "4                 1.289131   1.754019                  1.090244   \n",
       "\n",
       "   channel_2_filt_0.3_3_hz  channel_2_filt_0.3_4_hz  channel_3  \\\n",
       "0                 0.544112                 1.008461   2.043074   \n",
       "1                 0.723179                 1.366876   3.332205   \n",
       "2                 0.674219                 0.986908   1.871802   \n",
       "3                 1.043042                 1.332227   1.128918   \n",
       "4                 1.133098                 1.171183   1.588161   \n",
       "\n",
       "   channel_3_filt_0.08_4_hz  channel_3_filt_0.3_3_hz  channel_3_filt_0.3_4_hz  \\\n",
       "0                  0.986134                 0.794930                 1.193922   \n",
       "1                  0.908468                 0.543425                 0.972572   \n",
       "2                  0.918954                 0.944462                 1.412270   \n",
       "3                  0.727890                 0.899484                 1.193922   \n",
       "4                  1.071584                 0.838329                 1.219240   \n",
       "\n",
       "   premature  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_samp_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f3be719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to re-do this step because the X dataframes now contain the label column\n",
    "X_train_samp_en, y_train_samp_en = feature_label_split(X_train_samp_en, 'premature')\n",
    "X_val_samp_en, y_val_samp_en = feature_label_split(X_val_samp_en, 'premature')\n",
    "X_test_samp_en, y_test_samp_en = feature_label_split(X_test_samp_en, 'premature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6dd870a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>channel_1</th>\n",
       "      <th>channel_1_filt_0.08_4_hz</th>\n",
       "      <th>channel_1_filt_0.3_3_hz</th>\n",
       "      <th>channel_1_filt_0.3_4_hz</th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_2_filt_0.08_4_hz</th>\n",
       "      <th>channel_2_filt_0.3_3_hz</th>\n",
       "      <th>channel_2_filt_0.3_4_hz</th>\n",
       "      <th>channel_3</th>\n",
       "      <th>channel_3_filt_0.08_4_hz</th>\n",
       "      <th>channel_3_filt_0.3_3_hz</th>\n",
       "      <th>channel_3_filt_0.3_4_hz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>994</td>\n",
       "      <td>1.143064</td>\n",
       "      <td>1.058607</td>\n",
       "      <td>0.836248</td>\n",
       "      <td>1.110882</td>\n",
       "      <td>0.890973</td>\n",
       "      <td>0.996333</td>\n",
       "      <td>0.686632</td>\n",
       "      <td>0.898746</td>\n",
       "      <td>1.815290</td>\n",
       "      <td>1.573506</td>\n",
       "      <td>0.760806</td>\n",
       "      <td>1.704748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>994</td>\n",
       "      <td>1.596015</td>\n",
       "      <td>1.225612</td>\n",
       "      <td>0.648297</td>\n",
       "      <td>1.218157</td>\n",
       "      <td>0.555277</td>\n",
       "      <td>1.036092</td>\n",
       "      <td>0.829279</td>\n",
       "      <td>1.337504</td>\n",
       "      <td>2.041220</td>\n",
       "      <td>1.034590</td>\n",
       "      <td>0.814754</td>\n",
       "      <td>1.258955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>994</td>\n",
       "      <td>1.307157</td>\n",
       "      <td>0.972732</td>\n",
       "      <td>0.901548</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.883321</td>\n",
       "      <td>0.940007</td>\n",
       "      <td>0.760970</td>\n",
       "      <td>1.016934</td>\n",
       "      <td>1.228070</td>\n",
       "      <td>0.853490</td>\n",
       "      <td>0.883016</td>\n",
       "      <td>0.966441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>994</td>\n",
       "      <td>1.307513</td>\n",
       "      <td>1.037988</td>\n",
       "      <td>0.806476</td>\n",
       "      <td>1.850600</td>\n",
       "      <td>0.554311</td>\n",
       "      <td>0.991928</td>\n",
       "      <td>0.827737</td>\n",
       "      <td>1.041454</td>\n",
       "      <td>1.741498</td>\n",
       "      <td>0.997516</td>\n",
       "      <td>0.745594</td>\n",
       "      <td>1.264597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>994</td>\n",
       "      <td>0.561378</td>\n",
       "      <td>0.428632</td>\n",
       "      <td>0.491252</td>\n",
       "      <td>0.828856</td>\n",
       "      <td>0.652046</td>\n",
       "      <td>0.653407</td>\n",
       "      <td>0.643550</td>\n",
       "      <td>0.839439</td>\n",
       "      <td>1.444889</td>\n",
       "      <td>0.909818</td>\n",
       "      <td>0.552623</td>\n",
       "      <td>0.976722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id  channel_1  channel_1_filt_0.08_4_hz  channel_1_filt_0.3_3_hz  \\\n",
       "0     994   1.143064                  1.058607                 0.836248   \n",
       "1     994   1.596015                  1.225612                 0.648297   \n",
       "2     994   1.307157                  0.972732                 0.901548   \n",
       "3     994   1.307513                  1.037988                 0.806476   \n",
       "4     994   0.561378                  0.428632                 0.491252   \n",
       "\n",
       "   channel_1_filt_0.3_4_hz  channel_2  channel_2_filt_0.08_4_hz  \\\n",
       "0                 1.110882   0.890973                  0.996333   \n",
       "1                 1.218157   0.555277                  1.036092   \n",
       "2                 1.098612   0.883321                  0.940007   \n",
       "3                 1.850600   0.554311                  0.991928   \n",
       "4                 0.828856   0.652046                  0.653407   \n",
       "\n",
       "   channel_2_filt_0.3_3_hz  channel_2_filt_0.3_4_hz  channel_3  \\\n",
       "0                 0.686632                 0.898746   1.815290   \n",
       "1                 0.829279                 1.337504   2.041220   \n",
       "2                 0.760970                 1.016934   1.228070   \n",
       "3                 0.827737                 1.041454   1.741498   \n",
       "4                 0.643550                 0.839439   1.444889   \n",
       "\n",
       "   channel_3_filt_0.08_4_hz  channel_3_filt_0.3_3_hz  channel_3_filt_0.3_4_hz  \n",
       "0                  1.573506                 0.760806                 1.704748  \n",
       "1                  1.034590                 0.814754                 1.258955  \n",
       "2                  0.853490                 0.883016                 0.966441  \n",
       "3                  0.997516                 0.745594                 1.264597  \n",
       "4                  0.909818                 0.552623                 0.976722  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_samp_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "742714a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>channel_1</th>\n",
       "      <th>channel_1_filt_0.08_4_hz</th>\n",
       "      <th>channel_1_filt_0.3_3_hz</th>\n",
       "      <th>channel_1_filt_0.3_4_hz</th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_2_filt_0.08_4_hz</th>\n",
       "      <th>channel_2_filt_0.3_3_hz</th>\n",
       "      <th>channel_2_filt_0.3_4_hz</th>\n",
       "      <th>channel_3</th>\n",
       "      <th>channel_3_filt_0.08_4_hz</th>\n",
       "      <th>channel_3_filt_0.3_3_hz</th>\n",
       "      <th>channel_3_filt_0.3_4_hz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1360</td>\n",
       "      <td>0.980829</td>\n",
       "      <td>0.721478</td>\n",
       "      <td>0.688084</td>\n",
       "      <td>0.866591</td>\n",
       "      <td>0.702280</td>\n",
       "      <td>0.548696</td>\n",
       "      <td>0.595819</td>\n",
       "      <td>0.851371</td>\n",
       "      <td>0.498880</td>\n",
       "      <td>0.513354</td>\n",
       "      <td>0.711496</td>\n",
       "      <td>1.124930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1360</td>\n",
       "      <td>0.601165</td>\n",
       "      <td>0.527898</td>\n",
       "      <td>0.787334</td>\n",
       "      <td>0.909122</td>\n",
       "      <td>0.316287</td>\n",
       "      <td>0.337396</td>\n",
       "      <td>0.660203</td>\n",
       "      <td>0.795338</td>\n",
       "      <td>1.273706</td>\n",
       "      <td>0.585789</td>\n",
       "      <td>0.724563</td>\n",
       "      <td>0.983230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1360</td>\n",
       "      <td>0.795277</td>\n",
       "      <td>0.522386</td>\n",
       "      <td>1.317301</td>\n",
       "      <td>1.000974</td>\n",
       "      <td>0.696662</td>\n",
       "      <td>0.504747</td>\n",
       "      <td>0.472359</td>\n",
       "      <td>0.734305</td>\n",
       "      <td>1.120235</td>\n",
       "      <td>0.724753</td>\n",
       "      <td>0.735707</td>\n",
       "      <td>0.903219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1360</td>\n",
       "      <td>0.799670</td>\n",
       "      <td>0.643550</td>\n",
       "      <td>0.584839</td>\n",
       "      <td>0.612567</td>\n",
       "      <td>0.659246</td>\n",
       "      <td>0.514720</td>\n",
       "      <td>0.497624</td>\n",
       "      <td>0.736319</td>\n",
       "      <td>0.555387</td>\n",
       "      <td>0.409697</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>1.049822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1360</td>\n",
       "      <td>0.733602</td>\n",
       "      <td>0.439568</td>\n",
       "      <td>0.709496</td>\n",
       "      <td>0.892276</td>\n",
       "      <td>1.000632</td>\n",
       "      <td>0.468807</td>\n",
       "      <td>0.510826</td>\n",
       "      <td>0.628008</td>\n",
       "      <td>1.471288</td>\n",
       "      <td>0.445585</td>\n",
       "      <td>0.605372</td>\n",
       "      <td>0.976273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id  channel_1  channel_1_filt_0.08_4_hz  channel_1_filt_0.3_3_hz  \\\n",
       "0    1360   0.980829                  0.721478                 0.688084   \n",
       "1    1360   0.601165                  0.527898                 0.787334   \n",
       "2    1360   0.795277                  0.522386                 1.317301   \n",
       "3    1360   0.799670                  0.643550                 0.584839   \n",
       "4    1360   0.733602                  0.439568                 0.709496   \n",
       "\n",
       "   channel_1_filt_0.3_4_hz  channel_2  channel_2_filt_0.08_4_hz  \\\n",
       "0                 0.866591   0.702280                  0.548696   \n",
       "1                 0.909122   0.316287                  0.337396   \n",
       "2                 1.000974   0.696662                  0.504747   \n",
       "3                 0.612567   0.659246                  0.514720   \n",
       "4                 0.892276   1.000632                  0.468807   \n",
       "\n",
       "   channel_2_filt_0.3_3_hz  channel_2_filt_0.3_4_hz  channel_3  \\\n",
       "0                 0.595819                 0.851371   0.498880   \n",
       "1                 0.660203                 0.795338   1.273706   \n",
       "2                 0.472359                 0.734305   1.120235   \n",
       "3                 0.497624                 0.736319   0.555387   \n",
       "4                 0.510826                 0.628008   1.471288   \n",
       "\n",
       "   channel_3_filt_0.08_4_hz  channel_3_filt_0.3_3_hz  channel_3_filt_0.3_4_hz  \n",
       "0                  0.513354                 0.711496                 1.124930  \n",
       "1                  0.585789                 0.724563                 0.983230  \n",
       "2                  0.724753                 0.735707                 0.903219  \n",
       "3                  0.409697                 0.916291                 1.049822  \n",
       "4                  0.445585                 0.605372                 0.976273  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_samp_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b000f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names_signal = ['channel_1', 'channel_1_filt_0.08_4_hz', 'channel_1_filt_0.3_3_hz', 'channel_1_filt_0.3_4_hz', \n",
    "                           'channel_2', 'channel_2_filt_0.08_4_hz', 'channel_2_filt_0.3_3_hz', 'channel_2_filt_0.3_4_hz', \n",
    "                           'channel_3', 'channel_3_filt_0.08_4_hz', 'channel_3_filt_0.3_3_hz', 'channel_3_filt_0.3_4_hz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1da7558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = ['channel_1_filt_0.08_4_hz', 'channel_2_filt_0.08_4_hz', 'channel_3_filt_0.08_4_hz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0826db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't want to have the rec_ids scaled\n",
    "preprocessor_features = ColumnTransformer(\n",
    "        remainder='drop', #passthough features not listed\n",
    "        transformers=[\n",
    "            ('standard', StandardScaler(), features_to_use)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e82d540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_arr_samp_en = preprocessor_features.fit_transform(X_train_samp_en)\n",
    "X_val_arr_samp_en = preprocessor_features.transform(X_val_samp_en)\n",
    "X_test_arr_samp_en = preprocessor_features.transform(X_test_samp_en)\n",
    "\n",
    "y_train_arr_samp_en = lb.fit_transform(y_train_samp_en['premature'])\n",
    "y_val_arr_samp_en = lb.transform(y_val_samp_en['premature'])\n",
    "y_test_arr_samp_en = lb.transform(y_test_samp_en['premature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb93f7",
   "metadata": {},
   "source": [
    "We do not need to pad/truncate the sequences as we've reduced the sequence length of each rec id to a fixed window size by calculating the sample entropy of subsequent time windows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df71069a",
   "metadata": {},
   "source": [
    "Create tensors of the X and y data. BCEWithLogitsLoss requires its target to be a float tensor, not long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71cab2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_samp_en = torch.from_numpy(X_train_arr_samp_en)\n",
    "train_targets_samp_en = torch.from_numpy(y_train_arr_samp_en).float().view(-1, 1)\n",
    "val_features_samp_en = torch.from_numpy(X_val_arr_samp_en)\n",
    "val_targets_samp_en = torch.from_numpy(y_val_arr_samp_en).float().view(-1, 1)\n",
    "test_features_samp_en = torch.from_numpy(X_test_arr_samp_en)\n",
    "test_targets_samp_en = torch.from_numpy(y_test_arr_samp_en).float().view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7dd1b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_features_samp_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b05ff32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8752154 ,  1.09888589,  0.9846844 ],\n",
       "       [ 0.29535794,  0.80187928,  0.72572396],\n",
       "       [-0.10149126,  1.07326032,  0.76068659],\n",
       "       ...,\n",
       "       [-0.67197139,  2.5378804 , -0.7642934 ],\n",
       "       [-0.94315463,  0.1223262 , -0.7552336 ],\n",
       "       [-0.92784781,  2.83124745, -0.86137443]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_arr_samp_en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d39cd4",
   "metadata": {},
   "source": [
    "We put the features and targets in TensorDataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c8a3978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset_samp_en = TensorDataset(train_features_samp_en, train_targets_samp_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd38b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_samp_en = TensorDataset(val_features_samp_en, val_targets_samp_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67d74f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_samp_en = TensorDataset(test_features_samp_en, test_targets_samp_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7544a80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_samp_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7122a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8752, 1.0989, 0.9847], dtype=torch.float64) torch.Size([3]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset_samp_en:\n",
    "    print(x, x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba1ad3",
   "metadata": {},
   "source": [
    "At this moment, each time step is a separate dedicated tensor. We want to merge together the time steps in chunks of 300 time steps. The time steps in a chunk must have no overlap with other chunks, as each rec id only has 300 time steps and the time steps of different rec ids must not be mixed.\n",
    "\n",
    "The features will have the shape [sub_seq_length (=300), num_features] and the target will have the shape [num_targets]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "510f7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom Datasets with non-overlapping sequences of length 300\n",
    "custom_non_overlap_train_dataset_samp_en = NonOverlappingSequencesDataset(train_dataset_samp_en, 300, len(features_to_use), 1, 0)\n",
    "custom_non_overlap_val_dataset_samp_en = NonOverlappingSequencesDataset(val_dataset_samp_en, 300, len(features_to_use), 1, 0)\n",
    "custom_non_overlap_test_dataset_samp_en = NonOverlappingSequencesDataset(test_dataset_samp_en, 300, len(features_to_use), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24cbf11",
   "metadata": {},
   "source": [
    "The custom_non_overlap_train_dataset will have length len(train_dataset) / sub_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a38c285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(custom_non_overlap_train_dataset_samp_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5efd2ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.7522e-01,  1.0989e+00,  9.8468e-01],\n",
      "        [ 2.9536e-01,  8.0188e-01,  7.2572e-01],\n",
      "        [-1.0149e-01,  1.0733e+00,  7.6069e-01],\n",
      "        [ 1.6727e-01,  2.8299e+00,  1.2363e-01],\n",
      "        [ 9.2171e-01,  2.0096e+00,  1.2696e+00],\n",
      "        [ 1.1391e+00,  6.8324e-01, -2.8233e-01],\n",
      "        [ 1.7432e-01,  1.1965e+00, -2.1759e-01],\n",
      "        [ 2.7387e-01,  1.4291e+00, -6.3008e-02],\n",
      "        [ 4.5378e-01,  3.6576e+00,  2.8454e+00],\n",
      "        [ 1.6130e+00,  1.2541e+00,  1.9411e+00],\n",
      "        [ 5.6521e-01,  2.0408e+00,  2.7334e+00],\n",
      "        [ 1.1777e+00,  3.0692e+00,  2.1638e+00],\n",
      "        [ 5.3654e-01,  3.1558e+00,  5.9246e-01],\n",
      "        [ 1.4217e+00,  1.7315e+00,  1.0479e+00],\n",
      "        [ 6.0890e-01,  1.2937e+00,  1.5215e-01],\n",
      "        [-2.7209e-02,  2.5503e+00,  6.8724e-01],\n",
      "        [ 2.4135e-01,  4.0987e+00,  1.4564e+00],\n",
      "        [ 6.3038e-02,  2.4989e+00,  2.1143e+00],\n",
      "        [ 1.6792e-01,  3.1118e+00,  4.5302e-01],\n",
      "        [-5.9372e-01,  3.2850e+00,  7.0987e-01],\n",
      "        [-8.4166e-02,  2.8223e-01,  7.3495e-01],\n",
      "        [-8.3343e-01,  1.6017e-01, -9.7737e-01],\n",
      "        [-2.8451e-04,  3.1885e+00,  5.5966e-01],\n",
      "        [ 1.4241e+00,  1.4959e+00,  2.4359e+00],\n",
      "        [ 2.8827e-01,  1.6436e+00,  2.7485e+00],\n",
      "        [ 1.9830e-01,  2.5332e+00,  2.0758e+00],\n",
      "        [ 5.0233e-02,  1.2467e+00,  2.0758e+00],\n",
      "        [ 2.9380e-01,  2.2092e+00, -2.3570e-01],\n",
      "        [ 2.2221e+00,  2.1726e+00,  8.8258e-01],\n",
      "        [ 3.8998e+00,  2.4874e+00,  1.9075e+00],\n",
      "        [ 1.4045e+00,  2.7022e+00,  1.6901e+00],\n",
      "        [ 1.4347e+00,  2.5379e+00,  7.7472e-01],\n",
      "        [ 3.4675e-01, -7.0363e-04, -1.0819e+00],\n",
      "        [ 2.7416e-01,  4.2886e-01, -3.5128e-01],\n",
      "        [-3.4257e-01,  9.4644e-01, -4.7200e-01],\n",
      "        [-6.4663e-01,  1.7102e+00, -3.7776e-01],\n",
      "        [ 2.3894e-01, -6.9930e-03,  2.8710e-01],\n",
      "        [-5.5659e-02,  1.0861e+00, -1.8596e-01],\n",
      "        [ 1.4290e-01,  7.9138e-01,  8.6625e-01],\n",
      "        [ 6.1224e-01,  1.0987e+00,  2.2398e+00],\n",
      "        [ 1.0711e+00,  2.4793e+00,  2.6283e+00],\n",
      "        [ 1.4481e+00,  3.5959e+00,  1.4264e+00],\n",
      "        [ 1.8129e-01,  1.1677e+00,  3.2130e-01],\n",
      "        [-4.6854e-01, -3.4449e-01, -3.4079e-01],\n",
      "        [-1.6017e+00,  2.0408e+00, -8.7639e-01],\n",
      "        [-1.1785e-01,  6.2141e-01,  6.2597e-01],\n",
      "        [-1.4239e-01,  2.3213e-01, -3.6051e-01],\n",
      "        [ 3.9355e-02, -7.0363e-04, -6.8124e-01],\n",
      "        [ 6.8479e-01, -3.3562e-01,  5.0004e-01],\n",
      "        [ 1.1882e+00, -1.7532e-01, -3.0285e-01],\n",
      "        [-2.8948e-01, -4.2619e-02,  1.4865e+00],\n",
      "        [-2.6419e-01,  9.2596e-01,  1.2252e+00],\n",
      "        [ 4.3085e-01,  1.3917e+00,  5.3380e-01],\n",
      "        [ 8.3894e-01, -7.0732e-02,  1.8601e+00],\n",
      "        [ 7.9907e-01,  1.8005e+00, -3.2592e-01],\n",
      "        [-6.0199e-01,  6.6061e-01,  1.3597e+00],\n",
      "        [ 3.2997e-01,  1.1133e+00, -2.0116e-02],\n",
      "        [-3.8889e-01, -8.5704e-02,  8.5953e-01],\n",
      "        [ 9.0290e-01,  2.3387e+00,  2.5211e+00],\n",
      "        [ 4.1727e-01,  3.1885e+00,  1.3175e+00],\n",
      "        [-3.3195e-01, -1.5368e-01, -1.3017e+00],\n",
      "        [ 9.9378e-03,  2.4627e+00,  1.4759e+00],\n",
      "        [-8.9026e-03,  3.8163e+00, -5.9687e-01],\n",
      "        [ 1.6758e+00,  3.5322e+00, -8.7485e-02],\n",
      "        [ 6.9254e-01,  5.1416e+00,  8.2009e-01],\n",
      "        [ 4.9488e-01,  4.3810e+00,  1.2794e+00],\n",
      "        [-1.0310e+00,  2.3028e+00,  1.9589e-01],\n",
      "        [-3.5604e-01,  2.5790e+00,  1.2137e-01],\n",
      "        [ 4.4242e-01,  3.9051e+00,  8.8700e-01],\n",
      "        [ 2.1603e-01,  3.3027e+00, -3.8919e-01],\n",
      "        [-3.9480e-01,  2.0143e+00,  4.6719e-01],\n",
      "        [-8.6428e-02,  2.9463e+00,  1.1491e+00],\n",
      "        [ 7.8384e-01,  1.9552e+00,  2.9086e-01],\n",
      "        [ 1.1034e+00,  3.1801e+00,  1.5535e+00],\n",
      "        [ 7.7374e-01,  3.0334e+00,  1.4880e+00],\n",
      "        [ 1.4360e+00,  2.4148e+00,  8.2846e-01],\n",
      "        [ 5.9456e-01,  3.8889e+00,  1.0981e+00],\n",
      "        [-1.7314e-01,  6.0803e-01, -1.3934e-01],\n",
      "        [-7.3376e-01,  6.6945e-01, -4.7248e-01],\n",
      "        [ 4.9983e-01,  3.6225e+00, -5.7868e-01],\n",
      "        [ 1.1787e-01,  2.7781e+00, -8.4209e-01],\n",
      "        [ 4.5893e-01,  1.8184e+00,  2.5348e-01],\n",
      "        [ 6.6535e-01,  3.3130e+00, -4.5354e-01],\n",
      "        [-1.3497e-01,  3.9860e+00, -7.9580e-02],\n",
      "        [ 5.2585e-01,  1.7904e+00,  1.4865e+00],\n",
      "        [ 3.1155e-01,  1.0089e+00, -4.7823e-01],\n",
      "        [ 1.9480e+00,  1.9640e+00,  2.9791e-01],\n",
      "        [-4.0631e-03,  1.5541e+00, -5.8681e-01],\n",
      "        [-3.4589e-01,  1.1758e+00, -5.4263e-01],\n",
      "        [ 2.1658e-01,  6.0426e-01,  7.7861e-03],\n",
      "        [-1.0149e-01,  2.2983e-01, -1.7314e-01],\n",
      "        [ 4.4300e-01, -3.6079e-02,  4.5731e-01],\n",
      "        [ 1.3015e-01,  7.8376e-01, -3.0743e-01],\n",
      "        [ 3.7807e-01,  1.7649e+00,  1.9016e+00],\n",
      "        [ 6.5114e-01,  3.0743e+00,  2.4755e+00],\n",
      "        [-3.3824e-01,  2.0695e+00,  3.3818e-01],\n",
      "        [-8.0112e-01,  2.1117e+00, -7.7742e-01],\n",
      "        [ 1.0429e+00,  1.3760e+00,  1.7524e+00],\n",
      "        [ 2.8592e+00,  1.9313e+00,  1.3985e-01],\n",
      "        [ 1.7563e-01,  1.1363e+00,  3.4336e-01],\n",
      "        [-9.5650e-01, -5.5777e-01,  8.5918e-01],\n",
      "        [ 6.4244e-02,  8.8609e-01,  1.5488e+00],\n",
      "        [ 3.0172e-01,  2.4018e+00,  4.1995e-01],\n",
      "        [ 3.7807e-01,  4.2117e+00,  4.9901e-01],\n",
      "        [ 1.0239e+00,  2.9936e+00,  1.8737e+00],\n",
      "        [ 1.5720e+00,  1.0072e+00,  3.0022e-01],\n",
      "        [ 5.7234e-01,  5.6378e-01,  1.5600e-01],\n",
      "        [ 5.4916e-01,  1.6401e+00,  2.0790e-01],\n",
      "        [-2.4003e-02,  1.3778e+00,  3.2864e-01],\n",
      "        [ 1.0193e+00,  3.5503e+00,  1.8007e+00],\n",
      "        [-1.0338e-03,  2.5476e+00,  2.3723e+00],\n",
      "        [ 6.4427e-01,  3.2037e+00,  1.6131e+00],\n",
      "        [ 5.4465e-02,  6.3830e-01,  1.3398e+00],\n",
      "        [-1.9962e-01,  3.9829e-01, -3.7589e-01],\n",
      "        [ 3.8458e-01, -1.7405e-01,  1.5584e+00],\n",
      "        [ 8.8523e-01,  1.3077e+00,  7.7195e-01],\n",
      "        [ 4.9135e-01,  1.4438e+00, -1.3412e-01],\n",
      "        [ 1.0711e+00,  2.0682e+00,  1.0203e+00],\n",
      "        [ 1.8914e+00,  2.1152e+00,  2.0315e-01],\n",
      "        [ 2.5715e-01,  2.1110e+00, -4.3273e-01],\n",
      "        [ 3.3302e-01,  4.5732e+00,  4.5905e-01],\n",
      "        [ 3.9659e-01,  1.7925e+00,  1.6266e+00],\n",
      "        [ 1.1748e+00,  3.0728e+00,  7.4290e-01],\n",
      "        [ 1.4587e+00,  2.7695e+00,  3.7310e-01],\n",
      "        [ 8.3466e-01,  2.1110e+00, -6.5352e-01],\n",
      "        [ 6.8261e-01,  1.1872e-01, -8.6849e-01],\n",
      "        [-3.5806e-01, -7.5253e-01,  1.5148e+00],\n",
      "        [ 7.4188e-01, -3.8980e-01, -6.9678e-01],\n",
      "        [ 5.6156e-02,  2.3889e+00, -2.9554e-01],\n",
      "        [ 2.4711e-01,  3.9993e+00, -4.5849e-02],\n",
      "        [ 7.4095e-01,  2.4473e+00,  1.8301e+00],\n",
      "        [ 1.6288e+00,  2.7409e+00,  1.7996e+00],\n",
      "        [ 3.4288e-01,  3.5305e+00,  7.8444e-01],\n",
      "        [ 3.3647e-01,  1.8478e+00,  1.6473e+00],\n",
      "        [-1.0149e-01,  4.0987e+00,  1.4057e+00],\n",
      "        [-4.1726e-01,  3.0784e+00,  1.4718e+00],\n",
      "        [ 8.2804e-01,  2.7659e+00,  2.1479e+00],\n",
      "        [-5.3857e-02,  8.1011e-01, -5.0291e-01],\n",
      "        [ 3.2997e-01,  4.4009e-01,  6.9846e-01],\n",
      "        [ 2.5360e-01,  4.0919e-01,  6.6463e-01],\n",
      "        [ 6.3741e-01,  5.3159e+00,  2.1770e+00],\n",
      "        [ 8.4171e-01,  3.1885e+00,  3.0629e+00],\n",
      "        [ 4.8365e-01,  3.1580e+00,  2.4416e-02],\n",
      "        [ 4.4592e-01,  7.6647e-01, -4.1536e-01],\n",
      "        [ 4.6023e-01,  3.1847e-01, -1.3116e-01],\n",
      "        [-4.3138e-01,  2.1244e+00,  1.7412e+00],\n",
      "        [ 1.0542e+00,  7.0181e-01, -1.8280e-01],\n",
      "        [-6.3700e-02,  5.1349e-01,  3.3818e-01],\n",
      "        [ 1.6201e+00,  4.4155e-01,  1.3881e+00],\n",
      "        [ 1.7373e+00,  3.0221e+00,  2.0866e+00],\n",
      "        [ 2.3060e-01,  3.3270e+00,  1.9608e+00],\n",
      "        [-2.5465e-01,  2.0408e+00,  9.9663e-01],\n",
      "        [ 2.2142e+00,  2.1954e+00, -1.0170e+00],\n",
      "        [-2.4228e-01,  4.5222e-01, -1.3719e+00],\n",
      "        [ 2.3656e-01,  7.9674e-01, -2.0351e-01],\n",
      "        [-8.2742e-01, -3.5529e-01, -4.2938e-01],\n",
      "        [ 3.2365e-01,  1.7277e+00,  2.5969e+00],\n",
      "        [ 1.4045e+00,  8.5836e-01,  2.2373e+00],\n",
      "        [ 5.6942e-01,  2.4830e+00,  3.8565e-01],\n",
      "        [ 1.7965e-01,  1.9359e+00,  8.2076e-01],\n",
      "        [-1.2078e-01,  1.3343e+00,  2.4252e-02],\n",
      "        [-6.7611e-01,  3.5253e-01, -3.2211e-01],\n",
      "        [-3.8779e-01,  1.1103e-01, -1.0946e+00],\n",
      "        [-3.5929e-01, -2.7297e-01, -8.8267e-01],\n",
      "        [ 9.2747e-01,  8.5260e-02, -3.0541e-01],\n",
      "        [-1.7646e-01,  1.5777e+00,  9.2608e-01],\n",
      "        [-1.0782e+00,  1.1710e+00,  1.2718e-01],\n",
      "        [ 7.7069e-02,  2.2879e+00,  4.3788e-01],\n",
      "        [ 9.7352e-01,  3.4098e+00, -1.4999e-01],\n",
      "        [-4.4828e-01,  1.7517e+00,  7.1348e-01],\n",
      "        [ 6.3323e-01,  9.9146e-01,  4.0638e-01],\n",
      "        [ 8.6085e-01,  8.2663e-01,  4.7379e-01],\n",
      "        [ 9.5731e-01, -7.8290e-01,  8.0473e-01],\n",
      "        [ 1.9245e-01, -2.8484e-01,  1.4122e+00],\n",
      "        [ 1.1604e+00, -4.7881e-02,  1.2753e+00],\n",
      "        [-3.1115e-01,  9.2134e-01, -4.9958e-01],\n",
      "        [-5.7852e-01,  2.8131e-01, -1.1540e+00],\n",
      "        [ 1.8330e-05,  1.2937e+00, -4.5513e-01],\n",
      "        [ 7.0073e-01,  2.5136e+00, -6.8038e-01],\n",
      "        [-3.1746e-01,  8.6205e-01, -4.6935e-01],\n",
      "        [-7.1983e-02,  1.4253e+00,  2.1377e-01],\n",
      "        [ 3.0971e-01,  1.3043e+00, -9.6602e-01],\n",
      "        [ 3.8298e-01,  9.1343e-01, -7.1734e-01],\n",
      "        [-3.8008e-01,  1.7043e+00,  5.5562e-01],\n",
      "        [ 2.6772e-01,  9.6976e-01, -7.3825e-01],\n",
      "        [-3.8264e-01,  1.7607e+00, -3.8894e-01],\n",
      "        [ 7.8961e-01,  3.7824e+00,  2.6493e+00],\n",
      "        [ 1.7237e+00,  3.1994e+00,  6.2437e-01],\n",
      "        [-3.0812e-01, -1.7507e-02,  4.9578e-01],\n",
      "        [-6.2397e-01, -5.8710e-01,  9.6027e-01],\n",
      "        [-1.0149e-01, -1.1930e+00, -6.7326e-01],\n",
      "        [-1.0149e-01,  3.0031e-01,  1.2968e-01],\n",
      "        [-2.1706e-02,  2.8875e-02,  1.3654e-01],\n",
      "        [ 1.1737e+00,  2.8013e+00,  5.9907e-01],\n",
      "        [ 6.0512e-01,  4.6595e-01,  1.0346e+00],\n",
      "        [ 8.4722e-01,  1.6023e+00,  7.6728e-01],\n",
      "        [ 9.1468e-01,  1.5554e+00,  2.2425e-01],\n",
      "        [ 4.6525e-02,  1.8557e+00, -5.6959e-02],\n",
      "        [ 3.8458e-01,  1.8546e+00, -5.5145e-01],\n",
      "        [ 1.5652e+00,  1.6828e+00,  1.5113e+00],\n",
      "        [ 5.9356e-01,  2.1110e+00,  8.7712e-01],\n",
      "        [ 3.4570e-01,  2.4330e+00,  7.5181e-01],\n",
      "        [-4.8676e-01,  1.8100e+00,  1.2813e+00],\n",
      "        [-4.3290e-01,  2.0911e+00,  8.6114e-01],\n",
      "        [ 3.0293e-01,  2.2594e-01,  1.7277e-01],\n",
      "        [ 5.4192e-01,  2.3126e+00,  3.6378e-01],\n",
      "        [ 8.0920e-01,  8.5520e-01, -4.1738e-01],\n",
      "        [-2.5026e-01,  2.1023e+00,  8.2747e-01],\n",
      "        [ 3.7554e-01,  2.2976e+00,  2.7642e+00],\n",
      "        [ 1.4106e+00,  1.7572e+00,  1.0827e+00],\n",
      "        [ 1.5652e+00,  1.1410e+00,  1.1712e-01],\n",
      "        [ 8.0920e-01,  1.0115e+00, -5.7897e-01],\n",
      "        [ 5.8532e-01,  2.0695e+00, -1.0786e+00],\n",
      "        [ 3.7554e-01,  3.1118e+00, -1.7184e-01],\n",
      "        [-4.5433e-01,  6.9947e-01, -9.2500e-02],\n",
      "        [-4.4192e-01,  3.0091e-01,  2.4050e-01],\n",
      "        [-4.7268e-01,  2.1191e+00, -2.1835e-01],\n",
      "        [ 1.1840e-01,  2.0760e+00, -1.4865e-01],\n",
      "        [ 1.5139e+00,  1.3484e+00,  1.4475e+00],\n",
      "        [-1.4972e-01,  9.7527e-01, -1.0001e+00],\n",
      "        [ 8.0420e-01,  1.6312e+00,  1.0330e+00],\n",
      "        [ 3.6089e-01,  1.1051e+00,  1.6593e+00],\n",
      "        [ 2.2010e-01,  1.7464e+00, -5.7759e-01],\n",
      "        [-1.0946e+00, -1.5718e-01, -1.3600e+00],\n",
      "        [-4.2258e-01,  4.3463e-02, -3.8493e-01],\n",
      "        [ 7.0184e-01,  4.6869e-01,  1.2731e+00],\n",
      "        [-4.1768e-01,  1.0014e+00, -1.3587e-01],\n",
      "        [ 1.5665e+00,  3.5125e+00, -3.5443e-01],\n",
      "        [-3.3330e-01,  3.3375e+00, -9.7978e-01],\n",
      "        [ 7.9304e-01,  2.4793e+00, -3.9904e-01],\n",
      "        [-7.3426e-01,  2.3956e+00,  1.1463e+00],\n",
      "        [-4.0128e-01,  1.3387e+00, -6.3314e-01],\n",
      "        [ 6.1951e-01,  1.3750e+00, -5.1863e-02],\n",
      "        [ 7.5438e-01,  2.4898e+00, -3.4510e-02],\n",
      "        [ 7.1318e-01,  2.6499e+00,  7.2950e-01],\n",
      "        [ 1.0157e+00,  2.6702e+00,  1.5698e+00],\n",
      "        [-6.5177e-01,  8.1863e-01, -5.4392e-01],\n",
      "        [ 1.3744e+00,  5.0750e+00, -2.5489e-01],\n",
      "        [ 6.3964e-01,  3.3995e+00,  5.9772e-01],\n",
      "        [-3.8340e-02,  1.0972e+00, -1.6774e-01],\n",
      "        [ 1.2384e+00,  3.1118e+00,  1.0234e+00],\n",
      "        [-1.6677e-01,  2.3596e+00, -3.7526e-01],\n",
      "        [ 2.9646e-01,  8.6094e-01, -7.4256e-02],\n",
      "        [-2.0895e-01, -1.3362e-02, -6.3153e-01],\n",
      "        [-5.9801e-01,  9.4627e-01, -4.9789e-01],\n",
      "        [ 1.5395e+00, -2.7885e-01,  1.2895e+00],\n",
      "        [ 3.5483e-01, -3.7225e-01, -3.3054e-01],\n",
      "        [-1.7356e-01, -8.4979e-01,  1.5952e+00],\n",
      "        [ 1.1247e+00,  8.6401e-01,  4.8183e-01],\n",
      "        [-1.3719e-01, -1.3468e-01, -1.2942e+00],\n",
      "        [ 2.2567e-01,  9.9990e-01,  1.1039e-01],\n",
      "        [ 5.8955e-01,  2.9330e+00,  1.4057e+00],\n",
      "        [ 7.9349e-01,  2.0806e+00,  1.2864e+00],\n",
      "        [-6.7819e-01,  1.3103e+00, -8.9753e-01],\n",
      "        [-4.2988e-01,  1.3077e+00,  1.5148e+00],\n",
      "        [ 7.9907e-01,  2.8013e+00,  5.7628e-01],\n",
      "        [ 2.0284e-01,  1.6112e+00,  2.0835e+00],\n",
      "        [ 6.2944e-01,  3.2189e-01, -1.7468e-01],\n",
      "        [-4.0945e-01, -8.0664e-01, -9.5142e-01],\n",
      "        [ 7.5093e-01,  3.4144e-02,  1.3100e+00],\n",
      "        [-1.0878e+00, -1.5648e-01, -1.3229e+00],\n",
      "        [-4.2760e-01, -1.6954e-01, -9.0939e-01],\n",
      "        [-9.4678e-01, -8.6278e-01, -7.0794e-01],\n",
      "        [-4.5086e-01,  1.2058e+00, -7.5714e-01],\n",
      "        [ 4.9195e-01, -1.2598e-01,  6.1908e-01],\n",
      "        [-5.6324e-01,  2.5047e-01,  6.4086e-01],\n",
      "        [ 8.2804e-01,  2.1519e+00,  5.7044e-01],\n",
      "        [ 5.0997e-01, -1.9222e-01, -1.0599e+00],\n",
      "        [ 1.1524e+00,  6.2697e-01,  1.8029e-01],\n",
      "        [-9.5638e-01,  3.0476e-01, -1.2589e+00],\n",
      "        [-1.4146e-01,  1.3902e-01,  4.0776e-01],\n",
      "        [ 1.1644e+00,  4.5841e-01, -7.3830e-01],\n",
      "        [-2.7038e-01,  4.5289e-01,  5.6479e-01],\n",
      "        [ 5.9523e-02, -4.4901e-02,  9.0939e-02],\n",
      "        [ 4.1849e-01,  2.6477e+00,  9.1449e-01],\n",
      "        [ 3.5010e-01,  2.6318e+00,  1.6266e+00],\n",
      "        [ 1.7965e-01,  2.0655e+00,  1.7370e-01],\n",
      "        [ 4.6540e-01,  2.1571e+00,  9.2419e-01],\n",
      "        [ 5.8407e-01,  1.5122e+00,  1.1921e+00],\n",
      "        [-1.0149e-01, -6.2101e-01,  8.4020e-01],\n",
      "        [-1.8675e-01,  1.9037e-01,  4.2511e-01],\n",
      "        [-1.1576e+00, -9.4260e-01, -1.2324e+00],\n",
      "        [-2.8176e-01,  8.6579e-01, -3.5354e-01],\n",
      "        [-1.1786e+00,  1.0718e+00, -8.0280e-01],\n",
      "        [-2.9829e-01,  1.2636e+00,  1.1199e-01],\n",
      "        [-2.2679e-02,  1.2467e+00,  8.9371e-01],\n",
      "        [ 6.5114e-01,  9.4745e-01,  5.7428e-01],\n",
      "        [-3.9142e-01, -6.9933e-02, -3.1235e-01],\n",
      "        [-2.8879e-02,  1.2367e-01, -7.8823e-02],\n",
      "        [ 4.0975e-01,  1.1770e+00,  1.4117e-01],\n",
      "        [ 6.3168e-01,  2.2420e+00,  4.0873e-01],\n",
      "        [-7.7645e-02,  1.8056e+00,  1.5980e+00],\n",
      "        [ 3.2695e-01,  3.3375e+00,  2.0092e+00],\n",
      "        [ 8.6818e-01,  1.5760e+00,  1.7933e+00],\n",
      "        [ 6.1951e-01,  1.9235e+00,  1.3597e+00],\n",
      "        [ 2.1974e+00,  1.9571e+00,  3.0277e+00],\n",
      "        [ 4.9673e-01,  7.6321e-01,  2.1037e+00],\n",
      "        [ 3.9659e-01,  1.1492e+00,  3.0998e+00],\n",
      "        [ 9.2171e-01,  1.7904e+00,  1.6087e+00],\n",
      "        [-4.0435e-01,  1.6220e+00,  1.0696e+00]]) tensor([1.]) 300 torch.Size([300, 3]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for x, y in custom_non_overlap_train_dataset_samp_en:\n",
    "    print(x, y, x.size(0), x.size(), y.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9341a7ea",
   "metadata": {},
   "source": [
    "We now create a DataLoader object that wraps an iterable around the Dataset to enable easy access to the samples. The DataLoader features will have shape [batch_size, sub_seq_length, num_features] and the target will have shape [batch_size, num_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "29a11cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please note that the batch_size must be <= len(data) / sub_seq_length. Otherwise there are too few\n",
    "# datapoints to fit in the number of batches. \n",
    "custom_train_loader_samp_en = DataLoader(custom_non_overlap_train_dataset_samp_en, batch_size=60, shuffle=False, drop_last=False)\n",
    "custom_val_loader_samp_en = DataLoader(custom_non_overlap_val_dataset_samp_en, batch_size=60, shuffle=False, drop_last=False)\n",
    "custom_test_loader_samp_en = DataLoader(custom_non_overlap_test_dataset_samp_en, batch_size=60, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46050715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 300, 3]) torch.Size([60, 1])\n",
      "tensor([[[ 0.8752,  1.0989,  0.9847],\n",
      "         [ 0.2954,  0.8019,  0.7257],\n",
      "         [-0.1015,  1.0733,  0.7607],\n",
      "         ...,\n",
      "         [ 0.3966,  1.1492,  3.0998],\n",
      "         [ 0.9217,  1.7904,  1.6087],\n",
      "         [-0.4044,  1.6220,  1.0696]],\n",
      "\n",
      "        [[-1.2115, -0.2973, -1.2732],\n",
      "         [-1.0736, -0.9817, -0.1031],\n",
      "         [-1.0836, -0.3317, -0.9351],\n",
      "         ...,\n",
      "         [-0.4124, -0.3853, -0.1770],\n",
      "         [-0.4601, -0.3748, -0.9102],\n",
      "         [-0.5674, -1.2809, -0.5285]],\n",
      "\n",
      "        [[ 0.5397,  1.1785, -0.0350],\n",
      "         [ 0.0944,  0.5565, -0.1753],\n",
      "         [-0.6740, -0.4093, -1.3311],\n",
      "         ...,\n",
      "         [-0.8605,  0.7911, -0.4700],\n",
      "         [-0.5140,  0.8533, -0.1321],\n",
      "         [-0.4316,  0.9651,  0.1690]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7898, -0.8127,  0.2798],\n",
      "         [ 0.0971,  1.2197,  0.1232],\n",
      "         [ 0.8104,  1.7329,  0.6948],\n",
      "         ...,\n",
      "         [-0.7345,  0.6438,  0.1104],\n",
      "         [ 0.4236,  1.1677,  0.2498],\n",
      "         [ 1.6586,  0.4590,  1.8395]],\n",
      "\n",
      "        [[ 0.0322,  0.2194, -0.1220],\n",
      "         [ 1.0326,  0.1549,  0.3039],\n",
      "         [ 0.1832, -0.5811,  0.0518],\n",
      "         ...,\n",
      "         [ 0.3501, -0.1313,  0.3099],\n",
      "         [ 0.0360, -0.8651, -0.4820],\n",
      "         [ 1.9805, -0.6118,  1.0106]],\n",
      "\n",
      "        [[ 0.1410,  2.1487,  1.2616],\n",
      "         [ 0.0488,  2.8489,  0.5034],\n",
      "         [-0.7499,  1.4933,  0.6157],\n",
      "         ...,\n",
      "         [ 0.3854,  1.4167,  0.0236],\n",
      "         [ 0.0732, -0.5955,  0.7720],\n",
      "         [ 1.3023,  0.5313,  1.1126]]]) tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "for index, (data, target) in enumerate(custom_train_loader_samp_en):\n",
    "    print(data.shape, target.shape)\n",
    "    print(data, target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b35449d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(custom_val_loader_samp_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d662720",
   "metadata": {},
   "source": [
    "## Standard LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0417a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://towardsdatascience.com/building-rnn-lstm-and-gru-for-time-series-using-pytorch-a46e5b094e7b\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob, device):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        # Defining the number of layers and the nodes in each layer\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        # LSTM layers\n",
    "        # batch first: If True, then the input and output tensors are provided as (batch, seq_len, n_features) instead of \n",
    "        # (seq_len, batch, n_features). Note that this does not apply to hidden or cell states.\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
    "        )\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Each time the forward pass is applied, the hidden cells and states are initialized on zeros. Meaning\n",
    "        # that if you call model(x) in each mini-batch, the states and cells are initialized on zeros. We use\n",
    "        # this for our case when the batches are independent of each other (a stateless LSTM model)\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device=self.device).requires_grad_()\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device=self.device).requires_grad_()\n",
    "\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        # Forward propagation by passing in the input, hidden state, and cell state into the model\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Decode the hidden state of the last time step. The output shape will be [batch_size, output_dim]. We only\n",
    "        # want to know the hidden state of the last time step, as we're only interested in computing the loss after\n",
    "        # the entire sequence length has been processed. \n",
    "        out = self.fc(out[:, -1, :]) \n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "02e3c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Save the best model while training. If the current epoch's \n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "    def __init__(self, best_valid_loss=float('inf')):\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        \n",
    "    def __call__(self, current_valid_loss, epoch, model, optimizer, criterion, output_path, file_name_output):\n",
    "        if current_valid_loss < self.best_valid_loss:\n",
    "            self.best_valid_loss = current_valid_loss\n",
    "            print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
    "            print(f\"\\nSaving best model for epoch: {epoch}\\n\")\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "                }, f'{output_path}/{file_name_output}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d0c6a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizationLSTM:\n",
    "    \"\"\"Train, optimize and evaluate a LSTM model. Batches are processed independent of each other, meaning that the \n",
    "    hidden cells and states are resetted to zero after each batch has been processed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        LSTM model with specified input_dim, hidden_dim, output_dim, batch_size, device, layer_dim, batch_first.\n",
    "    loss_fn : torch.nn.modules.loss\n",
    "        Loss function\n",
    "    optimizer : torch.optim\n",
    "        Optimizer function.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.save_best_model = SaveBestModel()\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_predictions = []\n",
    "        self.val_predictions = []\n",
    "        self.test_predictions = []\n",
    "        self.train_probabilities = []\n",
    "        self.val_probabilities = []\n",
    "        self.test_probabilities = []\n",
    "        self.train_labels = []\n",
    "        self.val_labels = []\n",
    "        self.test_labels = []\n",
    "        \n",
    "    def get_predictions_binary_model(self, y_pred, train, val, test):\n",
    "        \"\"\"Get the predictions and probabilities for the train/val/test batch\"\"\"\n",
    "        assert self.check_if_only_one_boolean(train, val, test), f\"You can only be in either one of train/val/test mode, you are now in {len([var for var in [train, val, test] if var==True])} modes\"\n",
    "        # Calculate the probabilities from the raw logits\n",
    "        output_prob = torch.sigmoid(y_pred)\n",
    "        \n",
    "        # removes the 1th dimension with a max, which is the classification layer\n",
    "        # which means it returns the most likely label. Also, note you need to choose .indices since \n",
    "        # you want to return the position of where the most likely label is (not it's raw logit value)\n",
    "        pred = output_prob.max(1).indices\n",
    "        \n",
    "        # Data is first moved to cpu and then converted to numpy array\n",
    "        if train:\n",
    "            self.train_predictions.append(pred.cpu().data.numpy())\n",
    "            self.train_probabilities.append(output_prob.cpu().data.numpy())\n",
    "        elif val:\n",
    "            self.val_predictions.append(pred.cpu().data.numpy())\n",
    "            self.val_probabilities.append(output_prob.cpu().data.numpy())\n",
    "        elif test:\n",
    "            self.test_predictions.append(pred.cpu().data.numpy())\n",
    "            self.test_probabilities.append(output_prob.cpu().data.numpy())\n",
    "            \n",
    "    def check_if_only_one_boolean(self, *args):\n",
    "        \"\"\"Method to check if only one variable in a list of variables has a True value.\n",
    "        Since Booleans are a subtype of plain integers, you can sum the list of integers \n",
    "        quite easily and you can also pass true booleans into this function as well.\n",
    "        \"\"\"\n",
    "        return sum(args) == 1\n",
    "    \n",
    "    def train_step(self, x, y):\n",
    "        \"\"\"Returns loss and prediction.\"\"\"\n",
    "        # Sets model to train mode\n",
    "        self.model.train()\n",
    "        \n",
    "        # Zeroes gradients\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        y_pred = self.model(x)\n",
    "\n",
    "        # Computes loss (input for BCEwithlogits loss should be (prediction, true label))\n",
    "        loss = self.loss_fn(y_pred, y)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updates parameters \n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss, y_pred\n",
    "    \n",
    "    def train(self, train_loader, val_loader, batch_size=60, n_epochs=50):\n",
    "        output_path = file_paths['output_path'] + \"/\" + \"model\"\n",
    "        \n",
    "        current_date_and_time = \"{:%Y-%m-%d_%H-%M}\".format(datetime.datetime.now())\n",
    "        file_name_output = f'{current_date_and_time}_best_model_stateless'\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            total_train_loss_epoch = 0.0\n",
    "            total_samples = 0\n",
    "            for t, (x_batch, y_batch) in enumerate(train_loader):                \n",
    "                    \n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                # avg_train_batch_loss contains the value of the average cost of all the training examples of the current batch\n",
    "                avg_train_batch_loss, y_pred = self.train_step(x_batch, y_batch)\n",
    "                \n",
    "                self.train_labels.append(y_batch.cpu().data.numpy())\n",
    "                \n",
    "                self.get_predictions_binary_model(y_pred, train=True, val=False, test=False)\n",
    "          \n",
    "                # total_train_loss_epoch accumelates the total loss per train batch for each entire epoch\n",
    "                total_train_loss_epoch += (avg_train_batch_loss.item()*x_batch.size(0))\n",
    "                            \n",
    "            # Calculate average sample train loss for this particular epoch.\n",
    "            avg_sample_train_loss_epoch = total_train_loss_epoch / len(train_loader.sampler)\n",
    "            self.train_losses.append(avg_sample_train_loss_epoch)\n",
    "\n",
    "            self.train_labels.clear()\n",
    "            self.train_probabilities.clear()\n",
    "            self.train_predictions.clear()\n",
    "             \n",
    "            self.model.eval()     \n",
    "            with torch.no_grad():\n",
    "                total_val_loss_epoch = 0.0\n",
    "                correct_val, total_samples_val = 0, 0\n",
    "                for t, (x_val, y_val) in enumerate(val_loader):\n",
    "                    x_val = x_val.to(device)\n",
    "                    y_val = y_val.to(device)   \n",
    "                        \n",
    "                    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                    y_pred = self.model(x_val) # output shape is [batch_size, 1] and contains logits\n",
    "                    \n",
    "                    self.get_predictions_binary_model(y_pred, train=False, val=True, test=False)\n",
    "                    self.val_labels.append(y_val.cpu().data.numpy())\n",
    "            \n",
    "                    # TO DO: Find out if all samples are used for training/validating (i.e., are the last samples\n",
    "                    # that may not fit into a full batch now disregarded?)\n",
    "                    total_samples_val += y_val.size(0)\n",
    "                                        \n",
    "                    avg_val_batch_loss = self.loss_fn(y_pred, y_val)\n",
    "                    # total_val_loss_epoch accumelates the total loss per validation batch for the entire epoch -> total loss per epoch\n",
    "                    # update running training loss\n",
    "                    total_val_loss_epoch += (avg_val_batch_loss.item()*x_val.size(0))\n",
    "                    \n",
    "                # Calculate average sample validation loss for this particular epoch.\n",
    "                avg_sample_val_loss_epoch = total_val_loss_epoch / len(val_loader.sampler)\n",
    "                self.val_losses.append(avg_sample_val_loss_epoch)\n",
    "                                \n",
    "                self.val_labels.clear()\n",
    "                self.val_probabilities.clear()\n",
    "                self.val_predictions.clear()\n",
    "                \n",
    "                self.save_best_model(avg_sample_val_loss_epoch, epoch, self.model, self.optimizer, \n",
    "                                     self.loss_fn, output_path, file_name_output)         \n",
    "\n",
    "            print(f\"Epoch [{epoch}/{n_epochs}] Training loss: {avg_sample_train_loss_epoch:.10f}\\t Validation loss: {avg_sample_val_loss_epoch:.10f}\"\n",
    "                )\n",
    "            print('-'*50)\n",
    "            \n",
    "        self.save_loss_plot(current_date_and_time)\n",
    "        print('TRAINING COMPLETE')\n",
    "        \n",
    "    def evaluate(self, test_loader, checkpoint, batch_size=60):\n",
    "        model_epoch = checkpoint['epoch']\n",
    "        print(f\"Model was saved at {model_epoch} epochs\\n\")\n",
    "        \n",
    "        print(f'Loading at epoch {model_epoch} saved model weights...')\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct_test = 0\n",
    "            for x_test, y_test in test_loader:\n",
    "                x_test = x_test.to(device)\n",
    "                y_test = y_test.to(device)\n",
    "                \n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                y_pred = self.model(x_test) # output shape is [batch_size, 1] and contains logits\n",
    "                \n",
    "                self.get_predictions_binary_model(y_pred, train=False, val=False, test=True)\n",
    "                self.test_labels.append(y_test.cpu().data.numpy())\n",
    "                self.test_labels = list(np.array(self.test_labels, dtype=np.int64).flat)\n",
    "                self.test_predictions = list(np.array(self.test_predictions, dtype=np.int64).flat)\n",
    "\n",
    "                num_correct_batch = np.sum((self.test_predictions == y_test.view(1, -1)))\n",
    "                print(num_correct_batch)\n",
    "                \n",
    "                correct_test += num_correct_batch\n",
    "                precision_test, recall_test, _ = precision_recall_curve(list(np.array(self.test_labels).flat), \n",
    "                                                                        list(np.array(self.test_probabilities).flat))\n",
    "                self.plot_prec_recall_curve(recall_test, precision_test)\n",
    "\n",
    "                print(precision_score(self.test_labels, self.test_predictions))\n",
    "                print(recall_score(self.test_labels, self.test_predictions))\n",
    "                print(f1_score(self.test_labels, self.test_predictions))\n",
    "                # We clear the list with the predictions for the next batch which contains the sequences of new rec ids\n",
    "                self.test_labels.clear()\n",
    "                self.test_probabilities.clear()\n",
    "                self.test_predictions.clear()  \n",
    "                \n",
    "    \n",
    "    def save_loss_plot(self, current_date_and_time):\n",
    "        \"\"\"\n",
    "        Function to save the loss plot to disk.\n",
    "        \"\"\"\n",
    "        output_path = file_paths['output_path'] + \"/\" + \"model\"\n",
    "        file_name_output = f'{current_date_and_time}_loss.png'\n",
    "        \n",
    "        # loss plot\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.plot(\n",
    "            self.train_losses, color='orange', linestyle='-', \n",
    "            label='Train loss'\n",
    "        )\n",
    "        plt.plot(\n",
    "            self.val_losses, color='red', linestyle='-', \n",
    "            label='Validation loss'\n",
    "        )\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'{output_path}/{file_name_output}')\n",
    "        \n",
    "        \n",
    "    def plot_prec_recall_curve(self, recall, precision):\n",
    "        plt.plot(recall, precision, marker='.', label='Test set')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "61d3370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2861a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(features_to_use)\n",
    "output_dim = 1\n",
    "hidden_dim = 2\n",
    "layer_dim = 3\n",
    "batch_size = 60\n",
    "dropout = 0.2\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-6\n",
    "\n",
    "model_params = {'input_dim': input_dim,\n",
    "                'hidden_dim' : hidden_dim,\n",
    "                'layer_dim' : layer_dim,\n",
    "                'output_dim' : output_dim,\n",
    "                'dropout_prob' : dropout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "11b66157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(3, 2, num_layers=3, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm = LSTMModel(input_dim=input_dim, hidden_dim=hidden_dim, layer_dim=layer_dim, output_dim=output_dim, dropout_prob=dropout, device=device)\n",
    "model_lstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4a5f0ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loss combines a Sigmoid layer and the BCELoss in one single class. This version is more numerically stable than \n",
    "# using a plain Sigmoid followed by a BCELoss as, by combining the operations into one layer, we take advantage of the \n",
    "# log-sum-exp trick for numerical stability. Source: https://discuss.pytorch.org/t/bceloss-vs-bcewithlogitsloss/33586 \n",
    "# and https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.Adam(model_lstm.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    " \n",
    "opt_lstm = OptimizationLSTM(model=model_lstm, loss_fn=loss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4cafefd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best validation loss: 0.8683673739433289\n",
      "\n",
      "Saving best model for epoch: 1\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [1/50] Training loss: 0.8659276565\t Validation loss: 0.8683673739\n",
      "\n",
      "Best validation loss: 0.8649910092353821\n",
      "\n",
      "Saving best model for epoch: 2\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [2/50] Training loss: 0.8629748821\t Validation loss: 0.8649910092\n",
      "\n",
      "Best validation loss: 0.8616164922714233\n",
      "\n",
      "Saving best model for epoch: 3\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [3/50] Training loss: 0.8594251871\t Validation loss: 0.8616164923\n",
      "\n",
      "Best validation loss: 0.8582260012626648\n",
      "\n",
      "Saving best model for epoch: 4\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [4/50] Training loss: 0.8562313517\t Validation loss: 0.8582260013\n",
      "\n",
      "Best validation loss: 0.8548048138618469\n",
      "\n",
      "Saving best model for epoch: 5\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [5/50] Training loss: 0.8528413574\t Validation loss: 0.8548048139\n",
      "\n",
      "Best validation loss: 0.8513489961624146\n",
      "\n",
      "Saving best model for epoch: 6\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [6/50] Training loss: 0.8496667941\t Validation loss: 0.8513489962\n",
      "\n",
      "Best validation loss: 0.8478530645370483\n",
      "\n",
      "Saving best model for epoch: 7\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [7/50] Training loss: 0.8461450537\t Validation loss: 0.8478530645\n",
      "\n",
      "Best validation loss: 0.8443170189857483\n",
      "\n",
      "Saving best model for epoch: 8\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [8/50] Training loss: 0.8428794146\t Validation loss: 0.8443170190\n",
      "\n",
      "Best validation loss: 0.8407353758811951\n",
      "\n",
      "Saving best model for epoch: 9\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [9/50] Training loss: 0.8393067519\t Validation loss: 0.8407353759\n",
      "\n",
      "Best validation loss: 0.8371056318283081\n",
      "\n",
      "Saving best model for epoch: 10\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [10/50] Training loss: 0.8360303243\t Validation loss: 0.8371056318\n",
      "\n",
      "Best validation loss: 0.8334260582923889\n",
      "\n",
      "Saving best model for epoch: 11\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [11/50] Training loss: 0.8326123754\t Validation loss: 0.8334260583\n",
      "\n",
      "Best validation loss: 0.8296880125999451\n",
      "\n",
      "Saving best model for epoch: 12\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [12/50] Training loss: 0.8287065427\t Validation loss: 0.8296880126\n",
      "\n",
      "Best validation loss: 0.8258867263793945\n",
      "\n",
      "Saving best model for epoch: 13\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [13/50] Training loss: 0.8250390291\t Validation loss: 0.8258867264\n",
      "\n",
      "Best validation loss: 0.8220187425613403\n",
      "\n",
      "Saving best model for epoch: 14\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [14/50] Training loss: 0.8213528792\t Validation loss: 0.8220187426\n",
      "\n",
      "Best validation loss: 0.8180763125419617\n",
      "\n",
      "Saving best model for epoch: 15\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [15/50] Training loss: 0.8176756104\t Validation loss: 0.8180763125\n",
      "\n",
      "Best validation loss: 0.814056932926178\n",
      "\n",
      "Saving best model for epoch: 16\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [16/50] Training loss: 0.8137251933\t Validation loss: 0.8140569329\n",
      "\n",
      "Best validation loss: 0.8099536895751953\n",
      "\n",
      "Saving best model for epoch: 17\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [17/50] Training loss: 0.8098019163\t Validation loss: 0.8099536896\n",
      "\n",
      "Best validation loss: 0.805762529373169\n",
      "\n",
      "Saving best model for epoch: 18\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [18/50] Training loss: 0.8055479725\t Validation loss: 0.8057625294\n",
      "\n",
      "Best validation loss: 0.8014821410179138\n",
      "\n",
      "Saving best model for epoch: 19\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [19/50] Training loss: 0.8012239536\t Validation loss: 0.8014821410\n",
      "\n",
      "Best validation loss: 0.7971150875091553\n",
      "\n",
      "Saving best model for epoch: 20\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [20/50] Training loss: 0.7976788878\t Validation loss: 0.7971150875\n",
      "\n",
      "Best validation loss: 0.7926661372184753\n",
      "\n",
      "Saving best model for epoch: 21\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [21/50] Training loss: 0.7934409777\t Validation loss: 0.7926661372\n",
      "\n",
      "Best validation loss: 0.7881383895874023\n",
      "\n",
      "Saving best model for epoch: 22\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [22/50] Training loss: 0.7893493970\t Validation loss: 0.7881383896\n",
      "\n",
      "Best validation loss: 0.7835381031036377\n",
      "\n",
      "Saving best model for epoch: 23\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [23/50] Training loss: 0.7849527001\t Validation loss: 0.7835381031\n",
      "\n",
      "Best validation loss: 0.7788767218589783\n",
      "\n",
      "Saving best model for epoch: 24\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [24/50] Training loss: 0.7811143994\t Validation loss: 0.7788767219\n",
      "\n",
      "Best validation loss: 0.7741572260856628\n",
      "\n",
      "Saving best model for epoch: 25\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [25/50] Training loss: 0.7759613991\t Validation loss: 0.7741572261\n",
      "\n",
      "Best validation loss: 0.7693876028060913\n",
      "\n",
      "Saving best model for epoch: 26\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [26/50] Training loss: 0.7714025378\t Validation loss: 0.7693876028\n",
      "\n",
      "Best validation loss: 0.7645778656005859\n",
      "\n",
      "Saving best model for epoch: 27\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [27/50] Training loss: 0.7670268814\t Validation loss: 0.7645778656\n",
      "\n",
      "Best validation loss: 0.7597401738166809\n",
      "\n",
      "Saving best model for epoch: 28\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [28/50] Training loss: 0.7617260814\t Validation loss: 0.7597401738\n",
      "\n",
      "Best validation loss: 0.7548847198486328\n",
      "\n",
      "Saving best model for epoch: 29\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [29/50] Training loss: 0.7575895588\t Validation loss: 0.7548847198\n",
      "\n",
      "Best validation loss: 0.7500218749046326\n",
      "\n",
      "Saving best model for epoch: 30\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [30/50] Training loss: 0.7521169384\t Validation loss: 0.7500218749\n",
      "\n",
      "Best validation loss: 0.7451642751693726\n",
      "\n",
      "Saving best model for epoch: 31\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [31/50] Training loss: 0.7478728493\t Validation loss: 0.7451642752\n",
      "\n",
      "Best validation loss: 0.7403217554092407\n",
      "\n",
      "Saving best model for epoch: 32\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [32/50] Training loss: 0.7425031463\t Validation loss: 0.7403217554\n",
      "\n",
      "Best validation loss: 0.7355124950408936\n",
      "\n",
      "Saving best model for epoch: 33\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [33/50] Training loss: 0.7392429312\t Validation loss: 0.7355124950\n",
      "\n",
      "Best validation loss: 0.7307282090187073\n",
      "\n",
      "Saving best model for epoch: 34\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [34/50] Training loss: 0.7332653999\t Validation loss: 0.7307282090\n",
      "\n",
      "Best validation loss: 0.725975751876831\n",
      "\n",
      "Saving best model for epoch: 35\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [35/50] Training loss: 0.7284834782\t Validation loss: 0.7259757519\n",
      "\n",
      "Best validation loss: 0.7212621569633484\n",
      "\n",
      "Saving best model for epoch: 36\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [36/50] Training loss: 0.7240528067\t Validation loss: 0.7212621570\n",
      "\n",
      "Best validation loss: 0.716593325138092\n",
      "\n",
      "Saving best model for epoch: 37\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [37/50] Training loss: 0.7199861407\t Validation loss: 0.7165933251\n",
      "\n",
      "Best validation loss: 0.7119722366333008\n",
      "\n",
      "Saving best model for epoch: 38\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [38/50] Training loss: 0.7147313952\t Validation loss: 0.7119722366\n",
      "\n",
      "Best validation loss: 0.7073991894721985\n",
      "\n",
      "Saving best model for epoch: 39\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [39/50] Training loss: 0.7104118466\t Validation loss: 0.7073991895\n",
      "\n",
      "Best validation loss: 0.7028773427009583\n",
      "\n",
      "Saving best model for epoch: 40\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [40/50] Training loss: 0.7066616019\t Validation loss: 0.7028773427\n",
      "\n",
      "Best validation loss: 0.6984092593193054\n",
      "\n",
      "Saving best model for epoch: 41\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [41/50] Training loss: 0.7022540967\t Validation loss: 0.6984092593\n",
      "\n",
      "Best validation loss: 0.6939912438392639\n",
      "\n",
      "Saving best model for epoch: 42\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [42/50] Training loss: 0.6978575985\t Validation loss: 0.6939912438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best validation loss: 0.689622163772583\n",
      "\n",
      "Saving best model for epoch: 43\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [43/50] Training loss: 0.6939869523\t Validation loss: 0.6896221638\n",
      "\n",
      "Best validation loss: 0.6853016018867493\n",
      "\n",
      "Saving best model for epoch: 44\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [44/50] Training loss: 0.6898592909\t Validation loss: 0.6853016019\n",
      "\n",
      "Best validation loss: 0.6810179948806763\n",
      "\n",
      "Saving best model for epoch: 45\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [45/50] Training loss: 0.6837748090\t Validation loss: 0.6810179949\n",
      "\n",
      "Best validation loss: 0.6767712831497192\n",
      "\n",
      "Saving best model for epoch: 46\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [46/50] Training loss: 0.6801934640\t Validation loss: 0.6767712831\n",
      "\n",
      "Best validation loss: 0.6725593209266663\n",
      "\n",
      "Saving best model for epoch: 47\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [47/50] Training loss: 0.6753889918\t Validation loss: 0.6725593209\n",
      "\n",
      "Best validation loss: 0.6683863401412964\n",
      "\n",
      "Saving best model for epoch: 48\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [48/50] Training loss: 0.6720606089\t Validation loss: 0.6683863401\n",
      "\n",
      "Best validation loss: 0.6642493009567261\n",
      "\n",
      "Saving best model for epoch: 49\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [49/50] Training loss: 0.6690323949\t Validation loss: 0.6642493010\n",
      "\n",
      "Best validation loss: 0.6601476073265076\n",
      "\n",
      "Saving best model for epoch: 50\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [50/50] Training loss: 0.6648841500\t Validation loss: 0.6601476073\n",
      "TRAINING COMPLETE\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt_lstm.train(custom_train_loader_samp_en, custom_val_loader_samp_en, batch_size=60, n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e5ed4df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model checkpoint\n",
    "best_model_cp = torch.load('/Users/AFischer/Documents/PhD_onderzoek/term_preterm_database/output/model/2022-01-12_14-28_best_model_stateless.pth', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5d018c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was saved at 50 epochs\n",
      "\n",
      "Loading at epoch 50 saved model weights...\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt_lstm.evaluate(custom_test_loader_samp_en, best_model_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7748e121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(custom_train_loader_samp_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0c1422",
   "metadata": {},
   "source": [
    "## This part is with the original signal data (so not subsampled to a fixed time window by using a feature such as sample entropy). The original signal data will be used to apply a stateful LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "985f42e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These dfs contain the original signal data\n",
    "X_train_orig = df_signals[df_signals['rec_id'].isin(X_train['rec_id'].unique())].reset_index(drop=True)\n",
    "X_val_orig = df_signals[df_signals['rec_id'].isin(X_val['rec_id'].unique())].reset_index(drop=True)\n",
    "X_test_orig = df_signals[df_signals['rec_id'].isin(X_test['rec_id'].unique())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "26be35f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>channel_1</th>\n",
       "      <th>channel_1_filt_0.08_4_hz</th>\n",
       "      <th>channel_1_filt_0.3_3_hz</th>\n",
       "      <th>channel_1_filt_0.3_4_hz</th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_2_filt_0.08_4_hz</th>\n",
       "      <th>channel_2_filt_0.3_3_hz</th>\n",
       "      <th>channel_2_filt_0.3_4_hz</th>\n",
       "      <th>channel_3</th>\n",
       "      <th>channel_3_filt_0.08_4_hz</th>\n",
       "      <th>channel_3_filt_0.3_3_hz</th>\n",
       "      <th>channel_3_filt_0.3_4_hz</th>\n",
       "      <th>premature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.009279</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>-0.013733</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.007248</td>\n",
       "      <td>-0.001619</td>\n",
       "      <td>-0.001963</td>\n",
       "      <td>-0.001452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.008443</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>0.003158</td>\n",
       "      <td>-0.011292</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.001984</td>\n",
       "      <td>-0.001667</td>\n",
       "      <td>-0.001687</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1391</td>\n",
       "      <td>-0.003052</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>-0.016175</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>-0.009689</td>\n",
       "      <td>-0.001785</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1391</td>\n",
       "      <td>-0.000610</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>-0.001391</td>\n",
       "      <td>-0.013733</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.000704</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1391</td>\n",
       "      <td>-0.007935</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>-0.003590</td>\n",
       "      <td>-0.003500</td>\n",
       "      <td>-0.013733</td>\n",
       "      <td>-0.000657</td>\n",
       "      <td>-0.001069</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.002365</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id  channel_1  channel_1_filt_0.08_4_hz  channel_1_filt_0.3_3_hz  \\\n",
       "0    1391   0.001755                  0.009279                 0.004092   \n",
       "1    1391   0.001755                  0.008443                 0.002888   \n",
       "2    1391  -0.003052                  0.006425                 0.000974   \n",
       "3    1391  -0.000610                  0.003946                -0.001363   \n",
       "4    1391  -0.007935                  0.001862                -0.003590   \n",
       "\n",
       "   channel_1_filt_0.3_4_hz  channel_2  channel_2_filt_0.08_4_hz  \\\n",
       "0                 0.004034  -0.013733                  0.000247   \n",
       "1                 0.003158  -0.011292                  0.000195   \n",
       "2                 0.001114  -0.016175                  0.000300   \n",
       "3                -0.001391  -0.013733                  0.000270   \n",
       "4                -0.003500  -0.013733                 -0.000657   \n",
       "\n",
       "   channel_2_filt_0.3_3_hz  channel_2_filt_0.3_4_hz  channel_3  \\\n",
       "0                 0.000299                -0.000061  -0.007248   \n",
       "1                 0.000392                 0.000072  -0.004807   \n",
       "2                 0.000461                 0.000411  -0.009689   \n",
       "3                 0.000038                 0.000586  -0.004807   \n",
       "4                -0.001069                -0.000200  -0.002365   \n",
       "\n",
       "   channel_3_filt_0.08_4_hz  channel_3_filt_0.3_3_hz  channel_3_filt_0.3_4_hz  \\\n",
       "0                 -0.001619                -0.001963                -0.001452   \n",
       "1                 -0.001984                -0.001667                -0.001687   \n",
       "2                 -0.001785                -0.000909                -0.001365   \n",
       "3                 -0.000704                 0.000281                -0.000165   \n",
       "4                  0.000707                 0.001519                 0.001390   \n",
       "\n",
       "   premature  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b0e352cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to re-do this step because the X dataframes now contain the label column\n",
    "X_train_orig, y_train_orig = feature_label_split(X_train_orig, 'premature')\n",
    "X_val_orig, y_val_orig = feature_label_split(X_val_orig, 'premature')\n",
    "X_test_orig, y_test_orig = feature_label_split(X_test_orig, 'premature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a7f46b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>channel_1</th>\n",
       "      <th>channel_1_filt_0.08_4_hz</th>\n",
       "      <th>channel_1_filt_0.3_3_hz</th>\n",
       "      <th>channel_1_filt_0.3_4_hz</th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_2_filt_0.08_4_hz</th>\n",
       "      <th>channel_2_filt_0.3_3_hz</th>\n",
       "      <th>channel_2_filt_0.3_4_hz</th>\n",
       "      <th>channel_3</th>\n",
       "      <th>channel_3_filt_0.08_4_hz</th>\n",
       "      <th>channel_3_filt_0.3_3_hz</th>\n",
       "      <th>channel_3_filt_0.3_4_hz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>994</td>\n",
       "      <td>-0.035019</td>\n",
       "      <td>-0.003428</td>\n",
       "      <td>-0.002109</td>\n",
       "      <td>-0.000978</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>-0.007157</td>\n",
       "      <td>-0.002977</td>\n",
       "      <td>-0.004307</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>0.006553</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>0.003759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>994</td>\n",
       "      <td>-0.034028</td>\n",
       "      <td>-0.002367</td>\n",
       "      <td>-0.001257</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>-0.003695</td>\n",
       "      <td>-0.000839</td>\n",
       "      <td>-0.000757</td>\n",
       "      <td>-0.002060</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.001947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>994</td>\n",
       "      <td>-0.030823</td>\n",
       "      <td>-0.002894</td>\n",
       "      <td>-0.000811</td>\n",
       "      <td>-0.000526</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>-0.000878</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>-0.007019</td>\n",
       "      <td>0.004438</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>0.001772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>994</td>\n",
       "      <td>-0.035096</td>\n",
       "      <td>-0.003996</td>\n",
       "      <td>-0.000510</td>\n",
       "      <td>-0.001657</td>\n",
       "      <td>0.009461</td>\n",
       "      <td>-0.000874</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>-0.003052</td>\n",
       "      <td>0.005055</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.002464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>994</td>\n",
       "      <td>-0.035859</td>\n",
       "      <td>-0.003816</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.001451</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>-0.003356</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>-0.002060</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.002188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id  channel_1  channel_1_filt_0.08_4_hz  channel_1_filt_0.3_3_hz  \\\n",
       "0     994  -0.035019                 -0.003428                -0.002109   \n",
       "1     994  -0.034028                 -0.002367                -0.001257   \n",
       "2     994  -0.030823                 -0.002894                -0.000811   \n",
       "3     994  -0.035096                 -0.003996                -0.000510   \n",
       "4     994  -0.035859                 -0.003816                 0.000029   \n",
       "\n",
       "   channel_1_filt_0.3_4_hz  channel_2  channel_2_filt_0.08_4_hz  \\\n",
       "0                -0.000978   0.002365                 -0.007157   \n",
       "1                 0.000072   0.002213                 -0.003695   \n",
       "2                -0.000526   0.011749                 -0.000878   \n",
       "3                -0.001657   0.009461                 -0.000874   \n",
       "4                -0.001451   0.002594                 -0.003356   \n",
       "\n",
       "   channel_2_filt_0.3_3_hz  channel_2_filt_0.3_4_hz  channel_3  \\\n",
       "0                -0.002977                -0.004307  -0.000153   \n",
       "1                -0.000839                -0.000757  -0.002060   \n",
       "2                 0.000699                 0.002106  -0.007019   \n",
       "3                 0.000882                 0.002140  -0.003052   \n",
       "4                -0.000264                -0.000337  -0.002060   \n",
       "\n",
       "   channel_3_filt_0.08_4_hz  channel_3_filt_0.3_3_hz  channel_3_filt_0.3_4_hz  \n",
       "0                  0.006553                 0.004693                 0.003759  \n",
       "1                  0.004715                 0.003288                 0.001947  \n",
       "2                  0.004438                 0.002372                 0.001772  \n",
       "3                  0.005055                 0.001710                 0.002464  \n",
       "4                  0.004739                 0.000765                 0.002188  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0503113d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>channel_1</th>\n",
       "      <th>channel_1_filt_0.08_4_hz</th>\n",
       "      <th>channel_1_filt_0.3_3_hz</th>\n",
       "      <th>channel_1_filt_0.3_4_hz</th>\n",
       "      <th>channel_2</th>\n",
       "      <th>channel_2_filt_0.08_4_hz</th>\n",
       "      <th>channel_2_filt_0.3_3_hz</th>\n",
       "      <th>channel_2_filt_0.3_4_hz</th>\n",
       "      <th>channel_3</th>\n",
       "      <th>channel_3_filt_0.08_4_hz</th>\n",
       "      <th>channel_3_filt_0.3_3_hz</th>\n",
       "      <th>channel_3_filt_0.3_4_hz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1360</td>\n",
       "      <td>0.077287</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.013886</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.029984</td>\n",
       "      <td>0.017581</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>0.003868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1360</td>\n",
       "      <td>0.069963</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.013886</td>\n",
       "      <td>-0.001802</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>0.029984</td>\n",
       "      <td>0.017962</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.003761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1360</td>\n",
       "      <td>0.067521</td>\n",
       "      <td>-0.002995</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.011444</td>\n",
       "      <td>-0.003028</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.031205</td>\n",
       "      <td>0.017446</td>\n",
       "      <td>0.003747</td>\n",
       "      <td>0.002775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1360</td>\n",
       "      <td>0.063859</td>\n",
       "      <td>-0.007752</td>\n",
       "      <td>-0.003233</td>\n",
       "      <td>-0.001042</td>\n",
       "      <td>0.009003</td>\n",
       "      <td>-0.005502</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.029984</td>\n",
       "      <td>0.018288</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.003260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1360</td>\n",
       "      <td>0.060197</td>\n",
       "      <td>-0.015740</td>\n",
       "      <td>-0.008818</td>\n",
       "      <td>-0.007265</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>-0.009993</td>\n",
       "      <td>-0.002890</td>\n",
       "      <td>-0.002218</td>\n",
       "      <td>0.029984</td>\n",
       "      <td>0.021409</td>\n",
       "      <td>0.006599</td>\n",
       "      <td>0.006117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id  channel_1  channel_1_filt_0.08_4_hz  channel_1_filt_0.3_3_hz  \\\n",
       "0    1360   0.077287                  0.002264                 0.004072   \n",
       "1    1360   0.069963                 -0.000254                 0.004077   \n",
       "2    1360   0.067521                 -0.002995                 0.001570   \n",
       "3    1360   0.063859                 -0.007752                -0.003233   \n",
       "4    1360   0.060197                 -0.015740                -0.008818   \n",
       "\n",
       "   channel_1_filt_0.3_4_hz  channel_2  channel_2_filt_0.08_4_hz  \\\n",
       "0                 0.003000   0.013886                 -0.000301   \n",
       "1                 0.002491   0.013886                 -0.001802   \n",
       "2                 0.001788   0.011444                 -0.003028   \n",
       "3                -0.001042   0.009003                 -0.005502   \n",
       "4                -0.007265   0.007782                 -0.009993   \n",
       "\n",
       "   channel_2_filt_0.3_3_hz  channel_2_filt_0.3_4_hz  channel_3  \\\n",
       "0                 0.003945                 0.003083   0.029984   \n",
       "1                 0.003762                 0.002739   0.029984   \n",
       "2                 0.002444                 0.002674   0.031205   \n",
       "3                 0.000026                 0.001292   0.029984   \n",
       "4                -0.002890                -0.002218   0.029984   \n",
       "\n",
       "   channel_3_filt_0.08_4_hz  channel_3_filt_0.3_3_hz  channel_3_filt_0.3_4_hz  \n",
       "0                  0.017581                 0.002339                 0.003868  \n",
       "1                  0.017962                 0.002863                 0.003761  \n",
       "2                  0.017446                 0.003747                 0.002775  \n",
       "3                  0.018288                 0.005110                 0.003260  \n",
       "4                  0.021409                 0.006599                 0.006117  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "22c142ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names_signal = ['channel_1', 'channel_1_filt_0.08_4_hz', 'channel_1_filt_0.3_3_hz', 'channel_1_filt_0.3_4_hz', \n",
    "                           'channel_2', 'channel_2_filt_0.08_4_hz', 'channel_2_filt_0.3_3_hz', 'channel_2_filt_0.3_4_hz', \n",
    "                           'channel_3', 'channel_3_filt_0.08_4_hz', 'channel_3_filt_0.3_3_hz', 'channel_3_filt_0.3_4_hz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a8f7c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = ['channel_1_filt_0.08_4_hz', 'channel_2_filt_0.08_4_hz', 'channel_3_filt_0.08_4_hz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fa72bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't want to have the rec_ids scaled\n",
    "preprocessor_features = ColumnTransformer(\n",
    "        remainder='drop', #passthough features not listed\n",
    "        transformers=[\n",
    "            ('standard', StandardScaler(), features_to_use)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f02497aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_arr_orig = preprocessor_features.fit_transform(X_train_orig)\n",
    "X_val_arr_orig = preprocessor_features.transform(X_val_orig)\n",
    "X_test_arr_orig = preprocessor_features.transform(X_test_orig)\n",
    "\n",
    "y_train_arr_orig = lb.fit_transform(y_train_orig['premature'])\n",
    "y_val_arr_orig = lb.transform(y_val_orig['premature'])\n",
    "y_test_arr_orig = lb.transform(y_test_orig['premature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb71d449",
   "metadata": {},
   "source": [
    "We will use X_train_scaled to verify our results later on (after we've padded/truncataed the sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2c8f9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_orig = pd.concat([X_train_orig['rec_id'], pd.DataFrame(X_train_arr_orig, columns=features_to_use)], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "16a494fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>channel_1_filt_0.08_4_hz</th>\n",
       "      <th>channel_2_filt_0.08_4_hz</th>\n",
       "      <th>channel_3_filt_0.08_4_hz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.552213</td>\n",
       "      <td>0.015928</td>\n",
       "      <td>-0.140085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.502509</td>\n",
       "      <td>0.012555</td>\n",
       "      <td>-0.171734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.382372</td>\n",
       "      <td>0.019323</td>\n",
       "      <td>-0.154522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.234830</td>\n",
       "      <td>0.017416</td>\n",
       "      <td>-0.060888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.110796</td>\n",
       "      <td>-0.042276</td>\n",
       "      <td>0.061204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id  channel_1_filt_0.08_4_hz  channel_2_filt_0.08_4_hz  \\\n",
       "0    1391                  0.552213                  0.015928   \n",
       "1    1391                  0.502509                  0.012555   \n",
       "2    1391                  0.382372                  0.019323   \n",
       "3    1391                  0.234830                  0.017416   \n",
       "4    1391                  0.110796                 -0.042276   \n",
       "\n",
       "   channel_3_filt_0.08_4_hz  \n",
       "0                 -0.140085  \n",
       "1                 -0.171734  \n",
       "2                 -0.154522  \n",
       "3                 -0.060888  \n",
       "4                  0.061204  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled_orig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7002e5",
   "metadata": {},
   "source": [
    "We pad/truncate the sequence of each rec_id to length fixed_seq_length (this is set at 28800 time steps). \n",
    "Padding must be done AFTER scaling the features, otherwise the zeros will be taken into account when scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "63ff23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_arr_padded_orig, y_train_arr_padded_orig = pad_sequences_to_fixed_length(X_train_orig, X_train_arr_orig, \n",
    "                                                                                 y_train_arr_orig, \n",
    "                                                                                 num_features=len(features_to_use), \n",
    "                                                                                 fixed_seq_length=28800)\n",
    "X_val_arr_padded_orig, y_val_arr_padded_orig = pad_sequences_to_fixed_length(X_val_orig, X_val_arr_orig, \n",
    "                                                                             y_val_arr_orig,  \n",
    "                                                                             num_features=len(features_to_use), \n",
    "                                                                             fixed_seq_length=28800) \n",
    "X_test_arr_padded_orig, y_test_arr_padded_orig = pad_sequences_to_fixed_length(X_test_orig, X_test_arr_orig, \n",
    "                                                                               y_test_arr_orig, \n",
    "                                                                               num_features=len(features_to_use), \n",
    "                                                                               fixed_seq_length=28800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7708acb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create df_final to later on to check if the output of custom_sort_for_stateful_lstm is correct\n",
    "df_final_orig = pad_sequences_to_fixed_length_df(X_train_scaled_orig, num_features=len(features_to_use), fixed_seq_length=28800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "883d017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_orig['time_step'] = df_final_orig.groupby('rec_id').cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "87e2cbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>channel_1_filt_0.08_4_hz</th>\n",
       "      <th>channel_2_filt_0.08_4_hz</th>\n",
       "      <th>channel_3_filt_0.08_4_hz</th>\n",
       "      <th>time_step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.552213</td>\n",
       "      <td>0.015928</td>\n",
       "      <td>-0.140085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.502509</td>\n",
       "      <td>0.012555</td>\n",
       "      <td>-0.171734</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.382372</td>\n",
       "      <td>0.019323</td>\n",
       "      <td>-0.154522</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.234830</td>\n",
       "      <td>0.017416</td>\n",
       "      <td>-0.060888</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1391</td>\n",
       "      <td>0.110796</td>\n",
       "      <td>-0.042276</td>\n",
       "      <td>0.061204</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id  channel_1_filt_0.08_4_hz  channel_2_filt_0.08_4_hz  \\\n",
       "0    1391                  0.552213                  0.015928   \n",
       "1    1391                  0.502509                  0.012555   \n",
       "2    1391                  0.382372                  0.019323   \n",
       "3    1391                  0.234830                  0.017416   \n",
       "4    1391                  0.110796                 -0.042276   \n",
       "\n",
       "   channel_3_filt_0.08_4_hz  time_step  \n",
       "0                 -0.140085          0  \n",
       "1                 -0.171734          1  \n",
       "2                 -0.154522          2  \n",
       "3                 -0.060888          3  \n",
       "4                  0.061204          4  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_orig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc8af7d",
   "metadata": {},
   "source": [
    "We custom sort x_arr_padded and y_arr_padded such that we can correctly batchify the data using the DataLoader class.\n",
    "\n",
    "In this function, we sort the x_arr_padded and y_arr_padded in such way that we take a batch (60 in our case) of rec_ids \n",
    "and take the first sub_seq_length (200) time steps for the first rec id, then the first sub_seq_length time steps for the second rec id, ..., the last sub_seq_length time steps of the last rec_id (of the first batch of 60 rec ids). After that, we move on to the next batch of 60 rec ids and we take the first sub_seq_length time steps of rec id 61, etc.\n",
    "\n",
    "In the end, we want to have our data in the following form: \n",
    "\n",
    "There are 180 rec ids in X_train, each rec id consisting of 28800 time steps. As we want to feed the data to a stateful LSTM model, we need to ensure that we correctly batchify our data. Stateful means that the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch:\n",
    "\n",
    "    batch1 = [sample10, sample20, sample30, sample40]\n",
    "    batch2 = [sample11, sample21, sample31, sample41]\n",
    "    \n",
    "In the case of X_train this means that our batches will have the form as we sketched below. With $P$ being the rec id and $\\textit{t}$ the timestep. In total, X_train will be batched into 432 batches, with 144 batches needed to finish an entire sequence. As we put 60 rec ids in one batch, the first 144 batches will be dedicated to the first 60 rec ids, the second 144 batches will be dedicated to rec id 61-120 and the last 144 batches will be dedicated to rec id 121-180.\n",
    "\n",
    "The same procedure will be repeated for X_val and X_test and as they both contain only 60 rec ids, they both need 144 batches to process their rec ids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c16ebe9",
   "metadata": {},
   "source": [
    "$$B_{1} = \\begin{pmatrix} P_{1}, t_{0} & P_{1}, t_{1} & P_{1}, t_{2} & ... & P_{1}, t_{198} & P_{1}, t_{199} \\\\ P_{2}, t_{0} & P_{2}, t_{1} & P_{2}, t_{2} & ... & P_{2}, t_{198} & P_{2}, t_{199} \\\\ ... & ... & ... & ... & ... & ... \\\\ P_{59}, t_{0} & P_{59}, t_{1} & P_{59}, t_{2} & ... & P_{59}, t_{198} & P_{59}, t_{199} \\\\ P_{60}, t_{0} & P_{60}, t_{1} & P_{60}, t_{2} & ... & P_{60}, t_{198} & P_{60}, t_{199} \\end{pmatrix}$$\n",
    "\n",
    "$$B_{2} = \\begin{pmatrix} P_{1}, t_{200} & P_{1}, t_{201} & P_{1}, t_{202} & ... & P_{1}, t_{398} & P_{1}, t_{399} \\\\ P_{2}, t_{200} & P_{2}, t_{201} & P_{2}, t_{202} & ... & P_{2}, t_{398} & P_{2}, t_{399} \\\\ ... & ... & ... & ... & ... & ... \\\\  P_{59}, t_{200} & P_{59}, t_{201} & P_{59}, t_{202} & ... & P_{59}, t_{398} & P_{59}, t_{399} \\\\P_{60}, t_{200} & P_{60}, t_{201} & P_{60}, t_{202} & ... & P_{60}, t_{398} & P_{60}, t_{399} \\end{pmatrix}$$\n",
    "\n",
    "$$\\begin{pmatrix} ... \\end{pmatrix}$$\n",
    "\n",
    "$$B_{144} = \\begin{pmatrix} P_{1}, t_{28600} & P_{1}, t_{28601} & P_{1}, t_{28602} & ... & P_{1}, t_{28798} & P_{1}, t_{28799} \\\\ P_{2}, t_{28600} & P_{2}, t_{28601} & P_{2}, t_{28602} & ... & P_{2}, t_{28798} & P_{2}, t_{28799} \\\\ ... & ... & ... & ... & ... & ... \\\\  P_{59}, t_{28600} & P_{59}, t_{28601} & P_{59}, t_{28602} & ... & P_{59}, t_{28798} & P_{59}, t_{28799}\\\\P_{60}, t_{28600} & P_{60}, t_{28601} & P_{60}, t_{28602} & ... & P_{60}, t_{28798} & P_{60}, t_{28799} \\end{pmatrix}$$\n",
    "\n",
    "$$B_{145} = \\begin{pmatrix} P_{61}, t_{0} & P_{61}, t_{1} & P_{61}, t_{2} & ... & P_{61}, t_{198} & P_{61}, t_{199} \\\\ P_{62}, t_{0} & P_{62}, t_{1} & P_{62}, t_{2} & ... & P_{62}, t_{198} & P_{62}, t_{199} \\\\ ... & ... & ... & ... & ... & ... \\\\ P_{119}, t_{0} & P_{119}, t_{1} & P_{119}, t_{2} & ... & P_{119}, t_{198} & P_{119}, t_{199} \\\\ P_{120}, t_{0} & P_{120}, t_{1} & P_{120}, t_{2} & ... & P_{120}, t_{198} & P_{120}, t_{199} \\end{pmatrix}$$\n",
    "\n",
    "$$\\begin{pmatrix} ... \\end{pmatrix}$$\n",
    "\n",
    "$$B_{288} = \\begin{pmatrix} P_{61}, t_{28600} & P_{61}, t_{28601} & P_{61}, t_{28602} & ... & P_{61}, t_{28798} & P_{61}, t_{28799} \\\\ P_{62}, t_{28600} & P_{62}, t_{28601} & P_{62}, t_{28602} & ... & P_{62}, t_{28798} & P_{62}, t_{28799} \\\\ ... & ... & ... & ... & ... & ... \\\\  P_{119}, t_{28600} & P_{119}, t_{28601} & P_{119}, t_{28602} & ... & P_{119}, t_{28798} & P_{119}, t_{28799}\\\\P_{120}, t_{28600} & P_{120}, t_{28601} & P_{120}, t_{28602} & ... & P_{120}, t_{28798} & P_{120}, t_{28799} \\end{pmatrix}$$\n",
    "\n",
    "$$B_{289} = \\begin{pmatrix} P_{121}, t_{0} & P_{121}, t_{1} & P_{121}, t_{2} & ... & P_{121}, t_{198} & P_{121}, t_{199} \\\\ P_{122}, t_{0} & P_{122}, t_{1} & P_{122}, t_{2} & ... & P_{122}, t_{198} & P_{122}, t_{199} \\\\ ... & ... & ... & ... & ... & ... \\\\ P_{179}, t_{0} & P_{179}, t_{1} & P_{179}, t_{2} & ... & P_{179}, t_{198} & P_{179}, t_{199} \\\\ P_{180}, t_{0} & P_{180}, t_{1} & P_{180}, t_{2} & ... & P_{180}, t_{198} & P_{180}, t_{199} \\end{pmatrix}$$\n",
    "\n",
    "$$\\begin{pmatrix} ... \\end{pmatrix}$$\n",
    "\n",
    "$$B_{432} = \\begin{pmatrix} P_{121}, t_{28600} & P_{121}, t_{28601} & P_{121}, t_{28602} & ... & P_{121}, t_{28798} & P_{121}, t_{28799} \\\\ P_{122}, t_{28600} & P_{122}, t_{28601} & P_{122}, t_{28602} & ... & P_{122}, t_{28798} & P_{122}, t_{28799} \\\\ ... & ... & ... & ... & ... & ... \\\\  P_{179}, t_{28600} & P_{179}, t_{28601} & P_{179}, t_{28602} & ... & P_{179}, t_{28798} & P_{179}, t_{28799}\\\\P_{180}, t_{28600} & P_{180}, t_{28601} & P_{180}, t_{28602} & ... & P_{180}, t_{28798} & P_{180}, t_{28799} \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b8cad27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_arr_padded_sorted_orig, y_train_arr_padded_sorted_orig = custom_sort_for_stateful_lstm(X_train_orig, \n",
    "                                                                                               X_train_arr_padded_orig, \n",
    "                                                                                               y_train_arr_padded_orig, \n",
    "                                                                                               fixed_seq_length=28800, \n",
    "                                                                                               sub_seq_length=200, \n",
    "                                                                                               batch_size=60, \n",
    "                                                                                               num_features=len(features_to_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cc2d7646",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_arr_padded_sorted_orig, y_val_arr_padded_sorted_orig = custom_sort_for_stateful_lstm(X_val_orig, \n",
    "                                                                                           X_val_arr_padded_orig, \n",
    "                                                                                           y_val_arr_padded_orig, \n",
    "                                                                                           fixed_seq_length=28800, \n",
    "                                                                                           sub_seq_length=200, \n",
    "                                                                                           batch_size=60, \n",
    "                                                                                           num_features=len(features_to_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "87a93609",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_arr_padded_sorted_orig, y_test_arr_padded_sorted_orig = custom_sort_for_stateful_lstm(X_test_orig, \n",
    "                                                                                             X_test_arr_padded_orig, \n",
    "                                                                                             y_test_arr_padded_orig, \n",
    "                                                                                             fixed_seq_length=28800, \n",
    "                                                                                             sub_seq_length=200, \n",
    "                                                                                             batch_size=60, \n",
    "                                                                                             num_features=len(features_to_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "357017ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create this df to quickly check whether our results from the custom sort function are correct.\n",
    "df1 = df_final_orig[(df_final_orig['rec_id'].isin(df_final_orig['rec_id'].unique()[0:60])) & (df_final_orig['time_step']<200)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "224cadb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to test whether the custom sorted data is correctly sorted.\n",
    "assert_frame_equal(df1[features_to_use], pd.DataFrame(X_train_arr_padded_sorted_orig[0:12000], columns=features_to_use), check_dtype=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "71cb8ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_final_orig, df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f911594d",
   "metadata": {},
   "source": [
    "Create tensors of the X and y data. BCEWithLogitsLoss requires its target to be a float tensor, not long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7ed60180",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_orig = torch.from_numpy(X_train_arr_padded_sorted_orig)\n",
    "train_targets_orig = torch.from_numpy(y_train_arr_padded_sorted_orig).float().view(-1, 1)\n",
    "val_features_orig = torch.from_numpy(X_val_arr_padded_sorted_orig)\n",
    "val_targets_orig = torch.from_numpy(y_val_arr_padded_sorted_orig).float().view(-1, 1)\n",
    "test_features_orig = torch.from_numpy(X_test_arr_padded_sorted_orig)\n",
    "test_targets_orig = torch.from_numpy(y_test_arr_padded_sorted_orig).float().view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "eb93a581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.DoubleTensor'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_orig.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8a66f73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_orig.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f46cda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class can be used to create overlapping windows!\n",
    "# class MyDataset(Dataset):\n",
    "#     def __init__(self, data, window):\n",
    "#         self.data = data\n",
    "#         self.window = window\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return self.data[index:index+self.window], self.data[index + self.window]        \n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data) - self.window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3e7f19",
   "metadata": {},
   "source": [
    "We put the features and targets in TensorDataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "30ea1d60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset_orig = TensorDataset(train_features_orig, train_targets_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a8166c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_orig = TensorDataset(val_features_orig, val_targets_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5ef84de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_orig = TensorDataset(test_features_orig, test_targets_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6fce386e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5184000, 1])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "79de9b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5522,  0.0159, -0.1401], dtype=torch.float64) torch.Size([3]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset_orig:\n",
    "    print(x, x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ee18a100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25920"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "144 * 60 + 144 * 60 + 144 * 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcf8875",
   "metadata": {},
   "source": [
    "At this moment, each time step is a separate dedicated tensor. We want to merge together the time steps in chunks of 200 time steps. The time steps in a chunk must have no overlap with other chunks.\n",
    "\n",
    "The features will have the shape [sub_seq_length (=200), num_features] and the target will have the shape [num_targets]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8af611ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom Datasets with non-overlapping sequences of length 200\n",
    "custom_non_overlap_train_dataset_orig = NonOverlappingSequencesDataset(train_dataset_orig, 200, len(features_to_use), 1, 0)\n",
    "custom_non_overlap_val_dataset_orig = NonOverlappingSequencesDataset(val_dataset_orig, 200, len(features_to_use), 1, 0)\n",
    "custom_non_overlap_test_dataset_orig = NonOverlappingSequencesDataset(test_dataset_orig, 200, len(features_to_use), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6265cb57",
   "metadata": {},
   "source": [
    "The custom_non_overlap_train_dataset will have length len(train_dataset) / sub_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cc98bbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25920"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(custom_non_overlap_train_dataset_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4d273a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.5221e-01,  1.5928e-02, -1.4009e-01],\n",
      "        [ 5.0251e-01,  1.2555e-02, -1.7173e-01],\n",
      "        [ 3.8237e-01,  1.9323e-02, -1.5452e-01],\n",
      "        [ 2.3483e-01,  1.7416e-02, -6.0888e-02],\n",
      "        [ 1.1080e-01, -4.2276e-02,  6.1204e-02],\n",
      "        [ 2.9466e-02, -1.8925e-01,  1.3345e-01],\n",
      "        [-3.5073e-03, -3.5370e-01,  1.0266e-01],\n",
      "        [ 3.4085e-02, -4.0471e-01, -4.2534e-02],\n",
      "        [ 1.5461e-01, -3.0490e-01, -2.6326e-01],\n",
      "        [ 3.0972e-01, -1.7663e-01, -4.6657e-01],\n",
      "        [ 4.0814e-01, -1.6352e-01, -5.4929e-01],\n",
      "        [ 4.0112e-01, -2.5700e-01, -4.7979e-01],\n",
      "        [ 3.3062e-01, -3.1602e-01, -3.3638e-01],\n",
      "        [ 2.8196e-01, -2.4851e-01, -2.4914e-01],\n",
      "        [ 3.0426e-01, -1.1515e-01, -2.8959e-01],\n",
      "        [ 3.8545e-01, -3.6076e-02, -4.1552e-01],\n",
      "        [ 4.8421e-01, -4.3242e-02, -5.2743e-01],\n",
      "        [ 5.6163e-01, -6.8550e-02, -5.6555e-01],\n",
      "        [ 5.8732e-01, -5.5422e-02, -5.3710e-01],\n",
      "        [ 5.4700e-01, -2.6198e-02, -4.7486e-01],\n",
      "        [ 4.6581e-01, -2.6529e-02, -4.0922e-01],\n",
      "        [ 4.0352e-01, -5.0445e-02, -3.6932e-01],\n",
      "        [ 3.8673e-01, -6.4531e-02, -3.6015e-01],\n",
      "        [ 3.5125e-01, -8.5584e-02, -3.3058e-01],\n",
      "        [ 2.0678e-01, -1.7127e-01, -2.1689e-01],\n",
      "        [-1.9350e-02, -3.1560e-01, -4.6201e-02],\n",
      "        [-1.6079e-01, -4.1427e-01,  5.1008e-02],\n",
      "        [-8.9965e-02, -3.8673e-01, -1.6771e-02],\n",
      "        [ 1.1093e-01, -2.9389e-01, -1.7110e-01],\n",
      "        [ 2.1749e-01, -2.6848e-01, -2.3388e-01],\n",
      "        [ 1.0256e-01, -3.4573e-01, -1.3077e-01],\n",
      "        [-1.3858e-01, -4.3200e-01,  2.3734e-02],\n",
      "        [-3.1204e-01, -4.4102e-01,  6.0567e-02],\n",
      "        [-3.2810e-01, -3.9264e-01, -6.0137e-02],\n",
      "        [-2.5303e-01, -3.5705e-01, -2.2505e-01],\n",
      "        [-1.9597e-01, -3.6089e-01, -3.0529e-01],\n",
      "        [-1.9568e-01, -3.8729e-01, -2.8420e-01],\n",
      "        [-2.1683e-01, -4.2685e-01, -2.4729e-01],\n",
      "        [-2.1437e-01, -4.7724e-01, -2.7182e-01],\n",
      "        [-1.8087e-01, -5.1233e-01, -3.4437e-01],\n",
      "        [-1.5256e-01, -5.0717e-01, -3.8071e-01],\n",
      "        [-1.8386e-01, -4.9474e-01, -3.1589e-01],\n",
      "        [-2.9126e-01, -5.4263e-01, -1.7953e-01],\n",
      "        [-4.0387e-01, -6.4991e-01, -8.3673e-02],\n",
      "        [-4.0094e-01, -7.1608e-01, -1.2209e-01],\n",
      "        [-2.3642e-01, -6.5829e-01, -2.7583e-01],\n",
      "        [-1.6994e-02, -5.2900e-01, -4.2541e-01],\n",
      "        [ 8.0794e-02, -4.6096e-01, -4.5414e-01],\n",
      "        [-1.3372e-02, -5.0289e-01, -3.4358e-01],\n",
      "        [-1.8865e-01, -5.6492e-01, -1.9199e-01],\n",
      "        [-2.7227e-01, -5.4001e-01, -1.3728e-01],\n",
      "        [-2.0721e-01, -4.3115e-01, -2.2664e-01],\n",
      "        [-8.2339e-02, -3.2573e-01, -3.6107e-01],\n",
      "        [ 4.9427e-04, -2.7693e-01, -4.0702e-01],\n",
      "        [ 3.9196e-02, -2.5946e-01, -3.5953e-01],\n",
      "        [ 9.4099e-02, -2.3596e-01, -3.4243e-01],\n",
      "        [ 1.8038e-01, -2.1543e-01, -4.3612e-01],\n",
      "        [ 2.4570e-01, -2.2075e-01, -5.6737e-01],\n",
      "        [ 2.5054e-01, -2.3161e-01, -6.1013e-01],\n",
      "        [ 2.2164e-01, -2.0736e-01, -5.4567e-01],\n",
      "        [ 1.9766e-01, -1.6152e-01, -4.5963e-01],\n",
      "        [ 1.5864e-01, -1.6131e-01, -4.0835e-01],\n",
      "        [ 6.6176e-02, -2.3158e-01, -3.6969e-01],\n",
      "        [-3.7700e-02, -3.0077e-01, -3.3290e-01],\n",
      "        [-4.3510e-02, -2.8284e-01, -3.5247e-01],\n",
      "        [ 8.8486e-02, -1.9163e-01, -4.6316e-01],\n",
      "        [ 2.5650e-01, -1.2628e-01, -5.9223e-01],\n",
      "        [ 3.2097e-01, -1.4483e-01, -6.1898e-01],\n",
      "        [ 2.5250e-01, -1.9904e-01, -5.1382e-01],\n",
      "        [ 1.4282e-01, -2.0951e-01, -3.7721e-01],\n",
      "        [ 8.8388e-02, -1.6546e-01, -3.3406e-01],\n",
      "        [ 1.0782e-01, -1.1956e-01, -4.1433e-01],\n",
      "        [ 1.7180e-01, -1.0839e-01, -5.4843e-01],\n",
      "        [ 2.5822e-01, -1.1662e-01, -6.5499e-01],\n",
      "        [ 3.4577e-01, -1.1681e-01, -7.0358e-01],\n",
      "        [ 3.9121e-01, -1.1100e-01, -7.0210e-01],\n",
      "        [ 3.6356e-01, -1.1769e-01, -6.6601e-01],\n",
      "        [ 2.9720e-01, -1.3441e-01, -6.2382e-01],\n",
      "        [ 2.7372e-01, -1.3357e-01, -6.2685e-01],\n",
      "        [ 3.3461e-01, -9.7870e-02, -7.0743e-01],\n",
      "        [ 4.2448e-01, -4.9661e-02, -8.1491e-01],\n",
      "        [ 4.3678e-01, -3.6997e-02, -8.2706e-01],\n",
      "        [ 3.1995e-01, -8.8422e-02, -6.6601e-01],\n",
      "        [ 1.3742e-01, -1.7985e-01, -4.0762e-01],\n",
      "        [ 1.9641e-02, -2.4813e-01, -2.3886e-01],\n",
      "        [ 4.9525e-02, -2.4587e-01, -2.7677e-01],\n",
      "        [ 1.9057e-01, -1.8793e-01, -4.4801e-01],\n",
      "        [ 3.2848e-01, -1.3975e-01, -5.7688e-01],\n",
      "        [ 3.8026e-01, -1.5364e-01, -5.7381e-01],\n",
      "        [ 3.5818e-01, -2.1042e-01, -5.0372e-01],\n",
      "        [ 3.3435e-01, -2.2649e-01, -4.7860e-01],\n",
      "        [ 3.5541e-01, -1.3036e-01, -5.1219e-01],\n",
      "        [ 3.9084e-01,  6.3582e-02, -4.8972e-01],\n",
      "        [ 3.5901e-01,  2.6765e-01, -2.8192e-01],\n",
      "        [ 2.1088e-01,  4.0928e-01,  1.0665e-01],\n",
      "        [-4.8267e-03,  4.9118e-01,  5.0813e-01],\n",
      "        [-1.6950e-01,  5.5711e-01,  7.2551e-01],\n",
      "        [-1.9881e-01,  6.1990e-01,  7.0490e-01],\n",
      "        [-1.1172e-01,  6.4869e-01,  5.7014e-01],\n",
      "        [ 9.3339e-03,  6.2303e-01,  4.8512e-01],\n",
      "        [ 1.0018e-01,  5.7164e-01,  5.0139e-01],\n",
      "        [ 1.3110e-01,  5.4280e-01,  5.6346e-01],\n",
      "        [ 7.4722e-02,  5.5279e-01,  6.3430e-01],\n",
      "        [-7.4330e-02,  5.8524e-01,  7.4219e-01],\n",
      "        [-2.3909e-01,  6.2970e-01,  8.8679e-01],\n",
      "        [-2.8844e-01,  6.8397e-01,  9.7819e-01],\n",
      "        [-1.7471e-01,  7.1826e-01,  9.4108e-01],\n",
      "        [-1.1903e-02,  6.8462e-01,  8.4693e-01],\n",
      "        [ 3.2118e-02,  5.8474e-01,  8.5917e-01],\n",
      "        [-8.1641e-02,  4.9551e-01,  1.0281e+00],\n",
      "        [-2.2002e-01,  4.9708e-01,  1.1981e+00],\n",
      "        [-2.2056e-01,  5.8732e-01,  1.1650e+00],\n",
      "        [-5.2829e-02,  6.8823e-01,  9.0150e-01],\n",
      "        [ 1.7279e-01,  7.3115e-01,  5.8245e-01],\n",
      "        [ 3.3248e-01,  7.1524e-01,  3.8717e-01],\n",
      "        [ 3.9875e-01,  6.7977e-01,  3.2414e-01],\n",
      "        [ 4.3215e-01,  6.4561e-01,  2.6698e-01],\n",
      "        [ 4.9500e-01,  6.0774e-01,  1.2274e-01],\n",
      "        [ 5.8434e-01,  5.6733e-01, -7.0032e-02],\n",
      "        [ 6.3625e-01,  5.3110e-01, -1.9319e-01],\n",
      "        [ 5.8839e-01,  4.7940e-01, -1.7455e-01],\n",
      "        [ 4.5011e-01,  3.8256e-01, -6.9226e-02],\n",
      "        [ 3.1590e-01,  2.6882e-01, -2.1719e-02],\n",
      "        [ 2.9426e-01,  2.2444e-01, -1.3231e-01],\n",
      "        [ 4.0885e-01,  2.8046e-01, -3.5186e-01],\n",
      "        [ 5.6534e-01,  3.4032e-01, -5.1025e-01],\n",
      "        [ 6.1743e-01,  2.8620e-01, -4.5077e-01],\n",
      "        [ 4.8386e-01,  1.3974e-01, -1.5811e-01],\n",
      "        [ 2.2545e-01,  4.7304e-02,  2.1305e-01],\n",
      "        [ 1.4385e-03,  1.0084e-01,  4.4740e-01],\n",
      "        [-7.5194e-02,  2.3130e-01,  4.5313e-01],\n",
      "        [-3.6744e-02,  2.9792e-01,  3.4127e-01],\n",
      "        [ 1.3219e-04,  2.4461e-01,  2.9264e-01],\n",
      "        [-2.5464e-02,  1.4465e-01,  3.5986e-01],\n",
      "        [-7.6832e-02,  1.0515e-01,  4.4374e-01],\n",
      "        [-1.0740e-01,  1.4979e-01,  4.5232e-01],\n",
      "        [-1.3152e-01,  2.1128e-01,  4.1749e-01],\n",
      "        [-1.8190e-01,  2.3247e-01,  4.3069e-01],\n",
      "        [-2.4774e-01,  2.3291e-01,  5.1801e-01],\n",
      "        [-3.0889e-01,  2.4783e-01,  6.3592e-01],\n",
      "        [-3.9851e-01,  2.4713e-01,  7.6040e-01],\n",
      "        [-5.5616e-01,  1.8129e-01,  8.9462e-01],\n",
      "        [-7.1607e-01,  8.7927e-02,  9.8304e-01],\n",
      "        [-7.2213e-01,  6.8497e-02,  9.2017e-01],\n",
      "        [-5.0561e-01,  1.4252e-01,  7.0137e-01],\n",
      "        [-2.0694e-01,  2.0140e-01,  4.8890e-01],\n",
      "        [-5.6514e-02,  1.4955e-01,  4.4782e-01],\n",
      "        [-1.3876e-01,  3.5960e-02,  5.5304e-01],\n",
      "        [-3.2858e-01, -1.1743e-02,  6.3483e-01],\n",
      "        [-4.6280e-01,  4.4316e-02,  5.9737e-01],\n",
      "        [-5.0359e-01,  1.1208e-01,  5.1171e-01],\n",
      "        [-5.0417e-01,  9.9860e-02,  4.8321e-01],\n",
      "        [-4.9172e-01,  3.2892e-02,  5.1106e-01],\n",
      "        [-4.6073e-01,  5.7294e-03,  5.3157e-01],\n",
      "        [-4.4470e-01,  4.8019e-02,  5.4167e-01],\n",
      "        [-5.0311e-01,  9.3209e-02,  5.9443e-01],\n",
      "        [-6.2205e-01,  8.2228e-02,  6.8120e-01],\n",
      "        [-6.9892e-01,  3.7406e-02,  7.0717e-01],\n",
      "        [-6.7326e-01,  3.5873e-03,  6.2511e-01],\n",
      "        [-6.2851e-01, -3.1324e-02,  5.3262e-01],\n",
      "        [-6.9684e-01, -1.0437e-01,  5.7036e-01],\n",
      "        [-8.7621e-01, -1.9574e-01,  7.4009e-01],\n",
      "        [-1.0132e+00, -2.3723e-01,  8.7988e-01],\n",
      "        [-9.8479e-01, -1.9961e-01,  8.3577e-01],\n",
      "        [-8.3754e-01, -1.2809e-01,  6.2894e-01],\n",
      "        [-7.1283e-01, -8.3530e-02,  4.3231e-01],\n",
      "        [-6.8277e-01, -8.3081e-02,  3.9295e-01],\n",
      "        [-7.1028e-01, -1.1076e-01,  4.9333e-01],\n",
      "        [-7.3901e-01, -1.5344e-01,  5.8661e-01],\n",
      "        [-7.5354e-01, -1.9739e-01,  5.5512e-01],\n",
      "        [-7.4201e-01, -2.0727e-01,  4.1567e-01],\n",
      "        [-6.6462e-01, -1.4981e-01,  2.6703e-01],\n",
      "        [-5.0859e-01, -4.5667e-02,  1.7078e-01],\n",
      "        [-3.4137e-01,  3.5594e-02,  1.1892e-01],\n",
      "        [-2.5276e-01,  4.8971e-02,  8.8998e-02],\n",
      "        [-2.5198e-01,  1.8334e-02,  6.9853e-02],\n",
      "        [-2.6304e-01, -7.8971e-03,  3.2447e-02],\n",
      "        [-2.1563e-01, -1.5707e-02, -6.2076e-02],\n",
      "        [-1.0838e-01, -1.4107e-02, -1.9309e-01],\n",
      "        [ 4.6043e-03,  4.3537e-03, -2.6088e-01],\n",
      "        [ 5.5052e-02,  4.6684e-02, -1.8310e-01],\n",
      "        [ 2.2640e-03,  7.7382e-02, -1.5870e-03],\n",
      "        [-1.2308e-01,  4.6237e-02,  1.4174e-01],\n",
      "        [-2.1606e-01, -3.3821e-02,  1.4351e-01],\n",
      "        [-1.7801e-01, -8.4775e-02,  3.4717e-02],\n",
      "        [-1.9668e-02, -6.3569e-02, -6.7589e-02],\n",
      "        [ 1.3009e-01, -2.5039e-02, -8.0801e-02],\n",
      "        [ 1.3815e-01, -4.7992e-02, -1.7449e-02],\n",
      "        [ 4.3984e-04, -1.2280e-01,  4.1962e-02],\n",
      "        [-1.4176e-01, -1.5730e-01,  9.1192e-03],\n",
      "        [-1.3356e-01, -9.2577e-02, -1.4945e-01],\n",
      "        [ 3.7113e-02,  2.5738e-02, -3.6722e-01],\n",
      "        [ 2.2512e-01,  1.0638e-01, -5.0575e-01],\n",
      "        [ 2.8062e-01,  1.1587e-01, -4.7040e-01],\n",
      "        [ 2.0310e-01,  9.6948e-02, -3.1438e-01],\n",
      "        [ 1.2438e-01,  9.8285e-02, -2.0540e-01],\n",
      "        [ 1.4693e-01,  1.1703e-01, -2.5720e-01],\n",
      "        [ 2.2482e-01,  1.0922e-01, -3.9214e-01],\n",
      "        [ 2.1552e-01,  3.4152e-02, -4.1030e-01],\n",
      "        [ 4.6382e-02, -1.0777e-01, -2.2553e-01]]) tensor([1.]) 200 torch.Size([200, 3]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for x, y in custom_non_overlap_train_dataset_orig:\n",
    "    print(x, y, x.size(0), x.size(), y.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70024f72",
   "metadata": {},
   "source": [
    "We now create a DataLoader object that wraps an iterable around the Dataset to enable easy access to the samples. The DataLoader features will have shape [batch_size, sub_seq_length, num_features] and the target will have shape [batch_size, num_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "556a2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please note that the batch_size must be <= len(data) / sub_seq_length. Otherwise there are too few\n",
    "# datapoints to fit in the number of batches. \n",
    "custom_train_loader_orig = DataLoader(custom_non_overlap_train_dataset_orig, batch_size=60, shuffle=False, drop_last=False)\n",
    "custom_val_loader_orig = DataLoader(custom_non_overlap_val_dataset_orig, batch_size=60, shuffle=False, drop_last=False)\n",
    "custom_test_loader_orig = DataLoader(custom_non_overlap_test_dataset_orig, batch_size=60, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b56568d",
   "metadata": {},
   "source": [
    "The total seq length is 28800 and the sub_seq_length is 200. So after 144 (28800 / 200) samples of the DataLoader you have completed the entire sequence for the first 60 (batch_size) rec_ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fc39c7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "144 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d16b7314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(custom_train_loader_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c9f85597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 200, 3]) torch.Size([60, 1])\n",
      "tensor([[[ 5.5221e-01,  1.5928e-02, -1.4009e-01],\n",
      "         [ 5.0251e-01,  1.2555e-02, -1.7173e-01],\n",
      "         [ 3.8237e-01,  1.9323e-02, -1.5452e-01],\n",
      "         ...,\n",
      "         [ 2.2482e-01,  1.0922e-01, -3.9214e-01],\n",
      "         [ 2.1552e-01,  3.4152e-02, -4.1030e-01],\n",
      "         [ 4.6382e-02, -1.0777e-01, -2.2553e-01]],\n",
      "\n",
      "        [[ 1.7383e+00,  3.2570e-01, -9.1312e-01],\n",
      "         [ 1.8892e+00,  4.4224e-01, -9.5136e-01],\n",
      "         [ 1.7944e+00,  4.8735e-01, -9.1289e-01],\n",
      "         ...,\n",
      "         [-1.6873e-01, -2.3498e-02,  1.5228e-01],\n",
      "         [-3.5305e-01, -1.2165e-01,  2.7886e-01],\n",
      "         [-4.8326e-01, -2.3634e-01,  3.7583e-01]],\n",
      "\n",
      "        [[ 3.6168e-01, -2.0328e-01,  5.6099e-01],\n",
      "         [ 5.1477e-01, -1.0317e-01,  4.4883e-01],\n",
      "         [ 6.4356e-01,  5.6649e-03,  3.7602e-01],\n",
      "         ...,\n",
      "         [-1.8367e+00, -1.4729e+00,  4.0915e+00],\n",
      "         [-1.9459e+00, -1.5277e+00,  4.2480e+00],\n",
      "         [-1.8764e+00, -1.4137e+00,  4.1854e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.8355e+00, -2.7032e+00, -1.1707e+00],\n",
      "         [-2.1089e+00, -2.5587e+00, -9.3424e-01],\n",
      "         [-2.1153e+00, -2.4524e+00, -8.6264e-01],\n",
      "         ...,\n",
      "         [ 2.7000e-01,  1.2504e-01, -1.3480e-01],\n",
      "         [ 5.6984e-01, -7.1645e-02, -3.3227e-01],\n",
      "         [ 7.3132e-01, -1.3985e-01, -4.3982e-01]],\n",
      "\n",
      "        [[-6.3955e-01, -6.4301e-01, -4.9150e-01],\n",
      "         [-1.6466e-01, -4.0925e-01, -6.4536e-01],\n",
      "         [ 4.7419e-02, -2.9401e-01, -7.4773e-01],\n",
      "         ...,\n",
      "         [ 2.1032e-01,  1.5558e-01, -3.8400e-01],\n",
      "         [ 3.8725e-01, -1.4443e-03, -4.8111e-01],\n",
      "         [ 4.3536e-01, -1.1186e-01, -4.3767e-01]],\n",
      "\n",
      "        [[ 1.4023e-01, -1.7136e-01, -8.8307e-02],\n",
      "         [ 1.4058e-01,  1.0429e-01,  1.8801e-02],\n",
      "         [-1.8934e-02,  5.1284e-01,  2.0268e-01],\n",
      "         ...,\n",
      "         [ 4.8166e-01,  3.1322e-01, -1.2905e-01],\n",
      "         [ 8.5518e-01,  3.5615e-01, -3.2143e-01],\n",
      "         [ 1.2251e+00,  2.0321e-01, -5.0170e-01]]]) tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "for index, (data, target) in enumerate(custom_train_loader_orig):\n",
    "    print(data.shape, target.shape)\n",
    "    print(data, target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2f8c54a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 200, 3]) torch.Size([60, 1])\n",
      "tensor([[[ 1.3472e-01, -1.9344e-02,  1.5218e+00],\n",
      "         [-1.5179e-02, -1.1606e-01,  1.5547e+00],\n",
      "         [-1.7834e-01, -1.9497e-01,  1.5101e+00],\n",
      "         ...,\n",
      "         [ 1.4191e+00,  2.4746e+00, -1.8382e-01],\n",
      "         [ 1.2820e+00,  2.4957e+00, -1.8340e-01],\n",
      "         [ 1.2489e+00,  2.5592e+00, -1.7618e-01]],\n",
      "\n",
      "        [[ 2.0947e+00,  2.8699e+00,  3.8475e-01],\n",
      "         [ 2.2761e+00,  3.0820e+00,  3.6720e-01],\n",
      "         [ 2.3007e+00,  3.1694e+00,  4.4005e-01],\n",
      "         ...,\n",
      "         [-1.6270e+00, -2.8730e-01,  1.0645e+00],\n",
      "         [-1.6993e+00, -3.7431e-01,  1.0725e+00],\n",
      "         [-1.6154e+00, -4.5684e-01,  9.6798e-01]],\n",
      "\n",
      "        [[-3.4190e-01, -1.4888e-01,  2.6420e-01],\n",
      "         [-4.0219e-01, -1.8422e-01,  2.5631e-01],\n",
      "         [-5.1402e-01, -2.3570e-01,  2.7497e-01],\n",
      "         ...,\n",
      "         [-1.7635e-01, -3.6149e-02,  8.8540e-03],\n",
      "         [-1.0121e-01, -5.2934e-02, -7.8782e-02],\n",
      "         [-4.9789e-02, -4.4545e-02, -1.5422e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.0951e-01, -2.7405e-01,  2.9114e-01],\n",
      "         [-2.0210e-01, -2.3759e-01,  1.2103e-01],\n",
      "         [-2.1855e-03, -1.0444e-01, -1.2729e-01],\n",
      "         ...,\n",
      "         [ 5.2798e-01, -1.4201e-01, -1.0229e+00],\n",
      "         [ 4.2330e-01, -2.6670e-01, -9.3188e-01],\n",
      "         [ 4.1675e-01, -4.0840e-01, -9.1593e-01]],\n",
      "\n",
      "        [[-7.6227e-01,  1.9306e-01,  8.1866e-01],\n",
      "         [-7.6645e-01,  3.9741e-01,  8.6438e-01],\n",
      "         [-6.6679e-01,  5.6052e-01,  8.5510e-01],\n",
      "         ...,\n",
      "         [ 5.1789e-01, -3.6393e-01, -4.8333e-02],\n",
      "         [ 5.5818e-01, -1.1549e-01,  1.2054e-01],\n",
      "         [ 5.7929e-01,  8.8269e-02,  3.0952e-01]],\n",
      "\n",
      "        [[-3.8552e-01, -6.4357e-02,  7.9333e-01],\n",
      "         [-3.4874e-01,  1.8721e-02,  7.3864e-01],\n",
      "         [-4.6500e-01, -6.9135e-03,  8.1809e-01],\n",
      "         ...,\n",
      "         [ 1.0326e+00,  6.0620e+00,  2.0525e+00],\n",
      "         [ 1.1118e+00,  6.1154e+00,  1.9943e+00],\n",
      "         [ 1.1413e+00,  6.0235e+00,  1.8929e+00]]]) tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "for index, (data, target) in enumerate(custom_test_loader_orig):\n",
    "    print(data.shape, target.shape)\n",
    "    print(data, target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ee77b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://discuss.pytorch.org/t/lstm-stateful-batch-size-1/81002\n",
    "class LSTMStateful(nn.Module):\n",
    "    \"\"\"Create a stateful LSTM model for where the current hidden states and values \n",
    "      are passed on to the next batch in the forward pass.\n",
    "      \n",
    "      When initializing an object of this class, the hidden states and cells will be resetted at value zero.\n",
    "\n",
    "      Parameters\n",
    "      ----------\n",
    "      input_size : int\n",
    "          Input dimension of LSTM model.\n",
    "      hidden_size : int\n",
    "          Hidden states dimensionality.\n",
    "      batch_size : int\n",
    "          Number of samples in a batch.\n",
    "      device : str\n",
    "          'cuda' or 'cpu'\n",
    "      **kwargs\n",
    "          For the nn.LSTM module.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, batch_size, device, **kwargs):\n",
    "        \n",
    "        super().__init__()\n",
    "        self._hidden_state, self._hidden_cell = (None, None)\n",
    "        self._batch_size = batch_size\n",
    "        self._hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, **kwargs)\n",
    "        self.reset_hidden_cell()\n",
    "        self.reset_hidden_state()\n",
    "        \n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self._batch_size\n",
    "        \n",
    "    @property\n",
    "    def hidden_size(self):\n",
    "        return self._hidden_size\n",
    "    \n",
    "    @property    \n",
    "    def hidden_cell(self):\n",
    "        return self._hidden_cell\n",
    "    \n",
    "    @property    \n",
    "    def hidden_state(self):\n",
    "        return self._hidden_state\n",
    "    \n",
    "    def reset_hidden_cell(self):\n",
    "        self._hidden_cell = torch.zeros(self.lstm.num_layers, self.batch_size, self.hidden_size, device=self.device)\n",
    "        \n",
    "    def reset_hidden_state(self):\n",
    "        self._hidden_state = torch.zeros(self.lstm.num_layers, self.batch_size, self.hidden_size, device=self.device)   \n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        \"\"\"The current hidden states and cells are passed in the forward pass.\"\"\"\n",
    "        lstm_out, (self._hidden_cell, self._hidden_state) = self.lstm(input_seq, (self._hidden_cell, self._hidden_state))\n",
    "        \n",
    "        return lstm_out, (self._hidden_cell, self._hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "73836e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMStatefulClassification(nn.Module):\n",
    "    \"\"\"Create a stateful LSTM model for binary classification where the current hidden states and values \n",
    "      are passed on to the next batch in the forward pass.\n",
    "\n",
    "      Parameters\n",
    "      ----------\n",
    "      input_size : int\n",
    "          Input dimension of LSTM model.\n",
    "      hidden_size : int\n",
    "          Hidden states dimensionality.\n",
    "      batch_size : int\n",
    "          Number of samples in a batch.\n",
    "      device : str\n",
    "          'cuda' or 'cpu'\n",
    "      **kwargs\n",
    "          For the nn.LSTM module.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, device, num_layers, batch_first):\n",
    "        super().__init__()\n",
    "        self.lstm = LSTMStateful(input_size=input_size, hidden_size=hidden_size, \n",
    "                                 batch_size=batch_size, device=device, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, (hidden_cell, hidden_state) = self.lstm(x)\n",
    "        \n",
    "        # Decode the hidden state of the last time step. The shape will be [batch_size, output_dim]. We only\n",
    "        # want to know the hidden state of the last time step, as we're only interested in computing the loss \n",
    "        # after the entire sequence length has been processed\n",
    "        output = self.linear(output[:, -1, :]) \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f6f93876",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizationStatefulLSTM(OptimizationLSTM):\n",
    "    \"\"\"Train, optimize and evaluate a stateful LSTM model. Stateful means that the hidden states and cells\n",
    "        are passed on to the next batch instead of being resetted to zero at the beginning of each batch. This is\n",
    "        useful when the sequence is too long to be processed by the LSTM model all at once. We therefore split up\n",
    "        the sequence in multiple sub-sequences. The number of sub-sequences needed to process an entire sequence is \n",
    "        denoted by the parameter num_sub_sequences. The hidden cells and states are manually resetted to zero after \n",
    "        num_sub_sequences batches have been processed. \n",
    "        \n",
    "        The final prediction will be made by making a prediction for each sub-sequence and at the end take the mean\n",
    "        over all sub-sequence predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : nn.Module\n",
    "            LSTM model with specified input_dim, hidden_dim, output_dim, batch_size, device, layer_dim, batch_first.\n",
    "        loss_fn : torch.nn.modules.loss\n",
    "            Loss function\n",
    "        optimizer : torch.optim\n",
    "            Optimizer function.\n",
    "        num_sub_sequences : int\n",
    "            Number of sub-sequences that make up an entire sequence.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, loss_fn, optimizer, num_sub_sequences):\n",
    "        super().__init__(model, loss_fn, optimizer) \n",
    "        self.num_sub_sequences = num_sub_sequences\n",
    "        self.save_best_model = SaveBestModel()\n",
    "        self.final_train_predictions = []\n",
    "        self.final_val_predictions = []\n",
    "        self.final_test_predictions = []\n",
    "        self.final_train_prob = []\n",
    "        self.final_val_prob = []\n",
    "        self.final_test_prob = []\n",
    "        \n",
    "    def reset_states(self):\n",
    "        \"\"\"Reset the hidden states and cells to zero.\"\"\"\n",
    "        for layer in self.model.modules():\n",
    "            if hasattr(layer, 'reset_hidden_cell'): \n",
    "                layer.reset_hidden_cell()\n",
    "            if hasattr(layer, 'reset_hidden_state'):  \n",
    "                layer.reset_hidden_state()\n",
    "        \n",
    "    def obtain_correct_classified_instances(self, y, t, epoch, train, val, test):\n",
    "        \"\"\"Obtain the number of correctly classified instances by taking the mean prediction over all \n",
    "        sub sequences and compare it against the true label.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y : torch.Tensor\n",
    "            Tensor containing the true labels. Shape [batch_size, output_size].\n",
    "        t : int\n",
    "            The time step in the data loader.\n",
    "        train : Boolean\n",
    "            If in train mode.\n",
    "        val : Boolean\n",
    "            If in validation mode.\n",
    "        test : Boolean\n",
    "            If in test mode.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        num_correct : int\n",
    "            Percentage of change in prediction within the total sequences. \n",
    "        \"\"\"\n",
    "        assert super().check_if_only_one_boolean(train, val, test), f\"You can only be in either one of train/val/test mode, you are now in {len([var for var in [train, val, test] if var==True])} modes\"\n",
    "        if train:\n",
    "            predictions = self.train_predictions\n",
    "        elif val:\n",
    "            predictions = self.val_predictions\n",
    "        elif test:\n",
    "            predictions = self.test_predictions \n",
    "    \n",
    "        assert len(predictions) == self.num_sub_sequences, f'The number of predictions on time step {t} should be {self.num_sub_sequences}, but is {len(predictions)}'\n",
    "\n",
    "        perc_changes_in_pred, mean_pred = self.analyze_predictions(train, val, test)\n",
    "        print(f'The percentage of change in prediction within the entire sequence is: {perc_changes_in_pred}% in epoch {epoch} and batch {t}')\n",
    "                        \n",
    "        # y gets reshaped into the same form as pred in order to compute the accuracy \n",
    "        num_correct = np.sum((mean_pred == y.view(1, -1)))\n",
    "                                \n",
    "        return num_correct, mean_pred\n",
    "        \n",
    "        \n",
    "    def analyze_predictions(self, train, val, test):\n",
    "        \"\"\"Analyze the predictions by checking how often there is a change in prediction within the entire sequence.\n",
    "        \n",
    "        If a total sequence is 28800 time steps and the sub_sequence length is 200 time steps, then there are \n",
    "        28800 / 200 = 144 sub_sequences. Meaning, that within an entire sequence, there can be a maximum of 143 changes \n",
    "        in prediction.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        perc_changes_in_pred : float\n",
    "            Percentage of change in prediction within the total sequences. \n",
    "        mean_pred : torch.Tensor\n",
    "            Tensor of size [batch_size]. Containing the mean prediction for all batch_size rec ids.\n",
    "        \"\"\"\n",
    "        assert super().check_if_only_one_boolean(train, val, test), f\"You can only be in either one of train/val/test mode, you are now in {len([var for var in [train, val, test] if var==True])} modes\"\n",
    "        if train:\n",
    "            predictions = self.train_predictions\n",
    "        elif val:\n",
    "            predictions = self.val_predictions\n",
    "        elif test:\n",
    "            predictions = self.test_predictions            \n",
    "            \n",
    "        # Calculate the mean prediction by taking the average over all sub_sequences that make up one total sequence\n",
    "        # The variable predictions contains all the sub_sequence predictions belonging to batch_size rec ids.\n",
    "        mean_pred = np.mean(np.stack(predictions, axis=0), axis=0)\n",
    "                    \n",
    "        # For each sub_sequence prediction we check whether the subsequent sub_sequence prediction is different\n",
    "        # If a subsequent sub_sequence prediction is different, the difference will be non-zero\n",
    "        changes_in_pred = np.diff(predictions, axis=0)  \n",
    "        \n",
    "        # Concatenate all values into one list\n",
    "        #changes_in_pred = torch.cat(list(changes_in_pred))\n",
    "        changes_in_pred = changes_in_pred.flatten()\n",
    "                    \n",
    "        # Here we sum all the cases where there has been a change in prediction going from one sub_sequence to the next one    \n",
    "        #num_changes_in_pred = torch.sum(changes_in_pred != 0).item()\n",
    "        num_changes_in_pred = np.sum(changes_in_pred != 0)\n",
    "                    \n",
    "        perc_changes_in_pred = (num_changes_in_pred / len(changes_in_pred)) * 100\n",
    "        \n",
    "        return perc_changes_in_pred, mean_pred\n",
    "            \n",
    "            \n",
    "    def evaluate_after_entire_sequence(self, y, t, epoch, train, val, test):\n",
    "        \"\"\"\n",
    "        After an entire sequence is processed, we want to know the average prediction over the entire \n",
    "        sequence and use that as a final prediction for the entire sequence.\n",
    "        \"\"\"\n",
    "        assert super().check_if_only_one_boolean(train, val, test), f\"You can only be in either one of train/val/test mode, you are now in {len([var for var in [train, val, test] if var==True])} modes\"\n",
    "\n",
    "        # Data is first moved to cpu and then converted to numpy array \n",
    "        true_label = y.cpu().data.numpy()\n",
    "        correct_entire_seq, mean_pred = self.obtain_correct_classified_instances(y, t, epoch, \n",
    "                                                                                 train=train, \n",
    "                                                                                 val=val, \n",
    "                                                                                 test=test)\n",
    "                    \n",
    "        # We clear the list with the predictions for the next batch which contains the sequences of new rec ids\n",
    "        if train:\n",
    "            self.train_labels.append(true_label)\n",
    "            self.final_train_predictions.append(mean_pred)\n",
    "            self.train_predictions.clear() \n",
    "            mean_prob = np.mean(np.stack(self.train_probabilities, axis=0), axis=0)\n",
    "            self.final_train_prob.append(mean_prob)\n",
    "        elif val:\n",
    "            self.val_labels.append(true_label)\n",
    "            self.final_val_predictions.append(mean_pred)\n",
    "            self.val_predictions.clear()  \n",
    "            mean_prob = np.mean(np.stack(self.val_probabilities, axis=0), axis=0)\n",
    "            self.final_val_prob.append(mean_prob)\n",
    "        elif test:\n",
    "            self.test_labels.append(true_label)\n",
    "            self.final_test_predictions.append(mean_pred)\n",
    "            self.test_predictions.clear()  \n",
    "            mean_prob = np.mean(np.stack(self.test_probabilities, axis=0), axis=0)\n",
    "            self.final_test_prob.append(mean_prob)\n",
    "            \n",
    "        return correct_entire_seq\n",
    "                    \n",
    "    \n",
    "    def train(self, train_loader, val_loader, batch_size=60, sequence_length=200, n_epochs=50):\n",
    "        output_path = file_paths['output_path'] + \"/\" + \"model\"\n",
    "        \n",
    "        current_date_and_time = \"{:%Y-%m-%d_%H-%M}\".format(datetime.datetime.now())\n",
    "        file_name_output = f'{current_date_and_time}_best_model_statefull'\n",
    "        \n",
    "        # The model is trained/validated/tested according to a stateful LSTM model. Meaning that we will propagate\n",
    "        # hidden states and cells up untill an entire sequence is proccessed. The entire sequence length is 28800\n",
    "        # time steps and the sub_sequence length is 200 time steps. This means that 1 batch contains 200 time steps of\n",
    "        # batch_size (60) rec ids. As a result, we will reset the hidden states and cells after 144 batches have been \n",
    "        # processed. Then we will start processing the entire sequences of the next batch_size rec ids and again reset\n",
    "        # the hidden states and cells after 144 batches have been processed. This process is repeated up untill the \n",
    "        # entire sequence of each rec id has been processed.\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            total_train_loss_epoch = 0.0\n",
    "            correct_train, total_samples = 0, 0\n",
    "            total_runs_for_entire_sequence_completed = 0\n",
    "            for t, (x_batch, y_batch) in enumerate(train_loader):                \n",
    "                \n",
    "                # We manually reset the hidden states and cells after an entire sequence is processed\n",
    "                if (t % self.num_sub_sequences == 0):\n",
    "                    print(f'The hidden states and cells are resetted at the beginning of epoch {epoch}, batch {t} of train_loader')\n",
    "                    self.reset_states()\n",
    "                    \n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                # avg_train_batch_loss contains the value of the average cost of all the training examples of the current batch\n",
    "                avg_train_batch_loss, y_pred = super().train_step(x_batch, y_batch)\n",
    "                \n",
    "                super().get_predictions_binary_model(y_pred, train=True, val=False, test=False)\n",
    "                \n",
    "                # After an entire sequence is processed, we want to know the average prediction over the entire \n",
    "                # sequence and use that as a final prediction for the entire sequence\n",
    "                if len(self.train_predictions) == self.num_sub_sequences:\n",
    "                    correct_train_entire_seq = self.evaluate_after_entire_sequence(y_batch, t, epoch, \n",
    "                                                                                   train=True, val=False, test=False)\n",
    "                    \n",
    "                    correct_train += correct_train_entire_seq\n",
    "          \n",
    "                # total_train_loss_epoch accumelates the total loss per train batch for each entire epoch\n",
    "                total_train_loss_epoch += (avg_train_batch_loss.item()*x_batch.size(0))\n",
    "                \n",
    "                # We do truncated BPTT as the model otherwise would have to backpropagate through the entire sequence,\n",
    "                # which will lead to very long training times + vanishing/exploding gradients\n",
    "                self.model.lstm._hidden_state = self.model.lstm._hidden_state.detach()\n",
    "                self.model.lstm._hidden_cell = self.model.lstm._hidden_cell.detach()\n",
    "                \n",
    "                            \n",
    "            # Calculate average sample train loss for this particular epoch.\n",
    "            avg_sample_train_loss_epoch = total_train_loss_epoch / len(train_loader.sampler)\n",
    "            self.train_losses.append(avg_sample_train_loss_epoch)\n",
    "            \n",
    "            # We clear the labels and probabilities after each epoch \n",
    "            self.train_labels.clear()\n",
    "            self.final_train_prob.clear()\n",
    "               \n",
    "            self.model.eval()    \n",
    "            with torch.no_grad():\n",
    "                total_val_loss_epoch = 0.0\n",
    "                correct_val, total_samples_val = 0, 0\n",
    "                for t, (x_val, y_val) in enumerate(val_loader):\n",
    "                    x_val = x_val.to(device)\n",
    "                    y_val = y_val.to(device)\n",
    "                    \n",
    "                    if (t % self.num_sub_sequences == 0):\n",
    "                        print(f'The hidden states and cells are resetted at the beginning of epoch {epoch}, batch {t} of val_loader')\n",
    "                        self.reset_states()      \n",
    "                        \n",
    "                    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                    y_pred = self.model(x_val) # output shape is [batch_size, 1] and contains logits\n",
    "                    \n",
    "                    super().get_predictions_binary_model(y_pred, train=False, val=True, test=False)\n",
    "                    \n",
    "                    if len(self.val_predictions) == self.num_sub_sequences:\n",
    "                        correct_val_entire_seq = self.evaluate_after_entire_sequence(y_val, t, epoch, \n",
    "                                                                                     train=False, val=True, test=False)\n",
    "\n",
    "                        correct_val += correct_val_entire_seq\n",
    "            \n",
    "                    # TO DO: Find out if all samples are used for training/validating (i.e., are the last samples\n",
    "                    # that may not fit into a full batch now disregarded?)\n",
    "                    total_samples_val += y_val.size(0)\n",
    "                                        \n",
    "                    avg_val_batch_loss = self.loss_fn(y_pred, y_val)\n",
    "                    # total_val_loss_epoch accumelates the total loss per validation batch for the entire epoch -> total loss per epoch\n",
    "                    # update running training loss\n",
    "                    total_val_loss_epoch += (avg_val_batch_loss.item()*x_val.size(0))\n",
    "                    \n",
    "                # Calculate average sample validation loss for this particular epoch.\n",
    "                avg_sample_val_loss_epoch = total_val_loss_epoch / len(val_loader.sampler)\n",
    "                self.val_losses.append(avg_sample_val_loss_epoch)\n",
    "                                \n",
    "                # We clear the labels and probabilities after each epoch \n",
    "                self.val_labels.clear()\n",
    "                self.final_val_prob.clear()\n",
    "                \n",
    "                self.save_best_model(avg_sample_val_loss_epoch, epoch, self.model, self.optimizer, \n",
    "                                     self.loss_fn, output_path, file_name_output)\n",
    "\n",
    "            print(f\"Epoch [{epoch}/{n_epochs}] Training loss: {avg_sample_train_loss_epoch:.10f}\\t Validation loss: {avg_sample_val_loss_epoch:.10f}\"\n",
    "                )\n",
    "            print('-'*50)\n",
    "            \n",
    "        super().save_loss_plot(current_date_and_time)\n",
    "        print('TRAINING COMPLETE')\n",
    "            \n",
    "        \n",
    "    def evaluate(self, test_loader, checkpoint, batch_size=60):\n",
    "        model_epoch = checkpoint['epoch']\n",
    "        print(f\"Model was saved at {model_epoch} epochs\\n\")\n",
    "        \n",
    "        print(f'Loading at epoch {model_epoch} saved model weights...')\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct_test, total_samples_test = 0, 0\n",
    "            for t, (x_test, y_test) in enumerate(test_loader):\n",
    "                x_test = x_test.to(device)\n",
    "                y_test = y_test.to(device) \n",
    "                \n",
    "                # We manually reset the hidden states and cells after an entire sequence is processed\n",
    "                if (t % self.num_sub_sequences == 0):\n",
    "                    print(f'The hidden states and cells are resetted at the beginning batch {t} of test_loader')\n",
    "                    self.reset_states()\n",
    "                    \n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                y_pred = self.model(x_test) # output shape is [batch_size, 1] and contains logits\n",
    "                \n",
    "                super().get_predictions_binary_model(y_pred, train=False, val=False, test=True)\n",
    "                \n",
    "                # After the entire sequence has been processed we take the mean prediction of all sub-sequence \n",
    "                # predictions\n",
    "                if len(self.test_predictions) == self.num_sub_sequences:\n",
    "                    mean_prob = np.mean(np.stack(self.test_probabilities, axis=0), axis=0)\n",
    "                    true_label = y_test.cpu().data.numpy()\n",
    "                    correct_test_entire_seq, mean_pred_test = self.obtain_correct_classified_instances(y_test, t, 0, \n",
    "                                                                                                       train=False, \n",
    "                                                                                                       val=False, \n",
    "                                                                                                       test=True)\n",
    "\n",
    "                    correct_test += correct_test_entire_seq\n",
    "                    precision_test, recall_test, _ = precision_recall_curve(true_label, mean_prob)\n",
    "                    super().plot_prec_recall_curve(recall_test, precision_test)\n",
    "\n",
    "                    print(precision_score(true_label, mean_pred_test))\n",
    "                    print(recall_score(true_label, mean_pred_test))\n",
    "                    print(f1_score(true_label, mean_pred_test))\n",
    "                    # We clear the list with the predictions for the next batch which contains the sequences of new rec ids\n",
    "                    self.test_predictions.clear()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2d3a9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8d0a87aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(features_to_use)\n",
    "output_dim = 1\n",
    "hidden_dim = 2\n",
    "layer_dim = 3\n",
    "batch_size = 60\n",
    "total_sequence_length = 28800\n",
    "sub_sequence_length = 200\n",
    "# The num_sub_sequences variable is the number of sub_sequences necessary to complete an entire sequence\n",
    "num_sub_sequences = total_sequence_length / sub_sequence_length \n",
    "dropout = 0.2\n",
    "n_epochs = 2\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-6\n",
    "\n",
    "model_params = {'input_dim': input_dim,\n",
    "                'hidden_dim' : hidden_dim,\n",
    "                'layer_dim' : layer_dim,\n",
    "                'output_dim' : output_dim,\n",
    "                'dropout_prob' : dropout}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4ec28ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ea98279d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStatefulClassification(\n",
       "  (lstm): LSTMStateful(\n",
       "    (lstm): LSTM(3, 2, num_layers=3, batch_first=True)\n",
       "  )\n",
       "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stateful = LSTMStatefulClassification(input_size=input_dim, hidden_size=hidden_dim, output_size=output_dim, \n",
    "                                   batch_size=batch_size, device=device, num_layers=layer_dim, batch_first=True)\n",
    "model_stateful.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6a3085e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateful(\n",
       "  (lstm): LSTM(3, 2, num_layers=3, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stateful.lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "16b82658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stateful.lstm._hidden_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "90b0c0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stateful.lstm._hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "31d62e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144.0"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(custom_train_loader_orig) / (180 / model.lstm._batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "81ba41ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loss combines a Sigmoid layer and the BCELoss in one single class. This version is more numerically stable \n",
    "# than using a plain Sigmoid followed by a BCELoss as, by combining the operations into one layer, we take \n",
    "# advantage of the log-sum-exp trick for numerical stability. \n",
    "# Source: https://discuss.pytorch.org/t/bceloss-vs-bcewithlogitsloss/33586 and: \n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.Adam(model_stateful.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "opt_stateful = OptimizationStatefulLSTM(model=model_stateful, loss_fn=loss_fn, optimizer=optimizer, \n",
    "                                        num_sub_sequences=num_sub_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7f877b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStatefulClassification(\n",
       "  (lstm): LSTMStateful(\n",
       "    (lstm): LSTM(3, 2, num_layers=3, batch_first=True)\n",
       "  )\n",
       "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_stateful.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "426bef0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144.0"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_stateful.num_sub_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "cde66298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    weight_decay: 1e-06\n",
       ")"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_stateful.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3b3a1575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hidden states and cells are resetted at the beginning of epoch 1, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 1 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 1, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 1 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 1, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 1 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 1, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 1 and batch 143\n",
      "\n",
      "Best validation loss: 0.4960284839487738\n",
      "\n",
      "Saving best model for epoch: 1\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [1/50] Training loss: 0.5104042323\t Validation loss: 0.4960284839\n",
      "The hidden states and cells are resetted at the beginning of epoch 2, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 2 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 2, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 2 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 2, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 2 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 2, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 2 and batch 143\n",
      "\n",
      "Best validation loss: 0.4815954888860385\n",
      "\n",
      "Saving best model for epoch: 2\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [2/50] Training loss: 0.4965177535\t Validation loss: 0.4815954889\n",
      "The hidden states and cells are resetted at the beginning of epoch 3, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 3 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 3, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 3 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 3, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 3 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 3, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 3 and batch 143\n",
      "\n",
      "Best validation loss: 0.463015023411976\n",
      "\n",
      "Saving best model for epoch: 3\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [3/50] Training loss: 0.4810938018\t Validation loss: 0.4630150234\n",
      "The hidden states and cells are resetted at the beginning of epoch 4, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 4 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 4, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 4 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 4, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 4 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 4, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 4 and batch 143\n",
      "\n",
      "Best validation loss: 0.43994056309262913\n",
      "\n",
      "Saving best model for epoch: 4\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [4/50] Training loss: 0.4611888243\t Validation loss: 0.4399405631\n",
      "The hidden states and cells are resetted at the beginning of epoch 5, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 5 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 5, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 5 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 5, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 5 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 5, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 5 and batch 143\n",
      "\n",
      "Best validation loss: 0.4165834770020511\n",
      "\n",
      "Saving best model for epoch: 5\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [5/50] Training loss: 0.4391981657\t Validation loss: 0.4165834770\n",
      "The hidden states and cells are resetted at the beginning of epoch 6, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 6 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 6, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 6 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 6, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 6 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 6, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 6 and batch 143\n",
      "\n",
      "Best validation loss: 0.3965668605847491\n",
      "\n",
      "Saving best model for epoch: 6\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [6/50] Training loss: 0.4190285660\t Validation loss: 0.3965668606\n",
      "The hidden states and cells are resetted at the beginning of epoch 7, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 7 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 7, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 7 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 7, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 7 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 7, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 7 and batch 143\n",
      "\n",
      "Best validation loss: 0.3827111718969213\n",
      "\n",
      "Saving best model for epoch: 7\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [7/50] Training loss: 0.4038044721\t Validation loss: 0.3827111719\n",
      "The hidden states and cells are resetted at the beginning of epoch 8, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 8 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 8, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 8 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 8, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 8 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 8, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 8 and batch 143\n",
      "\n",
      "Best validation loss: 0.3740991854833232\n",
      "\n",
      "Saving best model for epoch: 8\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [8/50] Training loss: 0.3943074213\t Validation loss: 0.3740991855\n",
      "The hidden states and cells are resetted at the beginning of epoch 9, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 9 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 9, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 9 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 9, batch 288 of train_loader\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 9 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 9, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 9 and batch 143\n",
      "\n",
      "Best validation loss: 0.36874333396553993\n",
      "\n",
      "Saving best model for epoch: 9\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [9/50] Training loss: 0.3887088591\t Validation loss: 0.3687433340\n",
      "The hidden states and cells are resetted at the beginning of epoch 10, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 10 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 10, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 10 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 10, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 10 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 10, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 10 and batch 143\n",
      "\n",
      "Best validation loss: 0.36543777647117776\n",
      "\n",
      "Saving best model for epoch: 10\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [10/50] Training loss: 0.3854788267\t Validation loss: 0.3654377765\n",
      "The hidden states and cells are resetted at the beginning of epoch 11, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 11 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 11, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 11 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 11, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 11 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 11, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 11 and batch 143\n",
      "\n",
      "Best validation loss: 0.36342744363678825\n",
      "\n",
      "Saving best model for epoch: 11\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [11/50] Training loss: 0.3836927529\t Validation loss: 0.3634274436\n",
      "The hidden states and cells are resetted at the beginning of epoch 12, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 12 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 12, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 12 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 12, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 12 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 12, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 12 and batch 143\n",
      "\n",
      "Best validation loss: 0.36222138317922753\n",
      "\n",
      "Saving best model for epoch: 12\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [12/50] Training loss: 0.3827630401\t Validation loss: 0.3622213832\n",
      "The hidden states and cells are resetted at the beginning of epoch 13, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 13 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 13, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 13 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 13, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 13 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 13, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 13 and batch 143\n",
      "\n",
      "Best validation loss: 0.36150589688784546\n",
      "\n",
      "Saving best model for epoch: 13\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [13/50] Training loss: 0.3823191005\t Validation loss: 0.3615058969\n",
      "The hidden states and cells are resetted at the beginning of epoch 14, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 14 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 14, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 14 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 14, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 14 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 14, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 14 and batch 143\n",
      "\n",
      "Best validation loss: 0.36108449060055947\n",
      "\n",
      "Saving best model for epoch: 14\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [14/50] Training loss: 0.3821349092\t Validation loss: 0.3610844906\n",
      "The hidden states and cells are resetted at the beginning of epoch 15, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 15 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 15, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 15 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 15, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 15 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 15, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 15 and batch 143\n",
      "\n",
      "Best validation loss: 0.36083674658503795\n",
      "\n",
      "Saving best model for epoch: 15\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [15/50] Training loss: 0.3820784898\t Validation loss: 0.3608367466\n",
      "The hidden states and cells are resetted at the beginning of epoch 16, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 16 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 16, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 16 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 16, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 16 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 16, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 16 and batch 143\n",
      "\n",
      "Best validation loss: 0.36069062910974026\n",
      "\n",
      "Saving best model for epoch: 16\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [16/50] Training loss: 0.3820772208\t Validation loss: 0.3606906291\n",
      "The hidden states and cells are resetted at the beginning of epoch 17, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 17 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 17, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 17 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 17, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 17 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 17, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 17 and batch 143\n",
      "\n",
      "Best validation loss: 0.36060407840543324\n",
      "\n",
      "Saving best model for epoch: 17\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [17/50] Training loss: 0.3820943499\t Validation loss: 0.3606040784\n",
      "The hidden states and cells are resetted at the beginning of epoch 18, batch 0 of train_loader\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 18 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 18, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 18 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 18, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 18 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 18, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 18 and batch 143\n",
      "\n",
      "Best validation loss: 0.360552907610933\n",
      "\n",
      "Saving best model for epoch: 18\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [18/50] Training loss: 0.3821132529\t Validation loss: 0.3605529076\n",
      "The hidden states and cells are resetted at the beginning of epoch 19, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 19 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 19, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 19 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 19, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 19 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 19, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 19 and batch 143\n",
      "\n",
      "Best validation loss: 0.3605232112523582\n",
      "\n",
      "Saving best model for epoch: 19\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [19/50] Training loss: 0.3821275196\t Validation loss: 0.3605232113\n",
      "The hidden states and cells are resetted at the beginning of epoch 20, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 20 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 20, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 20 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 20, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 20 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 20, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 20 and batch 143\n",
      "\n",
      "Best validation loss: 0.36050705756578183\n",
      "\n",
      "Saving best model for epoch: 20\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [20/50] Training loss: 0.3821355780\t Validation loss: 0.3605070576\n",
      "The hidden states and cells are resetted at the beginning of epoch 21, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 21 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 21, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 21 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 21, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 21 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 21, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 21 and batch 143\n",
      "\n",
      "Best validation loss: 0.3604998489220937\n",
      "\n",
      "Saving best model for epoch: 21\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [21/50] Training loss: 0.3821376123\t Validation loss: 0.3604998489\n",
      "The hidden states and cells are resetted at the beginning of epoch 22, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 22 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 22, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 22 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 22, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 22 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 22, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 22 and batch 143\n",
      "\n",
      "Best validation loss: 0.36049902915126747\n",
      "\n",
      "Saving best model for epoch: 22\n",
      "\n",
      "--------------------------------------------------\n",
      "Epoch [22/50] Training loss: 0.3821345240\t Validation loss: 0.3604990292\n",
      "The hidden states and cells are resetted at the beginning of epoch 23, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 23 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 23, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 23 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 23, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 23 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 23, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 23 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [23/50] Training loss: 0.3821271563\t Validation loss: 0.3605032205\n",
      "The hidden states and cells are resetted at the beginning of epoch 24, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 24 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 24, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 24 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 24, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 24 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 24, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 24 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [24/50] Training loss: 0.3821162279\t Validation loss: 0.3605117446\n",
      "The hidden states and cells are resetted at the beginning of epoch 25, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 25 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 25, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 25 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 25, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 25 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 25, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 25 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [25/50] Training loss: 0.3821021410\t Validation loss: 0.3605244029\n",
      "The hidden states and cells are resetted at the beginning of epoch 26, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 26 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 26, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 26 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 26, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 26 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 26, batch 0 of val_loader\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 26 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [26/50] Training loss: 0.3820848756\t Validation loss: 0.3605413851\n",
      "The hidden states and cells are resetted at the beginning of epoch 27, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 27 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 27, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 27 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 27, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 27 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 27, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 27 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [27/50] Training loss: 0.3820639519\t Validation loss: 0.3605631561\n",
      "The hidden states and cells are resetted at the beginning of epoch 28, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 28 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 28, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 28 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 28, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 28 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 28, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 28 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [28/50] Training loss: 0.3820389174\t Validation loss: 0.3605904372\n",
      "The hidden states and cells are resetted at the beginning of epoch 29, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 29 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 29, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 29 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 29, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 29 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 29, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 29 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [29/50] Training loss: 0.3820097121\t Validation loss: 0.3606242111\n",
      "The hidden states and cells are resetted at the beginning of epoch 30, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 30 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 30, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 30 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 30, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 30 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 30, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 30 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [30/50] Training loss: 0.3819767024\t Validation loss: 0.3606656742\n",
      "The hidden states and cells are resetted at the beginning of epoch 31, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 31 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 31, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 31 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 31, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 31 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 31, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 31 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [31/50] Training loss: 0.3819405195\t Validation loss: 0.3607162353\n",
      "The hidden states and cells are resetted at the beginning of epoch 32, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 32 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 32, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 32 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 32, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 32 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 32, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 32 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [32/50] Training loss: 0.3819019322\t Validation loss: 0.3607769441\n",
      "The hidden states and cells are resetted at the beginning of epoch 33, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 33 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 33, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 33 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 33, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 33 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 33, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 33 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [33/50] Training loss: 0.3818616988\t Validation loss: 0.3608480390\n",
      "The hidden states and cells are resetted at the beginning of epoch 34, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 34 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 34, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 34 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 34, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 34 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 34, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 34 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [34/50] Training loss: 0.3818206182\t Validation loss: 0.3609287900\n",
      "The hidden states and cells are resetted at the beginning of epoch 35, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 35 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 35, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 35 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 35, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 35 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 35, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 35 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [35/50] Training loss: 0.3817796017\t Validation loss: 0.3610174615\n",
      "The hidden states and cells are resetted at the beginning of epoch 36, batch 0 of train_loader\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 36 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 36, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 36 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 36, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 36 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 36, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 36 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [36/50] Training loss: 0.3817393869\t Validation loss: 0.3611116687\n",
      "The hidden states and cells are resetted at the beginning of epoch 37, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 37 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 37, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 37 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 37, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 37 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 37, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 37 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [37/50] Training loss: 0.3817006249\t Validation loss: 0.3612085070\n",
      "The hidden states and cells are resetted at the beginning of epoch 38, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 38 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 38, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 38 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 38, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 38 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 38, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 38 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [38/50] Training loss: 0.3816649327\t Validation loss: 0.3613060845\n",
      "The hidden states and cells are resetted at the beginning of epoch 39, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 39 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 39, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 39 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 39, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 39 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 39, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 39 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [39/50] Training loss: 0.3816331703\t Validation loss: 0.3614035145\n",
      "The hidden states and cells are resetted at the beginning of epoch 40, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 40 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 40, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 40 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 40, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 40 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 40, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 40 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [40/50] Training loss: 0.3816051794\t Validation loss: 0.3614995819\n",
      "The hidden states and cells are resetted at the beginning of epoch 41, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 41 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 41, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 41 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 41, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 41 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 41, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 41 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [41/50] Training loss: 0.3815807820\t Validation loss: 0.3615927421\n",
      "The hidden states and cells are resetted at the beginning of epoch 42, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 42 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 42, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 42 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 42, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 42 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 42, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 42 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [42/50] Training loss: 0.3815598067\t Validation loss: 0.3616815679\n",
      "The hidden states and cells are resetted at the beginning of epoch 43, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 43 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 43, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 43 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 43, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 43 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 43, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 43 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [43/50] Training loss: 0.3815420293\t Validation loss: 0.3617650641\n",
      "The hidden states and cells are resetted at the beginning of epoch 44, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 44 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 44, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 44 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 44, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 44 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 44, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 44 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [44/50] Training loss: 0.3815270235\t Validation loss: 0.3618427101\n",
      "The hidden states and cells are resetted at the beginning of epoch 45, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 45 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 45, batch 144 of train_loader\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 45 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 45, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 45 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 45, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 45 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [45/50] Training loss: 0.3815143259\t Validation loss: 0.3619142986\n",
      "The hidden states and cells are resetted at the beginning of epoch 46, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 46 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 46, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 46 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 46, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 46 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 46, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 46 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [46/50] Training loss: 0.3815035325\t Validation loss: 0.3619798451\n",
      "The hidden states and cells are resetted at the beginning of epoch 47, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 47 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 47, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 47 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 47, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 47 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 47, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 47 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [47/50] Training loss: 0.3814943380\t Validation loss: 0.3620394903\n",
      "The hidden states and cells are resetted at the beginning of epoch 48, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 48 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 48, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 48 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 48, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 48 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 48, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 48 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [48/50] Training loss: 0.3814864408\t Validation loss: 0.3620935246\n",
      "The hidden states and cells are resetted at the beginning of epoch 49, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 49 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 49, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 49 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 49, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 49 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 49, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 49 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [49/50] Training loss: 0.3814796866\t Validation loss: 0.3621423857\n",
      "The hidden states and cells are resetted at the beginning of epoch 50, batch 0 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 50 and batch 143\n",
      "The hidden states and cells are resetted at the beginning of epoch 50, batch 144 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 50 and batch 287\n",
      "The hidden states and cells are resetted at the beginning of epoch 50, batch 288 of train_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 50 and batch 431\n",
      "The hidden states and cells are resetted at the beginning of epoch 50, batch 0 of val_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 50 and batch 143\n",
      "--------------------------------------------------\n",
      "Epoch [50/50] Training loss: 0.3814737778\t Validation loss: 0.3621865467\n",
      "TRAINING COMPLETE\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt_stateful.train(custom_train_loader_orig, custom_val_loader_orig, batch_size=60, n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1e68f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model checkpoint\n",
    "best_model_stateful_cp = torch.load('/Users/AFischer/Documents/PhD_onderzoek/term_preterm_database/output/model/2022-01-12_14-45_best_model_statefull.pth', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2d8f0870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was saved at 22 epochs\n",
      "\n",
      "Loading at epoch 22 saved model weights...\n",
      "The hidden states and cells are resetted at the beginning batch 0 of test_loader\n",
      "The percentage of change in prediction within the entire sequence is: 0.0% in epoch 0 and batch 143\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt_stateful.evaluate(custom_test_loader_orig, best_model_stateful_cp, batch_size=60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
