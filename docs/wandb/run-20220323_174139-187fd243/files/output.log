Epoch [1/25] Training loss: 1.2233	 Validation loss: 1.1701
--------------------------------------------------
Epoch [2/25] Training loss: 1.2651	 Validation loss: 1.1688
--------------------------------------------------
Epoch [3/25] Training loss: 1.2524	 Validation loss: 1.1676
--------------------------------------------------
Epoch [4/25] Training loss: 1.2470	 Validation loss: 1.1664
--------------------------------------------------
Epoch [5/25] Training loss: 1.2447	 Validation loss: 1.1655
--------------------------------------------------
Epoch [6/25] Training loss: 1.2624	 Validation loss: 1.1647
--------------------------------------------------
Epoch [7/25] Training loss: 1.2342	 Validation loss: 1.1638
--------------------------------------------------
Epoch [8/25] Training loss: 1.2207	 Validation loss: 1.1629
--------------------------------------------------
Epoch [9/25] Training loss: 1.2208	 Validation loss: 1.1621
--------------------------------------------------
Epoch [10/25] Training loss: 1.2199	 Validation loss: 1.1614
--------------------------------------------------
Epoch [11/25] Training loss: 1.2208	 Validation loss: 1.1607
--------------------------------------------------
Epoch [12/25] Training loss: 1.2221	 Validation loss: 1.1601
--------------------------------------------------
Epoch [13/25] Training loss: 1.2566	 Validation loss: 1.1595
--------------------------------------------------
Epoch [14/25] Training loss: 1.2319	 Validation loss: 1.1588
--------------------------------------------------
Epoch [15/25] Training loss: 1.2417	 Validation loss: 1.1583
--------------------------------------------------
Epoch [16/25] Training loss: 1.2046	 Validation loss: 1.1578
--------------------------------------------------
Epoch [17/25] Training loss: 1.2353	 Validation loss: 1.1573
--------------------------------------------------
Epoch [18/25] Training loss: 1.2306	 Validation loss: 1.1570
--------------------------------------------------
Epoch [19/25] Training loss: 1.2064	 Validation loss: 1.1566
--------------------------------------------------
Epoch [20/25] Training loss: 1.2369	 Validation loss: 1.1563
--------------------------------------------------
Epoch [21/25] Training loss: 1.2615	 Validation loss: 1.1561
--------------------------------------------------
Epoch [22/25] Training loss: 1.2366	 Validation loss: 1.1558
--------------------------------------------------
Epoch [23/25] Training loss: 1.2091	 Validation loss: 1.1555
--------------------------------------------------
Epoch [24/25] Training loss: 1.2371	 Validation loss: 1.1553
--------------------------------------------------
Epoch [25/25] Training loss: 1.2263	 Validation loss: 1.1551
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 1.1460859830887104e-05, 'num_hidden_units_per_layer': 96, 'weight_decay': 4.130124455300727e-05, 'kernel_size': 3, 'num_epochs': 20, 'drop_out': 0.39724065700554445, 'batch_size': 50, 'reduced_seq_length': 100, 'num_levels': 6, 'stride': 1, 'pos_weight': tensor([6.8261])}
[32m[I 2022-03-23 17:42:19,510][39m Trial 11 finished with value: 1.155130644639333 and parameters: {'learning_rate': 1.4331045309147078e-05, 'num_hidden_units_per_layer': 96, 'weight_decay': 8.538791497490616e-05, 'kernel_size': 3, 'num_epochs': 25, 'drop_out': 0.4214785552401229, 'batch_size': 50, 'reduced_seq_length': 80}. Best is trial 3 with value: 0.9335269729296366.
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0