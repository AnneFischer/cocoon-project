Epoch [1/20] Training loss: 1.4296	 Validation loss: 1.1942
--------------------------------------------------
Epoch [2/20] Training loss: 1.4826	 Validation loss: 1.2004
--------------------------------------------------
Epoch [3/20] Training loss: 1.2379	 Validation loss: 1.2291
--------------------------------------------------
Epoch [4/20] Training loss: 1.2257	 Validation loss: 1.1853
--------------------------------------------------
Epoch [5/20] Training loss: 1.1741	 Validation loss: 1.1765
--------------------------------------------------
Epoch [6/20] Training loss: 1.1876	 Validation loss: 1.1839
--------------------------------------------------
Epoch [7/20] Training loss: 1.1644	 Validation loss: 1.1798
--------------------------------------------------
Epoch [8/20] Training loss: 1.1834	 Validation loss: 1.1757
--------------------------------------------------
Epoch [9/20] Training loss: 1.1817	 Validation loss: 1.1761
--------------------------------------------------
Epoch [10/20] Training loss: 1.1219	 Validation loss: 1.1687
--------------------------------------------------
Epoch [11/20] Training loss: 1.1278	 Validation loss: 1.1677
--------------------------------------------------
Epoch [12/20] Training loss: 1.0884	 Validation loss: 1.1701
--------------------------------------------------
Epoch [13/20] Training loss: 1.0475	 Validation loss: 1.1677
--------------------------------------------------
Epoch [14/20] Training loss: 1.0488	 Validation loss: 1.1616
--------------------------------------------------
Epoch [15/20] Training loss: 1.0244	 Validation loss: 1.1516
--------------------------------------------------
Epoch [16/20] Training loss: 0.9304	 Validation loss: 1.1640
--------------------------------------------------
Epoch [17/20] Training loss: 0.9540	 Validation loss: 1.1799
--------------------------------------------------
Epoch [18/20] Training loss: 0.8276	 Validation loss: 1.2148
--------------------------------------------------
Epoch [19/20] Training loss: 0.9054	 Validation loss: 1.1968
--------------------------------------------------
[32m[I 2022-03-23 17:40:42,280][39m Trial 10 finished with value: 1.212086836496989 and parameters: {'learning_rate': 0.0037122460935228225, 'num_hidden_units_per_layer': 96, 'weight_decay': 6.004644198462957e-05, 'kernel_size': 3, 'num_epochs': 20, 'drop_out': 0.4903525195969467, 'batch_size': 40, 'reduced_seq_length': 180}. Best is trial 3 with value: 0.9335269729296366.
Epoch [20/20] Training loss: 0.9180	 Validation loss: 1.2121
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 1.4331045309147078e-05, 'num_hidden_units_per_layer': 96, 'weight_decay': 8.538791497490616e-05, 'kernel_size': 3, 'num_epochs': 25, 'drop_out': 0.4214785552401229, 'batch_size': 50, 'reduced_seq_length': 80, 'num_levels': 5, 'stride': 1, 'pos_weight': tensor([6.8261])}
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0