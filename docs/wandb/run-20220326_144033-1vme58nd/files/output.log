Epoch [1/30] Training loss: 1.2187	 Validation loss: 1.1648
--------------------------------------------------
Epoch [2/30] Training loss: 1.2129	 Validation loss: 1.1647
--------------------------------------------------
Epoch [3/30] Training loss: 1.1932	 Validation loss: 1.1644
--------------------------------------------------
Epoch [4/30] Training loss: 1.2045	 Validation loss: 1.1639
--------------------------------------------------
Epoch [5/30] Training loss: 1.1983	 Validation loss: 1.1633
--------------------------------------------------
Epoch [6/30] Training loss: 1.2039	 Validation loss: 1.1628
--------------------------------------------------
Epoch [7/30] Training loss: 1.1944	 Validation loss: 1.1638
--------------------------------------------------
Epoch [8/30] Training loss: 1.1853	 Validation loss: 1.1645
--------------------------------------------------
Epoch [9/30] Training loss: 1.1910	 Validation loss: 1.1664
--------------------------------------------------
Epoch [10/30] Training loss: 1.1880	 Validation loss: 1.1639
--------------------------------------------------
Epoch [11/30] Training loss: 1.1787	 Validation loss: 1.1645
--------------------------------------------------
Epoch [12/30] Training loss: 1.1833	 Validation loss: 1.1651
--------------------------------------------------
Epoch [13/30] Training loss: 1.1607	 Validation loss: 1.1655
--------------------------------------------------
Epoch [14/30] Training loss: 1.1723	 Validation loss: 1.1646
--------------------------------------------------
Epoch [15/30] Training loss: 1.1632	 Validation loss: 1.1648
--------------------------------------------------
Epoch [16/30] Training loss: 1.1458	 Validation loss: 1.1641
--------------------------------------------------
Epoch [17/30] Training loss: 1.1547	 Validation loss: 1.1634
--------------------------------------------------
Epoch [18/30] Training loss: 1.1483	 Validation loss: 1.1627
--------------------------------------------------
Epoch [19/30] Training loss: 1.1614	 Validation loss: 1.1623
--------------------------------------------------
Epoch [20/30] Training loss: 1.1562	 Validation loss: 1.1640
--------------------------------------------------
Epoch [21/30] Training loss: 1.1466	 Validation loss: 1.1629
--------------------------------------------------
Epoch [22/30] Training loss: 1.1390	 Validation loss: 1.1633
--------------------------------------------------
Epoch [23/30] Training loss: 1.1189	 Validation loss: 1.1630
--------------------------------------------------
Epoch [24/30] Training loss: 1.1282	 Validation loss: 1.1624
--------------------------------------------------
Epoch [25/30] Training loss: 1.1361	 Validation loss: 1.1625
--------------------------------------------------
Epoch [26/30] Training loss: 1.1225	 Validation loss: 1.1617
--------------------------------------------------
Epoch [27/30] Training loss: 1.1088	 Validation loss: 1.1626
--------------------------------------------------
Epoch [28/30] Training loss: 1.1074	 Validation loss: 1.1617
--------------------------------------------------
Epoch [29/30] Training loss: 1.0904	 Validation loss: 1.1624
--------------------------------------------------
[32m[I 2022-03-26 14:45:37,562][39m Trial 0 finished with value: 1.1640262206395466 and parameters: {'learning_rate': 1.002716662196964e-05, 'num_hidden_units_per_layer': 128, 'weight_decay': 0.00040451769612931155, 'kernel_size': 7, 'num_epochs': 30, 'drop_out': 0.1819180784452692, 'batch_size': 10, 'reduced_seq_length': 200}. Best is trial 0 with value: 1.1640262206395466.
Epoch [30/30] Training loss: 1.1050	 Validation loss: 1.1640
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 4.4586719974988234e-05, 'num_hidden_units_per_layer': 224, 'weight_decay': 2.4129104015184655e-05, 'kernel_size': 9, 'num_epochs': 25, 'drop_out': 0.4527033207403667, 'batch_size': 50, 'reduced_seq_length': 150, 'num_levels': 4, 'stride': 1, 'pos_weight': tensor([6.8261])}