Epoch [1/30] Training loss: 1.2487	 Validation loss: 1.1594
--------------------------------------------------
Epoch [2/30] Training loss: 1.1866	 Validation loss: 1.1638
--------------------------------------------------
Epoch [3/30] Training loss: 1.1817	 Validation loss: 1.1710
--------------------------------------------------
Epoch [4/30] Training loss: 1.1372	 Validation loss: 1.1634
--------------------------------------------------
Epoch [5/30] Training loss: 1.0922	 Validation loss: 1.1612
--------------------------------------------------
Epoch [6/30] Training loss: 1.0705	 Validation loss: 1.1666
--------------------------------------------------
Epoch [7/30] Training loss: 1.0784	 Validation loss: 1.1756
--------------------------------------------------
Epoch [8/30] Training loss: 1.0753	 Validation loss: 1.1749
--------------------------------------------------
Epoch [9/30] Training loss: 1.0642	 Validation loss: 1.1835
--------------------------------------------------
Epoch [10/30] Training loss: 1.0545	 Validation loss: 1.1809
--------------------------------------------------
Epoch [11/30] Training loss: 1.0591	 Validation loss: 1.2385
--------------------------------------------------
Epoch [12/30] Training loss: 0.9842	 Validation loss: 1.2720
--------------------------------------------------
Epoch [13/30] Training loss: 0.9602	 Validation loss: 1.2132
--------------------------------------------------
Epoch [14/30] Training loss: 0.9011	 Validation loss: 1.2251
--------------------------------------------------
Epoch [15/30] Training loss: 0.8751	 Validation loss: 1.2412
--------------------------------------------------
Epoch [16/30] Training loss: 0.7632	 Validation loss: 1.3003
--------------------------------------------------
Epoch [17/30] Training loss: 0.7988	 Validation loss: 1.3060
--------------------------------------------------
Epoch [18/30] Training loss: 0.7347	 Validation loss: 1.4046
--------------------------------------------------
Epoch [19/30] Training loss: 0.7031	 Validation loss: 1.4499
--------------------------------------------------
Epoch [20/30] Training loss: 0.6286	 Validation loss: 1.5009
--------------------------------------------------
Epoch [21/30] Training loss: 0.5652	 Validation loss: 1.6309
--------------------------------------------------
Epoch [22/30] Training loss: 0.6152	 Validation loss: 1.8651
--------------------------------------------------
Epoch [23/30] Training loss: 0.4909	 Validation loss: 1.6753
--------------------------------------------------
Epoch [24/30] Training loss: 0.4812	 Validation loss: 1.9193
--------------------------------------------------
Epoch [25/30] Training loss: 0.4133	 Validation loss: 1.8742
--------------------------------------------------
Epoch [26/30] Training loss: 0.4237	 Validation loss: 2.1780
--------------------------------------------------
Epoch [27/30] Training loss: 0.3302	 Validation loss: 2.0676
--------------------------------------------------
Epoch [28/30] Training loss: 0.3395	 Validation loss: 2.6243
--------------------------------------------------
Epoch [29/30] Training loss: 0.3534	 Validation loss: 2.1299
--------------------------------------------------
Epoch [30/30] Training loss: 0.3780	 Validation loss: 2.1402
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 0.0997966731645594, 'num_hidden_units_per_layer': 64, 'weight_decay': 0.000510832932497317, 'kernel_size': 5, 'num_epochs': 15, 'drop_out': 0.46668439555995034, 'batch_size': 20, 'reduced_seq_length': 40, 'num_levels': 3, 'stride': 1, 'pos_weight': tensor([6.8261])}
[32m[I 2022-03-25 13:55:51,864][39m Trial 18 finished with value: 2.1401893496513367 and parameters: {'learning_rate': 0.00020410630917833838, 'num_hidden_units_per_layer': 128, 'weight_decay': 0.045154405021085794, 'kernel_size': 7, 'num_epochs': 30, 'drop_out': 0.3673234135265, 'batch_size': 30, 'reduced_seq_length': 100}. Best is trial 5 with value: 1.1609607934951782.