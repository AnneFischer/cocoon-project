Epoch [1/25] Training loss: 1.2146	 Validation loss: 1.1806
--------------------------------------------------
Epoch [2/25] Training loss: 1.2100	 Validation loss: 1.1778
--------------------------------------------------
Epoch [3/25] Training loss: 1.2149	 Validation loss: 1.1755
--------------------------------------------------
Epoch [4/25] Training loss: 1.2074	 Validation loss: 1.1743
--------------------------------------------------
Epoch [5/25] Training loss: 1.2215	 Validation loss: 1.1727
--------------------------------------------------
Epoch [6/25] Training loss: 1.2034	 Validation loss: 1.1712
--------------------------------------------------
Epoch [7/25] Training loss: 1.1669	 Validation loss: 1.1704
--------------------------------------------------
Epoch [8/25] Training loss: 1.1767	 Validation loss: 1.1696
--------------------------------------------------
Epoch [9/25] Training loss: 1.2068	 Validation loss: 1.1687
--------------------------------------------------
Epoch [10/25] Training loss: 1.1965	 Validation loss: 1.1680
--------------------------------------------------
Epoch [11/25] Training loss: 1.2032	 Validation loss: 1.1674
--------------------------------------------------
Epoch [12/25] Training loss: 1.2024	 Validation loss: 1.1669
--------------------------------------------------
Epoch [13/25] Training loss: 1.1643	 Validation loss: 1.1666
--------------------------------------------------
Epoch [14/25] Training loss: 1.1688	 Validation loss: 1.1663
--------------------------------------------------
Epoch [15/25] Training loss: 1.1888	 Validation loss: 1.1660
--------------------------------------------------
Epoch [16/25] Training loss: 1.1907	 Validation loss: 1.1659
--------------------------------------------------
Epoch [17/25] Training loss: 1.1589	 Validation loss: 1.1656
--------------------------------------------------
Epoch [18/25] Training loss: 1.1710	 Validation loss: 1.1655
--------------------------------------------------
Epoch [19/25] Training loss: 1.1678	 Validation loss: 1.1652
--------------------------------------------------
Epoch [20/25] Training loss: 1.1680	 Validation loss: 1.1648
--------------------------------------------------
Epoch [21/25] Training loss: 1.1388	 Validation loss: 1.1642
--------------------------------------------------
Epoch [22/25] Training loss: 1.1834	 Validation loss: 1.1637
--------------------------------------------------
Epoch [23/25] Training loss: 1.1729	 Validation loss: 1.1633
--------------------------------------------------
Epoch [24/25] Training loss: 1.1522	 Validation loss: 1.1629
--------------------------------------------------
Epoch [25/25] Training loss: 1.1668	 Validation loss: 1.1622
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 0.04631833359455036, 'num_hidden_units_per_layer': 256, 'weight_decay': 0.003277627486508159, 'kernel_size': 7, 'num_epochs': 50, 'drop_out': 0.15506401798503144, 'batch_size': 10, 'reduced_seq_length': 80, 'num_levels': 4, 'stride': 1, 'pos_weight': tensor([6.8261])}
[32m[I 2022-03-28 10:59:00,339][39m Trial 8 finished with value: 1.1622211933135986 and parameters: {'learning_rate': 5.627597265669135e-05, 'num_hidden_units_per_layer': 64, 'weight_decay': 0.01329807528675216, 'kernel_size': 9, 'num_epochs': 25, 'drop_out': 0.4143668806875601, 'batch_size': 60, 'reduced_seq_length': 170}. Best is trial 8 with value: 1.1622211933135986.