Epoch [1/50] Training loss: 1.2173	 Validation loss: 1.1705
--------------------------------------------------
Epoch [2/50] Training loss: 1.2345	 Validation loss: 1.1611
--------------------------------------------------
Epoch [3/50] Training loss: 1.2090	 Validation loss: 1.1614
--------------------------------------------------
Epoch [4/50] Training loss: 1.2124	 Validation loss: 1.1622
--------------------------------------------------
Epoch [5/50] Training loss: 1.2158	 Validation loss: 1.1637
--------------------------------------------------
Epoch [6/50] Training loss: 1.1919	 Validation loss: 1.1644
--------------------------------------------------
Epoch [7/50] Training loss: 1.1999	 Validation loss: 1.1654
--------------------------------------------------
Epoch [8/50] Training loss: 1.2160	 Validation loss: 1.1659
--------------------------------------------------
Epoch [9/50] Training loss: 1.2073	 Validation loss: 1.1655
--------------------------------------------------
Epoch [10/50] Training loss: 1.2010	 Validation loss: 1.1634
--------------------------------------------------
Epoch [11/50] Training loss: 1.2017	 Validation loss: 1.1641
--------------------------------------------------
Epoch [12/50] Training loss: 1.1919	 Validation loss: 1.1650
--------------------------------------------------
Epoch [13/50] Training loss: 1.2147	 Validation loss: 1.1661
--------------------------------------------------
Epoch [14/50] Training loss: 1.2103	 Validation loss: 1.1660
--------------------------------------------------
Epoch [15/50] Training loss: 1.1945	 Validation loss: 1.1667
--------------------------------------------------
Epoch [16/50] Training loss: 1.2098	 Validation loss: 1.1633
--------------------------------------------------
Epoch [17/50] Training loss: 1.2103	 Validation loss: 1.1629
--------------------------------------------------
Epoch [18/50] Training loss: 1.2242	 Validation loss: 1.1653
--------------------------------------------------
Epoch [19/50] Training loss: 1.1817	 Validation loss: 1.1658
--------------------------------------------------
Epoch [20/50] Training loss: 1.2143	 Validation loss: 1.1643
--------------------------------------------------
Epoch [21/50] Training loss: 1.2029	 Validation loss: 1.1638
--------------------------------------------------
Epoch [22/50] Training loss: 1.2001	 Validation loss: 1.1676
--------------------------------------------------
Epoch [23/50] Training loss: 1.1941	 Validation loss: 1.1678
--------------------------------------------------
Epoch [24/50] Training loss: 1.1918	 Validation loss: 1.1646
--------------------------------------------------
Epoch [25/50] Training loss: 1.1793	 Validation loss: 1.1604
--------------------------------------------------
Epoch [26/50] Training loss: 1.1859	 Validation loss: 1.1595
--------------------------------------------------
Epoch [27/50] Training loss: 1.1686	 Validation loss: 1.1591
--------------------------------------------------
Epoch [28/50] Training loss: 1.1864	 Validation loss: 1.1591
--------------------------------------------------
Epoch [29/50] Training loss: 1.2040	 Validation loss: 1.1628
--------------------------------------------------
Epoch [30/50] Training loss: 1.1731	 Validation loss: 1.1644
--------------------------------------------------
Epoch [31/50] Training loss: 1.2002	 Validation loss: 1.1683
--------------------------------------------------
Epoch [32/50] Training loss: 1.1819	 Validation loss: 1.1636
--------------------------------------------------
Epoch [33/50] Training loss: 1.1640	 Validation loss: 1.1603
--------------------------------------------------
Epoch [34/50] Training loss: 1.1579	 Validation loss: 1.1596
--------------------------------------------------
Epoch [35/50] Training loss: 1.1947	 Validation loss: 1.1607
--------------------------------------------------
Epoch [36/50] Training loss: 1.2045	 Validation loss: 1.1662
--------------------------------------------------
Epoch [37/50] Training loss: 1.1867	 Validation loss: 1.1682
--------------------------------------------------
Epoch [38/50] Training loss: 1.1984	 Validation loss: 1.1681
--------------------------------------------------
Epoch [39/50] Training loss: 1.1796	 Validation loss: 1.1688
--------------------------------------------------
Epoch [40/50] Training loss: 1.1887	 Validation loss: 1.1617
--------------------------------------------------
Epoch [41/50] Training loss: 1.1594	 Validation loss: 1.1607
--------------------------------------------------
Epoch [42/50] Training loss: 1.1504	 Validation loss: 1.1609
--------------------------------------------------
Epoch [43/50] Training loss: 1.1650	 Validation loss: 1.1606
--------------------------------------------------
Epoch [44/50] Training loss: 1.1815	 Validation loss: 1.1603
--------------------------------------------------
Epoch [45/50] Training loss: 1.1928	 Validation loss: 1.1610
--------------------------------------------------
Epoch [46/50] Training loss: 1.1779	 Validation loss: 1.1614
--------------------------------------------------
Epoch [47/50] Training loss: 1.1712	 Validation loss: 1.1618
--------------------------------------------------
Epoch [48/50] Training loss: 1.1637	 Validation loss: 1.1603
--------------------------------------------------
Epoch [49/50] Training loss: 1.1705	 Validation loss: 1.1617
--------------------------------------------------
[32m[I 2022-03-22 14:50:18,926][39m Trial 2 finished with value: 1.1633620262145996 and parameters: {'learning_rate': 0.0004975689860081955, 'num_hidden_units_per_layer': 256, 'weight_decay': 0.0006840841953441877, 'kernel_size': 5, 'num_epochs': 50, 'drop_out': 0.45100304556866944, 'batch_size': 60, 'reduced_seq_length': 10}. Best is trial 0 with value: 1.1620822846889496.
Epoch [50/50] Training loss: 1.1763	 Validation loss: 1.1634
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 0.05995214443599483, 'num_hidden_units_per_layer': 96, 'weight_decay': 0.0002642020823890318, 'kernel_size': 5, 'num_epochs': 45, 'drop_out': 0.28131593575479436, 'batch_size': 40, 'reduced_seq_length': 50, 'num_levels': 4, 'stride': 1, 'pos_weight': tensor([6.8261])}
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0