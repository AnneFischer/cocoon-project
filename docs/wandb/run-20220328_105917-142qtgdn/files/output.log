Epoch [1/50] Training loss: 525.8268	 Validation loss: 2.1364
--------------------------------------------------
Epoch [2/50] Training loss: 4.1531	 Validation loss: 1.2808
--------------------------------------------------
Epoch [3/50] Training loss: 4.9772	 Validation loss: 1.7526
--------------------------------------------------
Epoch [4/50] Training loss: 2.2948	 Validation loss: 1.1617
--------------------------------------------------
Epoch [5/50] Training loss: 2.8303	 Validation loss: 1.0883
--------------------------------------------------
Epoch [6/50] Training loss: 1.3493	 Validation loss: 1.0040
--------------------------------------------------
Epoch [7/50] Training loss: 14.2296	 Validation loss: 1.4964
--------------------------------------------------
Epoch [8/50] Training loss: 3.0087	 Validation loss: 1.4133
--------------------------------------------------
Epoch [9/50] Training loss: 3.1370	 Validation loss: 1.3602
--------------------------------------------------
Epoch [10/50] Training loss: 8.1221	 Validation loss: 1.3480
--------------------------------------------------
Epoch [11/50] Training loss: 1.5229	 Validation loss: 1.8298
--------------------------------------------------
Epoch [12/50] Training loss: 1.3800	 Validation loss: 1.0734
--------------------------------------------------
Epoch [13/50] Training loss: 1.1954	 Validation loss: 1.0459
--------------------------------------------------
Epoch [14/50] Training loss: 1.1417	 Validation loss: 1.1350
--------------------------------------------------
Epoch [15/50] Training loss: 1.0649	 Validation loss: 1.0159
--------------------------------------------------
Epoch [16/50] Training loss: 1.1369	 Validation loss: 1.0474
--------------------------------------------------
Epoch [17/50] Training loss: 1.1488	 Validation loss: 1.0355
--------------------------------------------------
Epoch [18/50] Training loss: 1.2467	 Validation loss: 1.0817
--------------------------------------------------
Epoch [19/50] Training loss: 1.1491	 Validation loss: 1.0175
--------------------------------------------------
Epoch [20/50] Training loss: 0.9703	 Validation loss: 1.2182
--------------------------------------------------
Epoch [21/50] Training loss: 1.1194	 Validation loss: 1.0013
--------------------------------------------------
Epoch [22/50] Training loss: 0.9721	 Validation loss: 1.0302
--------------------------------------------------
Epoch [23/50] Training loss: 0.9111	 Validation loss: 1.1140
--------------------------------------------------
Epoch [24/50] Training loss: 0.7691	 Validation loss: 0.8613
--------------------------------------------------
Epoch [25/50] Training loss: 0.8800	 Validation loss: 0.9614
--------------------------------------------------
Epoch [26/50] Training loss: 0.7587	 Validation loss: 0.9803
--------------------------------------------------
Epoch [27/50] Training loss: 0.6365	 Validation loss: 1.0715
--------------------------------------------------
Epoch [28/50] Training loss: 0.7589	 Validation loss: 0.8455
--------------------------------------------------
Epoch [29/50] Training loss: 0.7029	 Validation loss: 1.0210
--------------------------------------------------
Epoch [30/50] Training loss: 0.5142	 Validation loss: 1.7737
--------------------------------------------------
Epoch [31/50] Training loss: 0.5230	 Validation loss: 1.4978
--------------------------------------------------
Epoch [32/50] Training loss: 0.7781	 Validation loss: 1.0385
--------------------------------------------------
Epoch [33/50] Training loss: 0.9979	 Validation loss: 1.4603
--------------------------------------------------
Epoch [34/50] Training loss: 0.9487	 Validation loss: 1.2480
--------------------------------------------------
Epoch [35/50] Training loss: 0.6055	 Validation loss: 1.1639
--------------------------------------------------
Epoch [36/50] Training loss: 0.7976	 Validation loss: 1.2050
--------------------------------------------------
Epoch [37/50] Training loss: 0.6341	 Validation loss: 1.0503
--------------------------------------------------
Epoch [38/50] Training loss: 0.4944	 Validation loss: 1.1505
--------------------------------------------------
Epoch [39/50] Training loss: 0.6017	 Validation loss: 1.0993
--------------------------------------------------
Epoch [40/50] Training loss: 0.6876	 Validation loss: 0.9991
--------------------------------------------------
Epoch [41/50] Training loss: 0.7013	 Validation loss: 1.1534
--------------------------------------------------
Epoch [42/50] Training loss: 0.6728	 Validation loss: 1.2508
--------------------------------------------------
Epoch [43/50] Training loss: 0.7972	 Validation loss: 1.4137
--------------------------------------------------
Epoch [44/50] Training loss: 0.6943	 Validation loss: 1.2814
--------------------------------------------------
Epoch [45/50] Training loss: 0.6812	 Validation loss: 1.8198
--------------------------------------------------
Epoch [46/50] Training loss: 0.5998	 Validation loss: 1.4653
--------------------------------------------------
Epoch [47/50] Training loss: 0.6787	 Validation loss: 1.3470
--------------------------------------------------
Epoch [48/50] Training loss: 0.7608	 Validation loss: 1.1811
--------------------------------------------------
Epoch [49/50] Training loss: 0.3412	 Validation loss: 1.9291
--------------------------------------------------
[32m[I 2022-03-28 11:10:15,102][39m Trial 9 finished with value: 1.8066975555072229 and parameters: {'learning_rate': 0.04631833359455036, 'num_hidden_units_per_layer': 256, 'weight_decay': 0.003277627486508159, 'kernel_size': 7, 'num_epochs': 50, 'drop_out': 0.15506401798503144, 'batch_size': 10, 'reduced_seq_length': 80}. Best is trial 8 with value: 1.1622211933135986.
Epoch [50/50] Training loss: 0.7369	 Validation loss: 1.8067
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 0.00012770770043511842, 'num_hidden_units_per_layer': 32, 'weight_decay': 0.09656077756527455, 'kernel_size': 9, 'num_epochs': 35, 'drop_out': 0.41153680403472803, 'batch_size': 30, 'reduced_seq_length': 100, 'num_levels': 4, 'stride': 1, 'pos_weight': tensor([6.8261])}