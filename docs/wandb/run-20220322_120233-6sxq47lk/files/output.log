
[32m[I 2022-03-22 12:02:45,876][39m A new study created in memory with name: no-name-c9572025-086c-42b3-b365-57157832e80b
Params: {'learning_rate': 0.0019472026247147618, 'num_hidden_units_per_layer': 32, 'weight_decay': 0.00019278650347650863, 'kernel_size': 5, 'num_epochs': 40, 'drop_out': 0.46715817760177303, 'batch_size': 10, 'reduced_seq_length': 140, 'num_levels': 5, 'stride': 1, 'pos_weight': tensor([6.8261])}
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
Epoch [1/40] Training loss: 1.2780	 Validation loss: 1.1748
--------------------------------------------------
Epoch [2/40] Training loss: 1.2295	 Validation loss: 1.1634
--------------------------------------------------
Epoch [3/40] Training loss: 1.2218	 Validation loss: 1.1690
--------------------------------------------------
Epoch [4/40] Training loss: 1.2214	 Validation loss: 1.1639
--------------------------------------------------
Epoch [5/40] Training loss: 1.2162	 Validation loss: 1.1624
--------------------------------------------------
Epoch [6/40] Training loss: 1.2189	 Validation loss: 1.1617
--------------------------------------------------
Epoch [7/40] Training loss: 1.2219	 Validation loss: 1.1655
--------------------------------------------------
Epoch [8/40] Training loss: 1.2180	 Validation loss: 1.1728
--------------------------------------------------
Epoch [9/40] Training loss: 1.2242	 Validation loss: 1.1671
--------------------------------------------------
Epoch [10/40] Training loss: 1.2189	 Validation loss: 1.1670
--------------------------------------------------
Epoch [11/40] Training loss: 1.2212	 Validation loss: 1.1632
--------------------------------------------------
Epoch [12/40] Training loss: 1.2174	 Validation loss: 1.1679
--------------------------------------------------
Epoch [13/40] Training loss: 1.2104	 Validation loss: 1.1667
--------------------------------------------------
Epoch [14/40] Training loss: 1.2114	 Validation loss: 1.1679
--------------------------------------------------
Epoch [15/40] Training loss: 1.2156	 Validation loss: 1.1628
--------------------------------------------------
Epoch [16/40] Training loss: 1.2109	 Validation loss: 1.1659
--------------------------------------------------
Epoch [17/40] Training loss: 1.2121	 Validation loss: 1.1625
--------------------------------------------------
Epoch [18/40] Training loss: 1.2080	 Validation loss: 1.1618
--------------------------------------------------
Epoch [19/40] Training loss: 1.2220	 Validation loss: 1.1633
--------------------------------------------------
Epoch [20/40] Training loss: 1.2166	 Validation loss: 1.1674
--------------------------------------------------
Epoch [21/40] Training loss: 1.2159	 Validation loss: 1.1665
--------------------------------------------------
Epoch [22/40] Training loss: 1.2182	 Validation loss: 1.1635
--------------------------------------------------
Epoch [23/40] Training loss: 1.2143	 Validation loss: 1.1630
--------------------------------------------------
Epoch [24/40] Training loss: 1.2120	 Validation loss: 1.1645
--------------------------------------------------
Epoch [25/40] Training loss: 1.2137	 Validation loss: 1.1668
--------------------------------------------------
Epoch [26/40] Training loss: 1.2012	 Validation loss: 1.1640
--------------------------------------------------
Epoch [27/40] Training loss: 1.2088	 Validation loss: 1.1634
--------------------------------------------------
Epoch [28/40] Training loss: 1.2137	 Validation loss: 1.1630
--------------------------------------------------
Epoch [29/40] Training loss: 1.2149	 Validation loss: 1.1642
--------------------------------------------------
Epoch [30/40] Training loss: 1.2141	 Validation loss: 1.1677
--------------------------------------------------
Epoch [31/40] Training loss: 1.2204	 Validation loss: 1.1707
--------------------------------------------------
Epoch [32/40] Training loss: 1.2132	 Validation loss: 1.1665
--------------------------------------------------
Epoch [33/40] Training loss: 1.2134	 Validation loss: 1.1670
--------------------------------------------------
Epoch [34/40] Training loss: 1.2162	 Validation loss: 1.1651
--------------------------------------------------
Epoch [35/40] Training loss: 1.2078	 Validation loss: 1.1627
--------------------------------------------------
Epoch [36/40] Training loss: 1.2121	 Validation loss: 1.1625
--------------------------------------------------
Epoch [37/40] Training loss: 1.2119	 Validation loss: 1.1650
--------------------------------------------------
Epoch [38/40] Training loss: 1.2120	 Validation loss: 1.1622
--------------------------------------------------
Epoch [39/40] Training loss: 1.2130	 Validation loss: 1.1636
--------------------------------------------------
[32m[I 2022-03-22 12:04:15,642][39m Trial 0 finished with value: 1.1627343793710072 and parameters: {'learning_rate': 0.0019472026247147618, 'num_hidden_units_per_layer': 32, 'weight_decay': 0.00019278650347650863, 'kernel_size': 5, 'num_epochs': 40, 'drop_out': 0.46715817760177303, 'batch_size': 10, 'reduced_seq_length': 140}. Best is trial 0 with value: 1.1627343793710072.
Epoch [40/40] Training loss: 1.2089	 Validation loss: 1.1627
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 1.8481913405731786e-05, 'num_hidden_units_per_layer': 224, 'weight_decay': 0.0021811973826807657, 'kernel_size': 3, 'num_epochs': 10, 'drop_out': 0.4050271608389924, 'batch_size': 10, 'reduced_seq_length': 100, 'num_levels': 6, 'stride': 1, 'pos_weight': tensor([6.8261])}
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 1 < 40; dropping {'epoch': 1, 'train_loss': 1.2095168961419, 'val_loss': 1.165120780467987}.
Epoch [1/10] Training loss: 1.2095	 Validation loss: 1.1651
--------------------------------------------------
Epoch [2/10] Training loss: 1.1952	 Validation loss: 1.1659
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 2 < 40; dropping {'epoch': 2, 'train_loss': 1.1952270501189761, 'val_loss': 1.1658977071444194}.
Epoch [3/10] Training loss: 1.2151	 Validation loss: 1.1633
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 3 < 40; dropping {'epoch': 3, 'train_loss': 1.2150546941492293, 'val_loss': 1.1633256872495015}.
Epoch [4/10] Training loss: 1.2112	 Validation loss: 1.1636
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 4 < 40; dropping {'epoch': 4, 'train_loss': 1.2111872335275014, 'val_loss': 1.163556585709254}.
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 5 < 40; dropping {'epoch': 5, 'train_loss': 1.2119788891739316, 'val_loss': 1.1626511017481487}.
Epoch [5/10] Training loss: 1.2120	 Validation loss: 1.1627
--------------------------------------------------
Epoch [6/10] Training loss: 1.1944	 Validation loss: 1.1628
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 6 < 40; dropping {'epoch': 6, 'train_loss': 1.1944171620739832, 'val_loss': 1.1628259718418121}.
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 7 < 40; dropping {'epoch': 7, 'train_loss': 1.2247813012864854, 'val_loss': 1.1635860403378804}.
Epoch [7/10] Training loss: 1.2248	 Validation loss: 1.1636
--------------------------------------------------
Epoch [8/10] Training loss: 1.1865	 Validation loss: 1.1634
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 8 < 40; dropping {'epoch': 8, 'train_loss': 1.1864755418565538, 'val_loss': 1.1633932987848918}.
Epoch [9/10] Training loss: 1.2197	 Validation loss: 1.1629
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 9 < 40; dropping {'epoch': 9, 'train_loss': 1.219738142357932, 'val_loss': 1.1629408796628316}.
Epoch [10/10] Training loss: 1.2153	 Validation loss: 1.1632
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 0.00028716194617925503, 'num_hidden_units_per_layer': 160, 'weight_decay': 0.0014983542642368712, 'kernel_size': 7, 'num_epochs': 45, 'drop_out': 0.3976951875527348, 'batch_size': 40, 'reduced_seq_length': 40, 'num_levels': 3, 'stride': 1, 'pos_weight': tensor([6.8261])}
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 10 < 40; dropping {'epoch': 10, 'train_loss': 1.215257250600391, 'val_loss': 1.1632221043109894}.
[32m[I 2022-03-22 13:11:57,508][39m Trial 1 finished with value: 1.1632221043109894 and parameters: {'learning_rate': 1.8481913405731786e-05, 'num_hidden_units_per_layer': 224, 'weight_decay': 0.0021811973826807657, 'kernel_size': 3, 'num_epochs': 10, 'drop_out': 0.4050271608389924, 'batch_size': 10, 'reduced_seq_length': 100}. Best is trial 0 with value: 1.1627343793710072.
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
Epoch [1/45] Training loss: 1.2269	 Validation loss: 1.1649
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 1 < 40; dropping {'epoch': 1, 'train_loss': 1.2268813914722867, 'val_loss': 1.164929946263631}.
Epoch [2/45] Training loss: 1.2179	 Validation loss: 1.1613
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 2 < 40; dropping {'epoch': 2, 'train_loss': 1.2179050048192341, 'val_loss': 1.1613476276397705}.
Epoch [3/45] Training loss: 1.2265	 Validation loss: 1.1656
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 3 < 40; dropping {'epoch': 3, 'train_loss': 1.2264620727962918, 'val_loss': 1.1655898094177246}.
Epoch [4/45] Training loss: 1.2176	 Validation loss: 1.1642
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 4 < 40; dropping {'epoch': 4, 'train_loss': 1.2176187170876398, 'val_loss': 1.164192756017049}.
Epoch [5/45] Training loss: 1.2148	 Validation loss: 1.1740
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 5 < 40; dropping {'epoch': 5, 'train_loss': 1.2148495250278049, 'val_loss': 1.1740463177363079}.
Epoch [6/45] Training loss: 1.2075	 Validation loss: 1.1743
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 6 < 40; dropping {'epoch': 6, 'train_loss': 1.2074520852830675, 'val_loss': 1.1743217309315999}.
Epoch [7/45] Training loss: 1.2186	 Validation loss: 1.1637
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 7 < 40; dropping {'epoch': 7, 'train_loss': 1.2186093065473769, 'val_loss': 1.163679043451945}.
Epoch [8/45] Training loss: 1.2204	 Validation loss: 1.1620
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 8 < 40; dropping {'epoch': 8, 'train_loss': 1.220431963602702, 'val_loss': 1.1620287895202637}.
Epoch [9/45] Training loss: 1.2415	 Validation loss: 1.1615
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 9 < 40; dropping {'epoch': 9, 'train_loss': 1.24152676264445, 'val_loss': 1.1614656845728557}.
Epoch [10/45] Training loss: 1.2172	 Validation loss: 1.1654
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 10 < 40; dropping {'epoch': 10, 'train_loss': 1.217214584350586, 'val_loss': 1.165417989095052}.
Epoch [11/45] Training loss: 1.2035	 Validation loss: 1.1775
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 11 < 40; dropping {'epoch': 11, 'train_loss': 1.2035406960381403, 'val_loss': 1.177493651707967}.
Epoch [12/45] Training loss: 1.2209	 Validation loss: 1.1761
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 12 < 40; dropping {'epoch': 12, 'train_loss': 1.2208802567587957, 'val_loss': 1.1761222680409749}.
Epoch [13/45] Training loss: 1.1958	 Validation loss: 1.1724
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 13 < 40; dropping {'epoch': 13, 'train_loss': 1.1957990063561335, 'val_loss': 1.1723562479019165}.
Epoch [14/45] Training loss: 1.2228	 Validation loss: 1.1676
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 14 < 40; dropping {'epoch': 14, 'train_loss': 1.2227927645047505, 'val_loss': 1.1676080226898193}.
Epoch [15/45] Training loss: 1.2167	 Validation loss: 1.1612
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 15 < 40; dropping {'epoch': 15, 'train_loss': 1.216741959253947, 'val_loss': 1.1611893971761067}.
Epoch [16/45] Training loss: 1.2128	 Validation loss: 1.1604
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 16 < 40; dropping {'epoch': 16, 'train_loss': 1.2127650048997667, 'val_loss': 1.1604458491007488}.
Epoch [17/45] Training loss: 1.2181	 Validation loss: 1.1630
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 17 < 40; dropping {'epoch': 17, 'train_loss': 1.218056148952908, 'val_loss': 1.1630239486694336}.
Epoch [18/45] Training loss: 1.2294	 Validation loss: 1.1808
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 18 < 40; dropping {'epoch': 18, 'train_loss': 1.2294387420018513, 'val_loss': 1.1808316310246785}.
Epoch [19/45] Training loss: 1.2162	 Validation loss: 1.1623
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 19 < 40; dropping {'epoch': 19, 'train_loss': 1.2162396709124248, 'val_loss': 1.162343422571818}.
Epoch [20/45] Training loss: 1.2374	 Validation loss: 1.1609
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 20 < 40; dropping {'epoch': 20, 'train_loss': 1.237444559733073, 'val_loss': 1.1608888705571492}.
Epoch [21/45] Training loss: 1.2500	 Validation loss: 1.1597
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 21 < 40; dropping {'epoch': 21, 'train_loss': 1.2499545812606812, 'val_loss': 1.1597471237182617}.
Epoch [22/45] Training loss: 1.2034	 Validation loss: 1.1710
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 22 < 40; dropping {'epoch': 22, 'train_loss': 1.2034034861458673, 'val_loss': 1.1709824005762737}.
Epoch [23/45] Training loss: 1.2038	 Validation loss: 1.1710
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 23 < 40; dropping {'epoch': 23, 'train_loss': 1.203820480240716, 'val_loss': 1.171049952507019}.
Epoch [24/45] Training loss: 1.2097	 Validation loss: 1.1616
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 24 < 40; dropping {'epoch': 24, 'train_loss': 1.2096649938159518, 'val_loss': 1.1615507205327351}.
Epoch [25/45] Training loss: 1.2179	 Validation loss: 1.1589
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 25 < 40; dropping {'epoch': 25, 'train_loss': 1.2178776661554973, 'val_loss': 1.1588858763376872}.
Epoch [26/45] Training loss: 1.2004	 Validation loss: 1.1609
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 26 < 40; dropping {'epoch': 26, 'train_loss': 1.2004364728927612, 'val_loss': 1.160871108373006}.
Epoch [27/45] Training loss: 1.2054	 Validation loss: 1.1604
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 27 < 40; dropping {'epoch': 27, 'train_loss': 1.2053608894348145, 'val_loss': 1.1604469219843547}.
Epoch [28/45] Training loss: 1.1770	 Validation loss: 1.1636
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 28 < 40; dropping {'epoch': 28, 'train_loss': 1.1770004034042358, 'val_loss': 1.1636049350102742}.
Epoch [29/45] Training loss: 1.2139	 Validation loss: 1.1680
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 29 < 40; dropping {'epoch': 29, 'train_loss': 1.2139487001630995, 'val_loss': 1.1679717699686687}.
Epoch [30/45] Training loss: 1.2082	 Validation loss: 1.1698
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 30 < 40; dropping {'epoch': 30, 'train_loss': 1.2081769174999661, 'val_loss': 1.1698386669158936}.
Epoch [31/45] Training loss: 1.2352	 Validation loss: 1.1604
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 31 < 40; dropping {'epoch': 31, 'train_loss': 1.2351861397425334, 'val_loss': 1.1603601773579915}.
Epoch [32/45] Training loss: 1.1886	 Validation loss: 1.1679
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 32 < 40; dropping {'epoch': 32, 'train_loss': 1.1886094278759427, 'val_loss': 1.1679161389668782}.
Epoch [33/45] Training loss: 1.1835	 Validation loss: 1.1630
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 33 < 40; dropping {'epoch': 33, 'train_loss': 1.183452910847134, 'val_loss': 1.1630261341730754}.
Epoch [34/45] Training loss: 1.1912	 Validation loss: 1.1639
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 34 < 40; dropping {'epoch': 34, 'train_loss': 1.1911620961295233, 'val_loss': 1.1639150778452556}.
Epoch [35/45] Training loss: 1.2155	 Validation loss: 1.1807
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 35 < 40; dropping {'epoch': 35, 'train_loss': 1.2154896259307861, 'val_loss': 1.180686076482137}.
Epoch [36/45] Training loss: 1.2369	 Validation loss: 1.1655
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 36 < 40; dropping {'epoch': 36, 'train_loss': 1.2369311253229778, 'val_loss': 1.1654877265294392}.
Epoch [37/45] Training loss: 1.2183	 Validation loss: 1.1646
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 37 < 40; dropping {'epoch': 37, 'train_loss': 1.2183473640018039, 'val_loss': 1.164566953976949}.
Epoch [38/45] Training loss: 1.2199	 Validation loss: 1.1649
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 38 < 40; dropping {'epoch': 38, 'train_loss': 1.2198541429307725, 'val_loss': 1.1648541688919067}.
Epoch [39/45] Training loss: 1.1970	 Validation loss: 1.1615
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 39 < 40; dropping {'epoch': 39, 'train_loss': 1.1970241202248468, 'val_loss': 1.1615341901779175}.
Epoch [40/45] Training loss: 1.1708	 Validation loss: 1.1625
--------------------------------------------------
Epoch [41/45] Training loss: 1.2348	 Validation loss: 1.1627
--------------------------------------------------
Epoch [42/45] Training loss: 1.2049	 Validation loss: 1.1610
--------------------------------------------------
Epoch [43/45] Training loss: 1.2156	 Validation loss: 1.1594
--------------------------------------------------
Epoch [44/45] Training loss: 1.1979	 Validation loss: 1.1681
--------------------------------------------------
Epoch [45/45] Training loss: 1.2147	 Validation loss: 1.1657
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 0.0005639986104966228, 'num_hidden_units_per_layer': 160, 'weight_decay': 0.010237426974145463, 'kernel_size': 3, 'num_epochs': 20, 'drop_out': 0.3638129310380509, 'batch_size': 50, 'reduced_seq_length': 160, 'num_levels': 6, 'stride': 1, 'pos_weight': tensor([6.8261])}
[32m[I 2022-03-22 13:15:03,388][39m Trial 2 finished with value: 1.1657407681147258 and parameters: {'learning_rate': 0.00028716194617925503, 'num_hidden_units_per_layer': 160, 'weight_decay': 0.0014983542642368712, 'kernel_size': 7, 'num_epochs': 45, 'drop_out': 0.3976951875527348, 'batch_size': 40, 'reduced_seq_length': 40}. Best is trial 0 with value: 1.1627343793710072.
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 1 < 45; dropping {'epoch': 1, 'train_loss': 1.3236102395587497, 'val_loss': 1.1620702147483826}.
Epoch [1/20] Training loss: 1.3236	 Validation loss: 1.1621
--------------------------------------------------
Epoch [2/20] Training loss: 1.2006	 Validation loss: 1.1842
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 2 < 45; dropping {'epoch': 2, 'train_loss': 1.20058540503184, 'val_loss': 1.1842230955759685}.
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 3 < 45; dropping {'epoch': 3, 'train_loss': 1.2501608067088656, 'val_loss': 1.1779549519220989}.
Epoch [3/20] Training loss: 1.2502	 Validation loss: 1.1780
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 4 < 45; dropping {'epoch': 4, 'train_loss': 1.231347491343816, 'val_loss': 1.1614579955736797}.
Epoch [4/20] Training loss: 1.2313	 Validation loss: 1.1615
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 5 < 45; dropping {'epoch': 5, 'train_loss': 1.2103524174955156, 'val_loss': 1.1609750787417095}.
Epoch [5/20] Training loss: 1.2104	 Validation loss: 1.1610
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 6 < 45; dropping {'epoch': 6, 'train_loss': 1.2075624995761447, 'val_loss': 1.165747344493866}.
Epoch [6/20] Training loss: 1.2076	 Validation loss: 1.1657
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 7 < 45; dropping {'epoch': 7, 'train_loss': 1.2331258787049189, 'val_loss': 1.1821564833323162}.
Epoch [7/20] Training loss: 1.2331	 Validation loss: 1.1822
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 8 < 45; dropping {'epoch': 8, 'train_loss': 1.2407195170720418, 'val_loss': 1.1600907643636067}.
Epoch [8/20] Training loss: 1.2407	 Validation loss: 1.1601
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 9 < 45; dropping {'epoch': 9, 'train_loss': 1.24012025197347, 'val_loss': 1.1609082221984863}.
Epoch [9/20] Training loss: 1.2401	 Validation loss: 1.1609
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 10 < 45; dropping {'epoch': 10, 'train_loss': 1.207860807577769, 'val_loss': 1.1621995170911152}.
Epoch [10/20] Training loss: 1.2079	 Validation loss: 1.1622
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 11 < 45; dropping {'epoch': 11, 'train_loss': 1.1836979985237122, 'val_loss': 1.1710170706113179}.
Epoch [11/20] Training loss: 1.1837	 Validation loss: 1.1710
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 12 < 45; dropping {'epoch': 12, 'train_loss': 1.2616068919499714, 'val_loss': 1.1613264083862305}.
Epoch [12/20] Training loss: 1.2616	 Validation loss: 1.1613
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 13 < 45; dropping {'epoch': 13, 'train_loss': 1.2377005418141682, 'val_loss': 1.1646596988042195}.
Epoch [13/20] Training loss: 1.2377	 Validation loss: 1.1647
--------------------------------------------------
Epoch [14/20] Training loss: 1.2162	 Validation loss: 1.1818
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 14 < 45; dropping {'epoch': 14, 'train_loss': 1.2161643968688116, 'val_loss': 1.181764582792918}.
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 15 < 45; dropping {'epoch': 15, 'train_loss': 1.235847658581204, 'val_loss': 1.162724534670512}.
Epoch [15/20] Training loss: 1.2358	 Validation loss: 1.1627
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 16 < 45; dropping {'epoch': 16, 'train_loss': 1.2495028773943584, 'val_loss': 1.1702086528142293}.
Epoch [16/20] Training loss: 1.2495	 Validation loss: 1.1702
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 17 < 45; dropping {'epoch': 17, 'train_loss': 1.2143836220105488, 'val_loss': 1.161526083946228}.
Epoch [17/20] Training loss: 1.2144	 Validation loss: 1.1615
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 18 < 45; dropping {'epoch': 18, 'train_loss': 1.234733561674754, 'val_loss': 1.1660583019256592}.
Epoch [18/20] Training loss: 1.2347	 Validation loss: 1.1661
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 19 < 45; dropping {'epoch': 19, 'train_loss': 1.215654022163815, 'val_loss': 1.1630786856015523}.
Epoch [19/20] Training loss: 1.2157	 Validation loss: 1.1631
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 20 < 45; dropping {'epoch': 20, 'train_loss': 1.2318324347337086, 'val_loss': 1.1585681239763896}.
[32m[I 2022-03-22 13:17:45,112][39m Trial 3 finished with value: 1.1585681239763896 and parameters: {'learning_rate': 0.0005639986104966228, 'num_hidden_units_per_layer': 160, 'weight_decay': 0.010237426974145463, 'kernel_size': 3, 'num_epochs': 20, 'drop_out': 0.3638129310380509, 'batch_size': 50, 'reduced_seq_length': 160}. Best is trial 3 with value: 1.1585681239763896.
Epoch [20/20] Training loss: 1.2318	 Validation loss: 1.1586
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 0.014803128712213492, 'num_hidden_units_per_layer': 256, 'weight_decay': 1.5547560847152715e-05, 'kernel_size': 3, 'num_epochs': 50, 'drop_out': 0.12111495895799354, 'batch_size': 40, 'reduced_seq_length': 100, 'num_levels': 6, 'stride': 1, 'pos_weight': tensor([6.8261])}
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
Epoch [1/50] Training loss: 7406.2580	 Validation loss: 7.0922
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 1 < 45; dropping {'epoch': 1, 'train_loss': 7406.257984823651, 'val_loss': 7.092230319976807}.
Epoch [2/50] Training loss: 4.1151	 Validation loss: 1.4946
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 2 < 45; dropping {'epoch': 2, 'train_loss': 4.115129550298055, 'val_loss': 1.4946150382359822}.
Epoch [3/50] Training loss: 1.4568	 Validation loss: 1.3094
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 3 < 45; dropping {'epoch': 3, 'train_loss': 1.4567965136633978, 'val_loss': 1.3093750476837158}.
Epoch [4/50] Training loss: 1.5654	 Validation loss: 1.2445
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 4 < 45; dropping {'epoch': 4, 'train_loss': 1.5654339260525174, 'val_loss': 1.244490146636963}.
Epoch [5/50] Training loss: 1.3284	 Validation loss: 1.1658
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 5 < 45; dropping {'epoch': 5, 'train_loss': 1.3283875385920207, 'val_loss': 1.1657978693644206}.
Epoch [6/50] Training loss: 1.2102	 Validation loss: 1.1704
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 6 < 45; dropping {'epoch': 6, 'train_loss': 1.2102195819218953, 'val_loss': 1.170361042022705}.
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 7 < 45; dropping {'epoch': 7, 'train_loss': 1.2818120850457086, 'val_loss': 1.1689844926198323}.
Epoch [7/50] Training loss: 1.2818	 Validation loss: 1.1690
--------------------------------------------------
Epoch [8/50] Training loss: 1.2882	 Validation loss: 1.1863
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 8 < 45; dropping {'epoch': 8, 'train_loss': 1.288223319583469, 'val_loss': 1.1862705945968628}.
Epoch [9/50] Training loss: 1.3390	 Validation loss: 1.1636
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 9 < 45; dropping {'epoch': 9, 'train_loss': 1.3389787409040663, 'val_loss': 1.1636048952738445}.
Epoch [10/50] Training loss: 1.2269	 Validation loss: 1.1544
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 10 < 45; dropping {'epoch': 10, 'train_loss': 1.2269286049736872, 'val_loss': 1.1544098059336345}.