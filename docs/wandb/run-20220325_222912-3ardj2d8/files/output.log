Epoch [1/15] Training loss: 1.2368	 Validation loss: 1.1842
--------------------------------------------------
Epoch [2/15] Training loss: 1.1971	 Validation loss: 1.1839
--------------------------------------------------
Epoch [3/15] Training loss: 1.2022	 Validation loss: 1.1835
--------------------------------------------------
Epoch [4/15] Training loss: 1.2083	 Validation loss: 1.1833
--------------------------------------------------
Epoch [5/15] Training loss: 1.2205	 Validation loss: 1.1831
--------------------------------------------------
Epoch [6/15] Training loss: 1.2187	 Validation loss: 1.1828
--------------------------------------------------
[32m[I 2022-03-25 22:29:25,941][39m Trial 5 finished with value: 1.1814854145050049 and parameters: {'learning_rate': 1.5456961350055723e-05, 'num_hidden_units_per_layer': 32, 'weight_decay': 0.08552209736943334, 'kernel_size': 9, 'num_epochs': 15, 'drop_out': 0.3902472444218624, 'batch_size': 20, 'reduced_seq_length': 30}. Best is trial 5 with value: 1.1814854145050049.
Epoch [7/15] Training loss: 1.2237	 Validation loss: 1.1826
--------------------------------------------------
Epoch [8/15] Training loss: 1.2030	 Validation loss: 1.1825
--------------------------------------------------
Epoch [9/15] Training loss: 1.2071	 Validation loss: 1.1823
--------------------------------------------------
Epoch [10/15] Training loss: 1.2066	 Validation loss: 1.1821
--------------------------------------------------
Epoch [11/15] Training loss: 1.1982	 Validation loss: 1.1819
--------------------------------------------------
Epoch [12/15] Training loss: 1.1921	 Validation loss: 1.1818
--------------------------------------------------
Epoch [13/15] Training loss: 1.2261	 Validation loss: 1.1818
--------------------------------------------------
Epoch [14/15] Training loss: 1.2163	 Validation loss: 1.1816
--------------------------------------------------
Epoch [15/15] Training loss: 1.2254	 Validation loss: 1.1815
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 0.0005773832279918202, 'num_hidden_units_per_layer': 64, 'weight_decay': 0.044768485884620554, 'kernel_size': 9, 'num_epochs': 40, 'drop_out': 0.10325963734806805, 'batch_size': 50, 'reduced_seq_length': 140, 'num_levels': 4, 'stride': 1, 'pos_weight': tensor([6.8261])}