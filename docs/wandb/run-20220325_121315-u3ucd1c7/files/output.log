Epoch [1/20] Training loss: 1.2371	 Validation loss: 1.1747
--------------------------------------------------
Epoch [2/20] Training loss: 1.2209	 Validation loss: 1.1653
--------------------------------------------------
Epoch [3/20] Training loss: 1.2074	 Validation loss: 1.1614
--------------------------------------------------
Epoch [4/20] Training loss: 1.1990	 Validation loss: 1.1610
--------------------------------------------------
Epoch [5/20] Training loss: 1.1647	 Validation loss: 1.1613
--------------------------------------------------
Epoch [6/20] Training loss: 1.1493	 Validation loss: 1.1622
--------------------------------------------------
Epoch [7/20] Training loss: 1.1630	 Validation loss: 1.1651
--------------------------------------------------
Epoch [8/20] Training loss: 1.1198	 Validation loss: 1.1627
--------------------------------------------------
Epoch [9/20] Training loss: 1.1414	 Validation loss: 1.1619
--------------------------------------------------
Epoch [10/20] Training loss: 1.1143	 Validation loss: 1.1656
--------------------------------------------------
Epoch [11/20] Training loss: 1.1045	 Validation loss: 1.1685
--------------------------------------------------
Epoch [12/20] Training loss: 1.0851	 Validation loss: 1.1680
--------------------------------------------------
Epoch [13/20] Training loss: 1.0719	 Validation loss: 1.1667
--------------------------------------------------
Epoch [14/20] Training loss: 1.0593	 Validation loss: 1.1648
--------------------------------------------------
Epoch [15/20] Training loss: 1.0100	 Validation loss: 1.1636
--------------------------------------------------
Epoch [16/20] Training loss: 0.9778	 Validation loss: 1.1611
--------------------------------------------------
Epoch [17/20] Training loss: 0.9620	 Validation loss: 1.1664
--------------------------------------------------
Epoch [18/20] Training loss: 0.8902	 Validation loss: 1.1718
--------------------------------------------------
[32m[I 2022-03-25 12:13:35,322][39m Trial 2 finished with value: 1.1736648678779602 and parameters: {'learning_rate': 0.0005667132127687578, 'num_hidden_units_per_layer': 32, 'weight_decay': 0.0005730950500122542, 'kernel_size': 7, 'num_epochs': 20, 'drop_out': 0.3025444674992914, 'batch_size': 30, 'reduced_seq_length': 80}. Best is trial 2 with value: 1.1736648678779602.
Epoch [19/20] Training loss: 0.9179	 Validation loss: 1.1764
--------------------------------------------------
Epoch [20/20] Training loss: 0.8322	 Validation loss: 1.1737
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 0.00047704191157793823, 'num_hidden_units_per_layer': 192, 'weight_decay': 1.637453695533046e-05, 'kernel_size': 7, 'num_epochs': 20, 'drop_out': 0.440489631245937, 'batch_size': 20, 'reduced_seq_length': 60, 'num_levels': 4, 'stride': 1, 'pos_weight': tensor([6.8261])}