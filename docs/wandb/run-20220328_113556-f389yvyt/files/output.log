Epoch [1/15] Training loss: 1.2495	 Validation loss: 1.2117
--------------------------------------------------
Epoch [2/15] Training loss: 1.2512	 Validation loss: 1.1999
--------------------------------------------------
Epoch [3/15] Training loss: 1.2045	 Validation loss: 1.1897
--------------------------------------------------
Epoch [4/15] Training loss: 1.2213	 Validation loss: 1.1823
--------------------------------------------------
Epoch [5/15] Training loss: 1.2209	 Validation loss: 1.1772
--------------------------------------------------
Epoch [6/15] Training loss: 1.2186	 Validation loss: 1.1733
--------------------------------------------------
Epoch [7/15] Training loss: 1.2007	 Validation loss: 1.1699
--------------------------------------------------
Epoch [8/15] Training loss: 1.1965	 Validation loss: 1.1674
--------------------------------------------------
Epoch [9/15] Training loss: 1.2069	 Validation loss: 1.1660
--------------------------------------------------
Epoch [10/15] Training loss: 1.2083	 Validation loss: 1.1659
--------------------------------------------------
Epoch [11/15] Training loss: 1.1909	 Validation loss: 1.1653
--------------------------------------------------
Epoch [12/15] Training loss: 1.1920	 Validation loss: 1.1640
--------------------------------------------------
Epoch [13/15] Training loss: 1.1708	 Validation loss: 1.1632
--------------------------------------------------
Epoch [14/15] Training loss: 1.1804	 Validation loss: 1.1619
--------------------------------------------------
[32m[I 2022-03-28 11:36:25,724][39m Trial 24 finished with value: 1.1602805058161418 and parameters: {'learning_rate': 7.864941399192223e-05, 'num_hidden_units_per_layer': 32, 'weight_decay': 3.0376996677345096e-06, 'kernel_size': 9, 'num_epochs': 15, 'drop_out': 0.2891129876358572, 'batch_size': 20, 'reduced_seq_length': 170}. Best is trial 11 with value: 1.1504377126693726.
Epoch [15/15] Training loss: 1.1885	 Validation loss: 1.1603
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 1.1992378575307765e-05, 'num_hidden_units_per_layer': 96, 'weight_decay': 2.6616847642989824e-06, 'kernel_size': 7, 'num_epochs': 15, 'drop_out': 0.28563910904765955, 'batch_size': 20, 'reduced_seq_length': 160, 'num_levels': 5, 'stride': 1, 'pos_weight': tensor([6.8261])}