Epoch [1/45] Training loss: 2.6623	 Validation loss: 1.2040
--------------------------------------------------
Epoch [2/45] Training loss: 1.2302	 Validation loss: 1.1954
--------------------------------------------------
Epoch [3/45] Training loss: 1.2146	 Validation loss: 1.1775
--------------------------------------------------
Epoch [4/45] Training loss: 1.1908	 Validation loss: 1.1769
--------------------------------------------------
Epoch [5/45] Training loss: 1.2252	 Validation loss: 1.1820
--------------------------------------------------
Epoch [6/45] Training loss: 1.2023	 Validation loss: 1.1851
--------------------------------------------------
Epoch [7/45] Training loss: 1.1941	 Validation loss: 1.1820
--------------------------------------------------
Epoch [8/45] Training loss: 1.1835	 Validation loss: 1.1748
--------------------------------------------------
Epoch [9/45] Training loss: 1.1869	 Validation loss: 1.1718
--------------------------------------------------
Epoch [10/45] Training loss: 1.1881	 Validation loss: 1.1766
--------------------------------------------------
Epoch [11/45] Training loss: 1.1656	 Validation loss: 1.1732
--------------------------------------------------
Epoch [12/45] Training loss: 1.1539	 Validation loss: 1.1672
--------------------------------------------------
Epoch [13/45] Training loss: 1.1413	 Validation loss: 1.1549
--------------------------------------------------
Epoch [14/45] Training loss: 1.1350	 Validation loss: 1.1521
--------------------------------------------------
Epoch [15/45] Training loss: 1.1057	 Validation loss: 1.1359
--------------------------------------------------
Epoch [16/45] Training loss: 1.1172	 Validation loss: 1.1282
--------------------------------------------------
Epoch [17/45] Training loss: 1.0392	 Validation loss: 1.1007
--------------------------------------------------
Epoch [18/45] Training loss: 1.0202	 Validation loss: 1.0630
--------------------------------------------------
Epoch [19/45] Training loss: 0.9605	 Validation loss: 1.0892
--------------------------------------------------
Epoch [20/45] Training loss: 0.9334	 Validation loss: 1.0492
--------------------------------------------------
Epoch [21/45] Training loss: 0.8808	 Validation loss: 1.0699
--------------------------------------------------
Epoch [22/45] Training loss: 0.7537	 Validation loss: 1.1791
--------------------------------------------------
Epoch [23/45] Training loss: 0.6773	 Validation loss: 1.2212
--------------------------------------------------
Epoch [24/45] Training loss: 0.5828	 Validation loss: 1.6217
--------------------------------------------------
Epoch [25/45] Training loss: 0.6821	 Validation loss: 1.4115
--------------------------------------------------
Epoch [26/45] Training loss: 0.6219	 Validation loss: 1.8125
--------------------------------------------------
Epoch [27/45] Training loss: 0.6855	 Validation loss: 1.6385
--------------------------------------------------
Epoch [28/45] Training loss: 0.6064	 Validation loss: 1.7178
--------------------------------------------------
Epoch [29/45] Training loss: 0.5609	 Validation loss: 2.0955
--------------------------------------------------
Epoch [30/45] Training loss: 0.5082	 Validation loss: 1.8886
--------------------------------------------------
Epoch [31/45] Training loss: 0.4572	 Validation loss: 2.3810
--------------------------------------------------
Epoch [32/45] Training loss: 0.4824	 Validation loss: 2.6634
--------------------------------------------------
Epoch [33/45] Training loss: 0.3787	 Validation loss: 1.9620
--------------------------------------------------
Epoch [34/45] Training loss: 0.4191	 Validation loss: 2.8446
--------------------------------------------------
Epoch [35/45] Training loss: 0.2816	 Validation loss: 3.1901
--------------------------------------------------
Epoch [36/45] Training loss: 0.3202	 Validation loss: 2.8883
--------------------------------------------------
Epoch [37/45] Training loss: 0.2434	 Validation loss: 3.5981
--------------------------------------------------
Epoch [38/45] Training loss: 0.3007	 Validation loss: 2.8920
--------------------------------------------------
Epoch [39/45] Training loss: 0.2356	 Validation loss: 3.3920
--------------------------------------------------
Epoch [40/45] Training loss: 0.2420	 Validation loss: 4.2149
--------------------------------------------------
Epoch [41/45] Training loss: 0.3258	 Validation loss: 3.6606
--------------------------------------------------
Epoch [42/45] Training loss: 0.2974	 Validation loss: 3.9362
--------------------------------------------------
Epoch [43/45] Training loss: 0.1178	 Validation loss: 5.8054
--------------------------------------------------
Epoch [44/45] Training loss: 0.2357	 Validation loss: 4.6173
--------------------------------------------------
[32m[I 2022-03-24 08:58:42,060][39m Trial 16 finished with value: 4.503679871559143 and parameters: {'learning_rate': 0.0066867301821178825, 'num_hidden_units_per_layer': 128, 'weight_decay': 0.00015618213636883733, 'kernel_size': 3, 'num_epochs': 45, 'drop_out': 0.35859664257823254, 'batch_size': 30, 'reduced_seq_length': 70}. Best is trial 3 with value: 0.9335269729296366.
Epoch [45/45] Training loss: 0.2264	 Validation loss: 4.5037
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 0.0006239758741025856, 'num_hidden_units_per_layer': 64, 'weight_decay': 0.0017860376089959293, 'kernel_size': 7, 'num_epochs': 35, 'drop_out': 0.23263915896801657, 'batch_size': 50, 'reduced_seq_length': 120, 'num_levels': 5, 'stride': 1, 'pos_weight': tensor([6.8261])}
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0