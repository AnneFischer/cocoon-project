Epoch [1/15] Training loss: 133.6579	 Validation loss: 11.8410
--------------------------------------------------
Epoch [2/15] Training loss: 3.8263	 Validation loss: 1.3995
--------------------------------------------------
Epoch [3/15] Training loss: 1.6656	 Validation loss: 1.3425
--------------------------------------------------
Epoch [4/15] Training loss: 1.5243	 Validation loss: 1.5212
--------------------------------------------------
Epoch [5/15] Training loss: 1.4453	 Validation loss: 1.3352
--------------------------------------------------
Epoch [6/15] Training loss: 1.2692	 Validation loss: 1.3179
--------------------------------------------------
Epoch [7/15] Training loss: 1.1567	 Validation loss: 1.4607
--------------------------------------------------
Epoch [8/15] Training loss: 1.1447	 Validation loss: 1.3960
--------------------------------------------------
Epoch [9/15] Training loss: 1.1533	 Validation loss: 1.5664
--------------------------------------------------
Epoch [10/15] Training loss: 1.1863	 Validation loss: 1.4953
--------------------------------------------------
Epoch [11/15] Training loss: 1.2639	 Validation loss: 1.5834
--------------------------------------------------
Epoch [12/15] Training loss: 1.3053	 Validation loss: 1.5163
--------------------------------------------------
Epoch [13/15] Training loss: 1.2021	 Validation loss: 1.4318
--------------------------------------------------
Epoch [14/15] Training loss: 1.1584	 Validation loss: 1.2912
--------------------------------------------------
[32m[I 2022-03-26 21:46:56,832][39m Trial 2 finished with value: 1.321844220161438 and parameters: {'learning_rate': 0.06395116222653713, 'num_hidden_units_per_layer': 192, 'weight_decay': 0.07097541045493241, 'kernel_size': 5, 'num_epochs': 15, 'drop_out': 0.28849785897123414, 'batch_size': 50, 'reduced_seq_length': 200}. Best is trial 0 with value: 1.1640262206395466.
Epoch [15/15] Training loss: 1.1850	 Validation loss: 1.3218
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 0.07257192467800369, 'num_hidden_units_per_layer': 128, 'weight_decay': 1.1255113043400407e-05, 'kernel_size': 3, 'num_epochs': 10, 'drop_out': 0.3113786409155155, 'batch_size': 60, 'reduced_seq_length': 160, 'num_levels': 6, 'stride': 1, 'pos_weight': tensor([6.8261])}