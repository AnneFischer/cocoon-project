[32m[I 2022-03-22 13:32:41,087][39m A new study created in memory with name: no-name-cfd51527-3159-4644-8ca4-8ab620972cc4
[33m[W 2022-03-22 13:32:41,094][39m Trial 0 failed because of the following error: NameError("name 'tensor' is not defined")
Traceback (most recent call last):
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/optuna/study/_optimize.py", line 213, in _run_trial
    value_or_values = func(trial)
  File "/var/folders/16/mg5_s98x3yd90kq7mmfmk3pr0000gn/T/ipykernel_88427/1522793752.py", line 33, in objective_tcn_model_samp_en
    'reduced_seq_length': 10, 'num_levels': 1, 'stride': 1, 'pos_weight': tensor([6.8261])}
NameError: name 'tensor' is not defined
Params: {'learning_rate': 7.09359897484749e-05, 'num_hidden_units_per_layer': 128, 'weight_decay': 0.002915999875272908, 'kernel_size': 7, 'num_epochs': 25, 'drop_out': 0.43907869610820505, 'batch_size': 10, 'reduced_seq_length': 10, 'num_levels': 1, 'stride': 1, 'pos_weight': tensor([6.8261])}
[32m[I 2022-03-22 13:33:10,004][39m A new study created in memory with name: no-name-95c41cee-a304-4b3c-9f55-290490028415
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
Epoch [1/25] Training loss: 1.2138	 Validation loss: 1.1657
--------------------------------------------------
Epoch [2/25] Training loss: 1.2176	 Validation loss: 1.1651
--------------------------------------------------
Epoch [3/25] Training loss: 1.2129	 Validation loss: 1.1642
--------------------------------------------------
Epoch [4/25] Training loss: 1.2162	 Validation loss: 1.1640
--------------------------------------------------
Epoch [5/25] Training loss: 1.2172	 Validation loss: 1.1637
--------------------------------------------------
Epoch [6/25] Training loss: 1.2154	 Validation loss: 1.1633
--------------------------------------------------
Epoch [7/25] Training loss: 1.2070	 Validation loss: 1.1636
--------------------------------------------------
Epoch [8/25] Training loss: 1.2033	 Validation loss: 1.1632
--------------------------------------------------
Epoch [9/25] Training loss: 1.2019	 Validation loss: 1.1625
--------------------------------------------------
Epoch [10/25] Training loss: 1.2123	 Validation loss: 1.1624
--------------------------------------------------
Epoch [11/25] Training loss: 1.2130	 Validation loss: 1.1624
--------------------------------------------------
Epoch [12/25] Training loss: 1.2069	 Validation loss: 1.1627
--------------------------------------------------
Epoch [13/25] Training loss: 1.2095	 Validation loss: 1.1634
--------------------------------------------------
Epoch [14/25] Training loss: 1.2078	 Validation loss: 1.1627
--------------------------------------------------
Epoch [15/25] Training loss: 1.2202	 Validation loss: 1.1626
--------------------------------------------------
Epoch [16/25] Training loss: 1.2049	 Validation loss: 1.1628
--------------------------------------------------
Epoch [17/25] Training loss: 1.2023	 Validation loss: 1.1626
--------------------------------------------------
Epoch [18/25] Training loss: 1.2062	 Validation loss: 1.1627
--------------------------------------------------
Epoch [19/25] Training loss: 1.2054	 Validation loss: 1.1622
--------------------------------------------------
Epoch [20/25] Training loss: 1.2001	 Validation loss: 1.1618
--------------------------------------------------
Epoch [21/25] Training loss: 1.2056	 Validation loss: 1.1618
--------------------------------------------------
Epoch [22/25] Training loss: 1.2077	 Validation loss: 1.1619
--------------------------------------------------
Epoch [23/25] Training loss: 1.2109	 Validation loss: 1.1619
--------------------------------------------------
Epoch [24/25] Training loss: 1.2004	 Validation loss: 1.1620
--------------------------------------------------
[32m[I 2022-03-22 13:39:03,480][39m Trial 0 finished with value: 1.1627809007962544 and parameters: {'learning_rate': 0.00960042561027041, 'num_hidden_units_per_layer': 64, 'weight_decay': 0.057341855118879015, 'kernel_size': 7, 'num_epochs': 50, 'drop_out': 0.47725996028364337, 'batch_size': 50, 'reduced_seq_length': 90}. Best is trial 0 with value: 1.1627809007962544.
Epoch [25/25] Training loss: 1.2047	 Validation loss: 1.1628
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 7.09359897484749e-05, 'num_hidden_units_per_layer': 128, 'weight_decay': 0.002915999875272908, 'kernel_size': 7, 'num_epochs': 25, 'drop_out': 0.43907869610820505, 'batch_size': 10, 'reduced_seq_length': 10, 'num_levels': 1, 'stride': 1, 'pos_weight': tensor([6.8261])}
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 1 < 25; dropping {'epoch': 1, 'train_loss': 1.2316241065661113, 'val_loss': 1.1634142498175304}.
Epoch [1/25] Training loss: 1.2316	 Validation loss: 1.1634
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 2 < 25; dropping {'epoch': 2, 'train_loss': 1.2099066807164087, 'val_loss': 1.1631980240345001}.
Epoch [2/25] Training loss: 1.2099	 Validation loss: 1.1632
--------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 3 < 25; dropping {'epoch': 3, 'train_loss': 1.2175686260064442, 'val_loss': 1.1639481286207836}.
Epoch [3/25] Training loss: 1.2176	 Validation loss: 1.1639
--------------------------------------------------
Process wandb_internal:
Traceback (most recent call last):
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/internal/internal.py", line 162, in wandb_internal
    thread.join()
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/threading.py", line 1011, in join
    self._wait_for_tstate_lock()
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/threading.py", line 1027, in _wait_for_tstate_lock
    elif lock.acquire(block, timeout):
KeyboardInterrupt
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/multiprocessing/process.py", line 333, in _bootstrap
    threading._shutdown()
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/threading.py", line 1388, in _shutdown
    lock.acquire()
KeyboardInterrupt
Exception in thread ChkStopThr:
Traceback (most recent call last):
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 167, in check_status
    status_response = self._interface.communicate_stop_status()
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 114, in communicate_stop_status
    resp = self._communicate_stop_status(status)
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 387, in _communicate_stop_status
    resp = self._communicate(req, local=True)
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 222, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 227, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 149, in check_network_status
    status_response = self._interface.communicate_network_status()
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 125, in communicate_network_status
    resp = self._communicate_network_status(status)
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 397, in _communicate_network_status
    resp = self._communicate(req, local=True)
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 222, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 227, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Error in callback <function _WandbInit._resume_backend at 0x7fb23d0793a0> (for pre_run_cell):
Error in callback <function _WandbInit._pause_backend at 0x7fb23d079550> (for post_run_cell):
Traceback (most recent call last):
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/wandb_init.py", line 954, in init
    run = wi.init()
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/wandb_init.py", line 471, in init
    self._wl._global_run_stack[-1].finish()
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 1538, in finish
    tel.feature.finish = True
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/lib/telemetry.py", line 43, in __exit__
    self._run._telemetry_callback(self._obj)
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 470, in _telemetry_callback
    self._telemetry_flush()
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 481, in _telemetry_flush
    self._backend.interface._publish_telemetry(self._telemetry_obj)
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 73, in _publish_telemetry
    self._publish(rec)
  File "/Users/AFischer/opt/anaconda3/envs/ai_medicine/lib/python3.8/site-packages/wandb/sdk/interface/interface_queue.py", line 49, in _publish
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Error in callback <function _WandbInit._resume_backend at 0x7fb23d0793a0> (for pre_run_cell):
Problem at: /var/folders/16/mg5_s98x3yd90kq7mmfmk3pr0000gn/T/ipykernel_88427/2752024895.py 1 <module>
Error in callback <function _WandbInit._pause_backend at 0x7fb23d079550> (for post_run_cell):
[34m[1mwandb[39m[22m: [32m[41mERROR[39m[49m Abnormal program exit