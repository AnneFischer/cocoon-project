Epoch [1/30] Training loss: 1.2032	 Validation loss: 1.1675
--------------------------------------------------
Epoch [2/30] Training loss: 1.2068	 Validation loss: 1.1669
--------------------------------------------------
Epoch [3/30] Training loss: 1.1888	 Validation loss: 1.1669
--------------------------------------------------
Epoch [4/30] Training loss: 1.1859	 Validation loss: 1.1672
--------------------------------------------------
Epoch [5/30] Training loss: 1.1900	 Validation loss: 1.1672
--------------------------------------------------
Epoch [6/30] Training loss: 1.1683	 Validation loss: 1.1678
--------------------------------------------------
Epoch [7/30] Training loss: 1.1797	 Validation loss: 1.1681
--------------------------------------------------
Epoch [8/30] Training loss: 1.1641	 Validation loss: 1.1682
--------------------------------------------------
Epoch [9/30] Training loss: 1.1755	 Validation loss: 1.1685
--------------------------------------------------
Epoch [10/30] Training loss: 1.1710	 Validation loss: 1.1687
--------------------------------------------------
Epoch [11/30] Training loss: 1.1711	 Validation loss: 1.1687
--------------------------------------------------
Epoch [12/30] Training loss: 1.1681	 Validation loss: 1.1689
--------------------------------------------------
Epoch [13/30] Training loss: 1.1641	 Validation loss: 1.1690
--------------------------------------------------
Epoch [14/30] Training loss: 1.1563	 Validation loss: 1.1691
--------------------------------------------------
Epoch [15/30] Training loss: 1.1544	 Validation loss: 1.1689
--------------------------------------------------
Epoch [16/30] Training loss: 1.1583	 Validation loss: 1.1687
--------------------------------------------------
Epoch [17/30] Training loss: 1.1435	 Validation loss: 1.1688
--------------------------------------------------
Epoch [18/30] Training loss: 1.1453	 Validation loss: 1.1692
--------------------------------------------------
Epoch [19/30] Training loss: 1.1444	 Validation loss: 1.1691
--------------------------------------------------
Epoch [20/30] Training loss: 1.1189	 Validation loss: 1.1690
--------------------------------------------------
Epoch [21/30] Training loss: 1.1431	 Validation loss: 1.1689
--------------------------------------------------
Epoch [22/30] Training loss: 1.1322	 Validation loss: 1.1693
--------------------------------------------------
Epoch [23/30] Training loss: 1.1195	 Validation loss: 1.1691
--------------------------------------------------
Epoch [24/30] Training loss: 1.1355	 Validation loss: 1.1690
--------------------------------------------------
Epoch [25/30] Training loss: 1.1209	 Validation loss: 1.1689
--------------------------------------------------
Epoch [26/30] Training loss: 1.1115	 Validation loss: 1.1689
--------------------------------------------------
Epoch [27/30] Training loss: 1.1025	 Validation loss: 1.1688
--------------------------------------------------
[32m[I 2022-03-28 11:22:58,142][39m Trial 16 finished with value: 1.169604738553365 and parameters: {'learning_rate': 2.8941971130869625e-05, 'num_hidden_units_per_layer': 160, 'weight_decay': 3.7022136823905307e-06, 'kernel_size': 7, 'num_epochs': 30, 'drop_out': 0.32632881120580604, 'batch_size': 40, 'reduced_seq_length': 10}. Best is trial 11 with value: 1.1504377126693726.
Epoch [28/30] Training loss: 1.1047	 Validation loss: 1.1687
--------------------------------------------------
Epoch [29/30] Training loss: 1.1049	 Validation loss: 1.1693
--------------------------------------------------
Epoch [30/30] Training loss: 1.1029	 Validation loss: 1.1696
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 0.0001790917192098505, 'num_hidden_units_per_layer': 96, 'weight_decay': 0.00013087796095603244, 'kernel_size': 9, 'num_epochs': 20, 'drop_out': 0.43546375144236593, 'batch_size': 50, 'reduced_seq_length': 60, 'num_levels': 3, 'stride': 1, 'pos_weight': tensor([6.8261])}