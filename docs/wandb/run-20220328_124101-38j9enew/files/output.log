Epoch [1/45] Training loss: 1.2484	 Validation loss: 1.1581
--------------------------------------------------
Epoch [2/45] Training loss: 1.2033	 Validation loss: 1.1565
--------------------------------------------------
Epoch [3/45] Training loss: 1.2089	 Validation loss: 1.1576
--------------------------------------------------
Epoch [4/45] Training loss: 1.2029	 Validation loss: 1.1552
--------------------------------------------------
Epoch [5/45] Training loss: 1.2014	 Validation loss: 1.1498
--------------------------------------------------
Epoch [6/45] Training loss: 1.1940	 Validation loss: 1.1472
--------------------------------------------------
Epoch [7/45] Training loss: 1.1716	 Validation loss: 1.1435
--------------------------------------------------
Epoch [8/45] Training loss: 1.1610	 Validation loss: 1.1412
--------------------------------------------------
Epoch [9/45] Training loss: 1.1592	 Validation loss: 1.1377
--------------------------------------------------
Epoch [10/45] Training loss: 1.1696	 Validation loss: 1.1353
--------------------------------------------------
Epoch [11/45] Training loss: 1.1589	 Validation loss: 1.1329
--------------------------------------------------
Epoch [12/45] Training loss: 1.1555	 Validation loss: 1.1319
--------------------------------------------------
Epoch [13/45] Training loss: 1.1423	 Validation loss: 1.1290
--------------------------------------------------
Epoch [14/45] Training loss: 1.1374	 Validation loss: 1.1263
--------------------------------------------------
Epoch [15/45] Training loss: 1.1243	 Validation loss: 1.1231
--------------------------------------------------
Epoch [16/45] Training loss: 1.1270	 Validation loss: 1.1208
--------------------------------------------------
Epoch [17/45] Training loss: 1.1153	 Validation loss: 1.1167
--------------------------------------------------
Epoch [18/45] Training loss: 1.0997	 Validation loss: 1.1145
--------------------------------------------------
Epoch [19/45] Training loss: 1.0902	 Validation loss: 1.1095
--------------------------------------------------
Epoch [20/45] Training loss: 1.1043	 Validation loss: 1.1056
--------------------------------------------------
Epoch [21/45] Training loss: 1.0681	 Validation loss: 1.1037
--------------------------------------------------
Epoch [22/45] Training loss: 1.0573	 Validation loss: 1.1005
--------------------------------------------------
Epoch [23/45] Training loss: 1.0625	 Validation loss: 1.0986
--------------------------------------------------
Epoch [24/45] Training loss: 1.0441	 Validation loss: 1.0958
--------------------------------------------------
Epoch [25/45] Training loss: 1.0419	 Validation loss: 1.0920
--------------------------------------------------
Epoch [26/45] Training loss: 1.0609	 Validation loss: 1.0902
--------------------------------------------------
Epoch [27/45] Training loss: 1.0296	 Validation loss: 1.0866
--------------------------------------------------
Epoch [28/45] Training loss: 1.0222	 Validation loss: 1.0868
--------------------------------------------------
Epoch [29/45] Training loss: 1.0110	 Validation loss: 1.0841
--------------------------------------------------
Epoch [30/45] Training loss: 0.9974	 Validation loss: 1.0902
--------------------------------------------------
Epoch [31/45] Training loss: 0.9680	 Validation loss: 1.0835
--------------------------------------------------
Epoch [32/45] Training loss: 0.9709	 Validation loss: 1.0776
--------------------------------------------------
Epoch [33/45] Training loss: 0.9222	 Validation loss: 1.0763
--------------------------------------------------
Epoch [34/45] Training loss: 0.8964	 Validation loss: 1.0754
--------------------------------------------------
Epoch [35/45] Training loss: 0.9205	 Validation loss: 1.0764
--------------------------------------------------
Epoch [36/45] Training loss: 0.9223	 Validation loss: 1.0726
--------------------------------------------------
Epoch [37/45] Training loss: 0.9565	 Validation loss: 1.0884
--------------------------------------------------
Epoch [38/45] Training loss: 0.9014	 Validation loss: 1.0757
--------------------------------------------------
Epoch [39/45] Training loss: 0.8521	 Validation loss: 1.0687
--------------------------------------------------
Epoch [40/45] Training loss: 0.8811	 Validation loss: 1.0698
--------------------------------------------------
Epoch [41/45] Training loss: 0.8417	 Validation loss: 1.0758
--------------------------------------------------
Epoch [42/45] Training loss: 0.8321	 Validation loss: 1.0784
--------------------------------------------------
Epoch [43/45] Training loss: 0.7949	 Validation loss: 1.0745
--------------------------------------------------
Epoch [44/45] Training loss: 0.8181	 Validation loss: 1.0737
--------------------------------------------------
Epoch [45/45] Training loss: 0.7494	 Validation loss: 1.0726
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 0.00033417207745977957, 'num_hidden_units_per_layer': 192, 'weight_decay': 6.543862510434693e-06, 'kernel_size': 3, 'num_epochs': 45, 'drop_out': 0.2765109708951375, 'batch_size': 60, 'reduced_seq_length': 140, 'num_levels': 6, 'stride': 1, 'pos_weight': tensor([6.8261])}
[32m[I 2022-03-28 12:46:34,456][39m Trial 39 finished with value: 1.0725955367088318 and parameters: {'learning_rate': 6.396416920856952e-05, 'num_hidden_units_per_layer': 192, 'weight_decay': 1.5023436140749057e-05, 'kernel_size': 3, 'num_epochs': 45, 'drop_out': 0.27088609805223973, 'batch_size': 50, 'reduced_seq_length': 140}. Best is trial 36 with value: 1.060733477274577.