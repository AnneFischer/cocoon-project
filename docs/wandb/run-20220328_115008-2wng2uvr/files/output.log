Epoch [1/30] Training loss: 1.2356	 Validation loss: 1.1735
--------------------------------------------------
Epoch [2/30] Training loss: 1.2425	 Validation loss: 1.1692
--------------------------------------------------
Epoch [3/30] Training loss: 1.2357	 Validation loss: 1.1668
--------------------------------------------------
Epoch [4/30] Training loss: 1.2178	 Validation loss: 1.1654
--------------------------------------------------
Epoch [5/30] Training loss: 1.2148	 Validation loss: 1.1650
--------------------------------------------------
Epoch [6/30] Training loss: 1.2012	 Validation loss: 1.1647
--------------------------------------------------
Epoch [7/30] Training loss: 1.2132	 Validation loss: 1.1649
--------------------------------------------------
Epoch [8/30] Training loss: 1.1943	 Validation loss: 1.1653
--------------------------------------------------
Epoch [9/30] Training loss: 1.1920	 Validation loss: 1.1656
--------------------------------------------------
Epoch [10/30] Training loss: 1.1915	 Validation loss: 1.1662
--------------------------------------------------
Epoch [11/30] Training loss: 1.1925	 Validation loss: 1.1666
--------------------------------------------------
Epoch [12/30] Training loss: 1.1789	 Validation loss: 1.1666
--------------------------------------------------
Epoch [13/30] Training loss: 1.1846	 Validation loss: 1.1665
--------------------------------------------------
Epoch [14/30] Training loss: 1.1860	 Validation loss: 1.1673
--------------------------------------------------
Epoch [15/30] Training loss: 1.1833	 Validation loss: 1.1673
--------------------------------------------------
Epoch [16/30] Training loss: 1.1591	 Validation loss: 1.1670
--------------------------------------------------
Epoch [17/30] Training loss: 1.1660	 Validation loss: 1.1675
--------------------------------------------------
Epoch [18/30] Training loss: 1.1658	 Validation loss: 1.1675
--------------------------------------------------
Epoch [19/30] Training loss: 1.1556	 Validation loss: 1.1678
--------------------------------------------------
Epoch [20/30] Training loss: 1.1446	 Validation loss: 1.1673
--------------------------------------------------
Epoch [21/30] Training loss: 1.1609	 Validation loss: 1.1674
--------------------------------------------------
Epoch [22/30] Training loss: 1.1555	 Validation loss: 1.1668
--------------------------------------------------
Epoch [23/30] Training loss: 1.1532	 Validation loss: 1.1664
--------------------------------------------------
Epoch [24/30] Training loss: 1.1545	 Validation loss: 1.1665
--------------------------------------------------
Epoch [25/30] Training loss: 1.1473	 Validation loss: 1.1655
--------------------------------------------------
Epoch [26/30] Training loss: 1.1415	 Validation loss: 1.1653
--------------------------------------------------
Epoch [27/30] Training loss: 1.1444	 Validation loss: 1.1655
--------------------------------------------------
Epoch [28/30] Training loss: 1.1437	 Validation loss: 1.1653
--------------------------------------------------
Epoch [29/30] Training loss: 1.1458	 Validation loss: 1.1650
--------------------------------------------------
[32m[I 2022-03-28 11:53:37,549][39m Trial 29 finished with value: 1.1649848222732544 and parameters: {'learning_rate': 1.0357013127315308e-05, 'num_hidden_units_per_layer': 192, 'weight_decay': 0.0002723944645439774, 'kernel_size': 7, 'num_epochs': 30, 'drop_out': 0.179201405498305, 'batch_size': 30, 'reduced_seq_length': 70}. Best is trial 27 with value: 1.136247197786967.
Epoch [30/30] Training loss: 1.1351	 Validation loss: 1.1650
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 3.057578873554319e-05, 'num_hidden_units_per_layer': 128, 'weight_decay': 1.680306108234576e-05, 'kernel_size': 5, 'num_epochs': 40, 'drop_out': 0.2569312793099514, 'batch_size': 40, 'reduced_seq_length': 110, 'num_levels': 5, 'stride': 1, 'pos_weight': tensor([6.8261])}