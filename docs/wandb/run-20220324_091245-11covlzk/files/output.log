Epoch [1/25] Training loss: 2.0429	 Validation loss: 1.2836
--------------------------------------------------
Epoch [2/25] Training loss: 1.3100	 Validation loss: 1.2034
--------------------------------------------------
Epoch [3/25] Training loss: 1.1961	 Validation loss: 1.1589
--------------------------------------------------
Epoch [4/25] Training loss: 1.2058	 Validation loss: 1.1597
--------------------------------------------------
Epoch [5/25] Training loss: 1.1908	 Validation loss: 1.1641
--------------------------------------------------
Epoch [6/25] Training loss: 1.1539	 Validation loss: 1.1759
--------------------------------------------------
Epoch [7/25] Training loss: 1.1548	 Validation loss: 1.1654
--------------------------------------------------
Epoch [8/25] Training loss: 1.1269	 Validation loss: 1.1592
--------------------------------------------------
Epoch [9/25] Training loss: 1.0932	 Validation loss: 1.1582
--------------------------------------------------
Epoch [10/25] Training loss: 1.1049	 Validation loss: 1.1580
--------------------------------------------------
Epoch [11/25] Training loss: 1.0565	 Validation loss: 1.1565
--------------------------------------------------
Epoch [12/25] Training loss: 1.0208	 Validation loss: 1.1495
--------------------------------------------------
Epoch [13/25] Training loss: 0.9885	 Validation loss: 1.1852
--------------------------------------------------
Epoch [14/25] Training loss: 0.9530	 Validation loss: 1.1548
--------------------------------------------------
Epoch [15/25] Training loss: 0.9484	 Validation loss: 1.1675
--------------------------------------------------
Epoch [16/25] Training loss: 0.8575	 Validation loss: 1.1591
--------------------------------------------------
Epoch [17/25] Training loss: 0.8613	 Validation loss: 1.1333
--------------------------------------------------
Epoch [18/25] Training loss: 0.7626	 Validation loss: 1.1143
--------------------------------------------------
Epoch [19/25] Training loss: 0.7984	 Validation loss: 1.1665
--------------------------------------------------
Epoch [20/25] Training loss: 0.6418	 Validation loss: 1.2475
--------------------------------------------------
Epoch [21/25] Training loss: 0.6892	 Validation loss: 1.1956
--------------------------------------------------
Epoch [22/25] Training loss: 0.6679	 Validation loss: 1.2336
--------------------------------------------------
Epoch [23/25] Training loss: 0.4843	 Validation loss: 1.6454
--------------------------------------------------
Epoch [24/25] Training loss: 0.5554	 Validation loss: 1.2628
--------------------------------------------------
[32m[I 2022-03-24 09:15:01,581][39m Trial 21 finished with value: 1.2146226167678833 and parameters: {'learning_rate': 0.0026313210142108905, 'num_hidden_units_per_layer': 192, 'weight_decay': 0.00019712343658389347, 'kernel_size': 3, 'num_epochs': 25, 'drop_out': 0.4412688070792891, 'batch_size': 60, 'reduced_seq_length': 90}. Best is trial 3 with value: 0.9335269729296366.
Epoch [25/25] Training loss: 0.5650	 Validation loss: 1.2146
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 0.009020030599366619, 'num_hidden_units_per_layer': 160, 'weight_decay': 4.1078040444468215e-06, 'kernel_size': 3, 'num_epochs': 25, 'drop_out': 0.44068493308494927, 'batch_size': 50, 'reduced_seq_length': 120, 'num_levels': 6, 'stride': 1, 'pos_weight': tensor([6.8261])}
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0