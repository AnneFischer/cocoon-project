Epoch [1/35] Training loss: 1.1983	 Validation loss: 1.1732
--------------------------------------------------
Epoch [2/35] Training loss: 1.2043	 Validation loss: 1.1726
--------------------------------------------------
Epoch [3/35] Training loss: 1.1816	 Validation loss: 1.1723
--------------------------------------------------
Epoch [4/35] Training loss: 1.1816	 Validation loss: 1.1723
--------------------------------------------------
Epoch [5/35] Training loss: 1.2004	 Validation loss: 1.1726
--------------------------------------------------
Epoch [6/35] Training loss: 1.1874	 Validation loss: 1.1724
--------------------------------------------------
Epoch [7/35] Training loss: 1.1768	 Validation loss: 1.1726
--------------------------------------------------
Epoch [8/35] Training loss: 1.1828	 Validation loss: 1.1729
--------------------------------------------------
Epoch [9/35] Training loss: 1.1754	 Validation loss: 1.1732
--------------------------------------------------
Epoch [10/35] Training loss: 1.1859	 Validation loss: 1.1733
--------------------------------------------------
Epoch [11/35] Training loss: 1.1880	 Validation loss: 1.1732
--------------------------------------------------
Epoch [12/35] Training loss: 1.1698	 Validation loss: 1.1739
--------------------------------------------------
Epoch [13/35] Training loss: 1.1603	 Validation loss: 1.1746
--------------------------------------------------
Epoch [14/35] Training loss: 1.1714	 Validation loss: 1.1749
--------------------------------------------------
Epoch [15/35] Training loss: 1.1543	 Validation loss: 1.1756
--------------------------------------------------
Epoch [16/35] Training loss: 1.1572	 Validation loss: 1.1759
--------------------------------------------------
Epoch [17/35] Training loss: 1.1420	 Validation loss: 1.1765
--------------------------------------------------
Epoch [18/35] Training loss: 1.1545	 Validation loss: 1.1772
--------------------------------------------------
Epoch [19/35] Training loss: 1.1744	 Validation loss: 1.1776
--------------------------------------------------
Epoch [20/35] Training loss: 1.1682	 Validation loss: 1.1786
--------------------------------------------------
Epoch [21/35] Training loss: 1.1443	 Validation loss: 1.1790
--------------------------------------------------
Epoch [22/35] Training loss: 1.1518	 Validation loss: 1.1793
--------------------------------------------------
Epoch [23/35] Training loss: 1.1425	 Validation loss: 1.1798
--------------------------------------------------
Epoch [24/35] Training loss: 1.1535	 Validation loss: 1.1806
--------------------------------------------------
Epoch [25/35] Training loss: 1.1392	 Validation loss: 1.1814
--------------------------------------------------
[32m[I 2022-03-25 13:48:07,783][39m Trial 14 finished with value: 1.1910597880681355 and parameters: {'learning_rate': 5.4157184343831415e-05, 'num_hidden_units_per_layer': 96, 'weight_decay': 0.07244891289438471, 'kernel_size': 5, 'num_epochs': 35, 'drop_out': 0.37482814513739715, 'batch_size': 20, 'reduced_seq_length': 10}. Best is trial 5 with value: 1.1609607934951782.
Epoch [26/35] Training loss: 1.1190	 Validation loss: 1.1820
--------------------------------------------------
Epoch [27/35] Training loss: 1.1250	 Validation loss: 1.1832
--------------------------------------------------
Epoch [28/35] Training loss: 1.1106	 Validation loss: 1.1840
--------------------------------------------------
Epoch [29/35] Training loss: 1.1060	 Validation loss: 1.1847
--------------------------------------------------
Epoch [30/35] Training loss: 1.1075	 Validation loss: 1.1855
--------------------------------------------------
Epoch [31/35] Training loss: 1.1063	 Validation loss: 1.1869
--------------------------------------------------
Epoch [32/35] Training loss: 1.0981	 Validation loss: 1.1874
--------------------------------------------------
Epoch [33/35] Training loss: 1.1257	 Validation loss: 1.1881
--------------------------------------------------
Epoch [34/35] Training loss: 1.0966	 Validation loss: 1.1897
--------------------------------------------------
Epoch [35/35] Training loss: 1.0790	 Validation loss: 1.1911
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 3.0082699717112154e-05, 'num_hidden_units_per_layer': 128, 'weight_decay': 0.01089630746296324, 'kernel_size': 5, 'num_epochs': 30, 'drop_out': 0.4048316348526041, 'batch_size': 20, 'reduced_seq_length': 40, 'num_levels': 3, 'stride': 1, 'pos_weight': tensor([6.8261])}