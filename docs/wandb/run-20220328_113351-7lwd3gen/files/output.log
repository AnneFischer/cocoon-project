Epoch [1/25] Training loss: 1.2076	 Validation loss: 1.1900
--------------------------------------------------
Epoch [2/25] Training loss: 1.2341	 Validation loss: 1.1841
--------------------------------------------------
Epoch [3/25] Training loss: 1.2161	 Validation loss: 1.1800
--------------------------------------------------
Epoch [4/25] Training loss: 1.2455	 Validation loss: 1.1764
--------------------------------------------------
Epoch [5/25] Training loss: 1.2290	 Validation loss: 1.1735
--------------------------------------------------
Epoch [6/25] Training loss: 1.2092	 Validation loss: 1.1706
--------------------------------------------------
Epoch [7/25] Training loss: 1.2109	 Validation loss: 1.1682
--------------------------------------------------
Epoch [8/25] Training loss: 1.1933	 Validation loss: 1.1662
--------------------------------------------------
Epoch [9/25] Training loss: 1.2400	 Validation loss: 1.1650
--------------------------------------------------
Epoch [10/25] Training loss: 1.2000	 Validation loss: 1.1640
--------------------------------------------------
Epoch [11/25] Training loss: 1.1878	 Validation loss: 1.1629
--------------------------------------------------
Epoch [12/25] Training loss: 1.1716	 Validation loss: 1.1622
--------------------------------------------------
Epoch [13/25] Training loss: 1.2054	 Validation loss: 1.1616
--------------------------------------------------
Epoch [14/25] Training loss: 1.1813	 Validation loss: 1.1613
--------------------------------------------------
Epoch [15/25] Training loss: 1.2246	 Validation loss: 1.1611
--------------------------------------------------
Epoch [16/25] Training loss: 1.2014	 Validation loss: 1.1611
--------------------------------------------------
Epoch [17/25] Training loss: 1.2092	 Validation loss: 1.1608
--------------------------------------------------
Epoch [18/25] Training loss: 1.1890	 Validation loss: 1.1607
--------------------------------------------------
Epoch [19/25] Training loss: 1.2114	 Validation loss: 1.1605
--------------------------------------------------
Epoch [20/25] Training loss: 1.1650	 Validation loss: 1.1603
--------------------------------------------------
Epoch [21/25] Training loss: 1.1799	 Validation loss: 1.1601
--------------------------------------------------
Epoch [22/25] Training loss: 1.1843	 Validation loss: 1.1601
--------------------------------------------------
Epoch [23/25] Training loss: 1.2207	 Validation loss: 1.1603
--------------------------------------------------
[32m[I 2022-03-28 11:34:30,507][39m Trial 22 finished with value: 1.160391092300415 and parameters: {'learning_rate': 7.611748593322204e-05, 'num_hidden_units_per_layer': 32, 'weight_decay': 0.0038901922378658305, 'kernel_size': 9, 'num_epochs': 25, 'drop_out': 0.36121305213062305, 'batch_size': 60, 'reduced_seq_length': 180}. Best is trial 11 with value: 1.1504377126693726.
Epoch [24/25] Training loss: 1.1936	 Validation loss: 1.1603
--------------------------------------------------
Epoch [25/25] Training loss: 1.1975	 Validation loss: 1.1604
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 1.906848156250737e-05, 'num_hidden_units_per_layer': 32, 'weight_decay': 0.002308000858057065, 'kernel_size': 7, 'num_epochs': 30, 'drop_out': 0.3564302337084053, 'batch_size': 50, 'reduced_seq_length': 130, 'num_levels': 5, 'stride': 1, 'pos_weight': tensor([6.8261])}