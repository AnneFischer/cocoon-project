Epoch [1/15] Training loss: 1.2213	 Validation loss: 1.1593
--------------------------------------------------
Epoch [2/15] Training loss: 1.1776	 Validation loss: 1.2178
--------------------------------------------------
Epoch [3/15] Training loss: 1.1799	 Validation loss: 1.1907
--------------------------------------------------
Epoch [4/15] Training loss: 1.1170	 Validation loss: 1.1535
--------------------------------------------------
Epoch [5/15] Training loss: 0.9499	 Validation loss: 1.1560
--------------------------------------------------
Epoch [6/15] Training loss: 0.9183	 Validation loss: 1.1541
--------------------------------------------------
Epoch [7/15] Training loss: 0.8511	 Validation loss: 1.1649
--------------------------------------------------
Epoch [8/15] Training loss: 0.8587	 Validation loss: 1.1816
--------------------------------------------------
Epoch [9/15] Training loss: 0.7774	 Validation loss: 1.1823
--------------------------------------------------
Epoch [10/15] Training loss: 0.6563	 Validation loss: 1.2833
--------------------------------------------------
Epoch [11/15] Training loss: 0.6521	 Validation loss: 1.2147
--------------------------------------------------
Epoch [12/15] Training loss: 0.5254	 Validation loss: 1.3581
--------------------------------------------------
Epoch [13/15] Training loss: 0.5368	 Validation loss: 1.3627
--------------------------------------------------
Epoch [14/15] Training loss: 0.4435	 Validation loss: 1.2757
--------------------------------------------------
[32m[I 2022-03-28 11:41:59,153][39m Trial 26 finished with value: 1.4244986772537231 and parameters: {'learning_rate': 0.00045980036503278407, 'num_hidden_units_per_layer': 128, 'weight_decay': 8.953385377559665e-06, 'kernel_size': 9, 'num_epochs': 15, 'drop_out': 0.3212432191492292, 'batch_size': 30, 'reduced_seq_length': 200}. Best is trial 11 with value: 1.1504377126693726.
Epoch [15/15] Training loss: 0.4295	 Validation loss: 1.4245
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 2.6666578713586677e-05, 'num_hidden_units_per_layer': 160, 'weight_decay': 2.137581204785164e-06, 'kernel_size': 9, 'num_epochs': 20, 'drop_out': 0.2557684332976077, 'batch_size': 20, 'reduced_seq_length': 140, 'num_levels': 4, 'stride': 1, 'pos_weight': tensor([6.8261])}