Epoch [1/15] Training loss: 1.2138	 Validation loss: 1.1804
--------------------------------------------------
Epoch [2/15] Training loss: 1.2015	 Validation loss: 1.1799
--------------------------------------------------
Epoch [3/15] Training loss: 1.1897	 Validation loss: 1.1787
--------------------------------------------------
Epoch [4/15] Training loss: 1.2013	 Validation loss: 1.1779
--------------------------------------------------
Epoch [5/15] Training loss: 1.2004	 Validation loss: 1.1766
--------------------------------------------------
Epoch [6/15] Training loss: 1.1877	 Validation loss: 1.1756
--------------------------------------------------
Epoch [7/15] Training loss: 1.2020	 Validation loss: 1.1754
--------------------------------------------------
Epoch [8/15] Training loss: 1.1786	 Validation loss: 1.1751
--------------------------------------------------
Epoch [9/15] Training loss: 1.1847	 Validation loss: 1.1743
--------------------------------------------------
Epoch [10/15] Training loss: 1.1822	 Validation loss: 1.1737
--------------------------------------------------
Epoch [11/15] Training loss: 1.1872	 Validation loss: 1.1735
--------------------------------------------------
Epoch [12/15] Training loss: 1.2000	 Validation loss: 1.1733
--------------------------------------------------
Epoch [13/15] Training loss: 1.1791	 Validation loss: 1.1729
--------------------------------------------------
Epoch [14/15] Training loss: 1.1797	 Validation loss: 1.1727
--------------------------------------------------
[32m[I 2022-03-28 11:38:15,105][39m Trial 25 finished with value: 1.172709862391154 and parameters: {'learning_rate': 1.1992378575307765e-05, 'num_hidden_units_per_layer': 96, 'weight_decay': 2.6616847642989824e-06, 'kernel_size': 7, 'num_epochs': 15, 'drop_out': 0.28563910904765955, 'batch_size': 20, 'reduced_seq_length': 160}. Best is trial 11 with value: 1.1504377126693726.
Epoch [15/15] Training loss: 1.1782	 Validation loss: 1.1727
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 0.00045980036503278407, 'num_hidden_units_per_layer': 128, 'weight_decay': 8.953385377559665e-06, 'kernel_size': 9, 'num_epochs': 15, 'drop_out': 0.3212432191492292, 'batch_size': 30, 'reduced_seq_length': 200, 'num_levels': 5, 'stride': 1, 'pos_weight': tensor([6.8261])}