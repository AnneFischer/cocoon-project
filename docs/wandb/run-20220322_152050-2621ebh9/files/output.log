Epoch [1/40] Training loss: 5.0610	 Validation loss: 1.7142
--------------------------------------------------
Epoch [2/40] Training loss: 1.7451	 Validation loss: 1.1965
--------------------------------------------------
Epoch [3/40] Training loss: 1.2215	 Validation loss: 1.1846
--------------------------------------------------
Epoch [4/40] Training loss: 1.2712	 Validation loss: 1.1624
--------------------------------------------------
Epoch [5/40] Training loss: 1.2285	 Validation loss: 1.1725
--------------------------------------------------
Epoch [6/40] Training loss: 1.2455	 Validation loss: 1.1748
--------------------------------------------------
Epoch [7/40] Training loss: 1.2352	 Validation loss: 1.1768
--------------------------------------------------
Epoch [8/40] Training loss: 1.2097	 Validation loss: 1.1646
--------------------------------------------------
Epoch [9/40] Training loss: 1.2378	 Validation loss: 1.1633
--------------------------------------------------
Epoch [10/40] Training loss: 1.2514	 Validation loss: 1.1632
--------------------------------------------------
Epoch [11/40] Training loss: 1.2000	 Validation loss: 1.1622
--------------------------------------------------
Epoch [12/40] Training loss: 1.2312	 Validation loss: 1.1623
--------------------------------------------------
Epoch [13/40] Training loss: 1.2180	 Validation loss: 1.1641
--------------------------------------------------
Epoch [14/40] Training loss: 1.2269	 Validation loss: 1.1634
--------------------------------------------------
Epoch [15/40] Training loss: 1.2199	 Validation loss: 1.1641
--------------------------------------------------
Epoch [16/40] Training loss: 1.2138	 Validation loss: 1.1651
--------------------------------------------------
Epoch [17/40] Training loss: 1.2141	 Validation loss: 1.1643
--------------------------------------------------
Epoch [18/40] Training loss: 1.2148	 Validation loss: 1.1637
--------------------------------------------------
Epoch [19/40] Training loss: 1.2139	 Validation loss: 1.1636
--------------------------------------------------
Epoch [20/40] Training loss: 1.2109	 Validation loss: 1.1634
--------------------------------------------------
Epoch [21/40] Training loss: 1.2133	 Validation loss: 1.1626
--------------------------------------------------
Epoch [22/40] Training loss: 1.2138	 Validation loss: 1.1634
--------------------------------------------------
Epoch [23/40] Training loss: 1.2145	 Validation loss: 1.1645
--------------------------------------------------
Epoch [24/40] Training loss: 1.2090	 Validation loss: 1.1648
--------------------------------------------------
Epoch [25/40] Training loss: 1.2121	 Validation loss: 1.1633
--------------------------------------------------
Epoch [26/40] Training loss: 1.2072	 Validation loss: 1.1643
--------------------------------------------------
Epoch [27/40] Training loss: 1.2093	 Validation loss: 1.1650
--------------------------------------------------
Epoch [28/40] Training loss: 1.2117	 Validation loss: 1.1669
--------------------------------------------------
Epoch [29/40] Training loss: 1.2078	 Validation loss: 1.1659
--------------------------------------------------
Epoch [30/40] Training loss: 1.2068	 Validation loss: 1.1644
--------------------------------------------------
Epoch [31/40] Training loss: 1.2122	 Validation loss: 1.1642
--------------------------------------------------
Epoch [32/40] Training loss: 1.2101	 Validation loss: 1.1635
--------------------------------------------------
Epoch [33/40] Training loss: 1.2109	 Validation loss: 1.1635
--------------------------------------------------
Epoch [34/40] Training loss: 1.2084	 Validation loss: 1.1638
--------------------------------------------------
Epoch [35/40] Training loss: 1.2092	 Validation loss: 1.1642
--------------------------------------------------
Epoch [36/40] Training loss: 1.2084	 Validation loss: 1.1639
--------------------------------------------------
Epoch [37/40] Training loss: 1.2104	 Validation loss: 1.1640
--------------------------------------------------
Epoch [38/40] Training loss: 1.2087	 Validation loss: 1.1639
--------------------------------------------------
Epoch [39/40] Training loss: 1.2082	 Validation loss: 1.1638
--------------------------------------------------
Epoch [40/40] Training loss: 1.2103	 Validation loss: 1.1638
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 0.003395980168759841, 'num_hidden_units_per_layer': 192, 'weight_decay': 0.006456888830984475, 'kernel_size': 7, 'num_epochs': 20, 'drop_out': 0.35357937436559733, 'batch_size': 30, 'reduced_seq_length': 150, 'num_levels': 5, 'stride': 1, 'pos_weight': tensor([6.8261])}
[32m[I 2022-03-22 15:24:47,091][39m Trial 11 finished with value: 1.1637810866038005 and parameters: {'learning_rate': 0.0066600779315279315, 'num_hidden_units_per_layer': 96, 'weight_decay': 0.08171255567566992, 'kernel_size': 7, 'num_epochs': 40, 'drop_out': 0.4928461629976556, 'batch_size': 40, 'reduced_seq_length': 200}. Best is trial 0 with value: 1.1620822846889496.
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0