Epoch [1/45] Training loss: 1.3339	 Validation loss: 1.1639
--------------------------------------------------
Epoch [2/45] Training loss: 1.2704	 Validation loss: 1.1608
--------------------------------------------------
Epoch [3/45] Training loss: 1.3483	 Validation loss: 1.1577
--------------------------------------------------
Epoch [4/45] Training loss: 1.2833	 Validation loss: 1.1553
--------------------------------------------------
Epoch [5/45] Training loss: 1.2993	 Validation loss: 1.1533
--------------------------------------------------
Epoch [6/45] Training loss: 1.2652	 Validation loss: 1.1520
--------------------------------------------------
Epoch [7/45] Training loss: 1.2031	 Validation loss: 1.1509
--------------------------------------------------
Epoch [8/45] Training loss: 1.2773	 Validation loss: 1.1502
--------------------------------------------------
Epoch [9/45] Training loss: 1.2488	 Validation loss: 1.1498
--------------------------------------------------
Epoch [10/45] Training loss: 1.2212	 Validation loss: 1.1496
--------------------------------------------------
Epoch [11/45] Training loss: 1.2559	 Validation loss: 1.1496
--------------------------------------------------
Epoch [12/45] Training loss: 1.2724	 Validation loss: 1.1497
--------------------------------------------------
Epoch [13/45] Training loss: 1.2862	 Validation loss: 1.1500
--------------------------------------------------
Epoch [14/45] Training loss: 1.2248	 Validation loss: 1.1504
--------------------------------------------------
Epoch [15/45] Training loss: 1.2373	 Validation loss: 1.1509
--------------------------------------------------
Epoch [16/45] Training loss: 1.2271	 Validation loss: 1.1513
--------------------------------------------------
Epoch [17/45] Training loss: 1.2344	 Validation loss: 1.1517
--------------------------------------------------
Epoch [18/45] Training loss: 1.2268	 Validation loss: 1.1521
--------------------------------------------------
Epoch [19/45] Training loss: 1.2395	 Validation loss: 1.1525
--------------------------------------------------
Epoch [20/45] Training loss: 1.2479	 Validation loss: 1.1530
--------------------------------------------------
Epoch [21/45] Training loss: 1.2667	 Validation loss: 1.1534
--------------------------------------------------
Epoch [22/45] Training loss: 1.1959	 Validation loss: 1.1538
--------------------------------------------------
Epoch [23/45] Training loss: 1.2234	 Validation loss: 1.1542
--------------------------------------------------
Epoch [24/45] Training loss: 1.2361	 Validation loss: 1.1543
--------------------------------------------------
Epoch [25/45] Training loss: 1.2116	 Validation loss: 1.1545
--------------------------------------------------
Epoch [26/45] Training loss: 1.2036	 Validation loss: 1.1546
--------------------------------------------------
Epoch [27/45] Training loss: 1.2600	 Validation loss: 1.1549
--------------------------------------------------
Epoch [28/45] Training loss: 1.1857	 Validation loss: 1.1553
--------------------------------------------------
Epoch [29/45] Training loss: 1.1958	 Validation loss: 1.1558
--------------------------------------------------
Epoch [30/45] Training loss: 1.2156	 Validation loss: 1.1560
--------------------------------------------------
Epoch [31/45] Training loss: 1.2448	 Validation loss: 1.1563
--------------------------------------------------
Epoch [32/45] Training loss: 1.2225	 Validation loss: 1.1566
--------------------------------------------------
Epoch [33/45] Training loss: 1.2589	 Validation loss: 1.1570
--------------------------------------------------
Epoch [34/45] Training loss: 1.1965	 Validation loss: 1.1575
--------------------------------------------------
Epoch [35/45] Training loss: 1.2728	 Validation loss: 1.1578
--------------------------------------------------
Epoch [36/45] Training loss: 1.2313	 Validation loss: 1.1582
--------------------------------------------------
Epoch [37/45] Training loss: 1.2287	 Validation loss: 1.1584
--------------------------------------------------
Epoch [38/45] Training loss: 1.2145	 Validation loss: 1.1582
--------------------------------------------------
Epoch [39/45] Training loss: 1.2411	 Validation loss: 1.1584
--------------------------------------------------
Epoch [40/45] Training loss: 1.2102	 Validation loss: 1.1586
--------------------------------------------------
Epoch [41/45] Training loss: 1.2282	 Validation loss: 1.1588
--------------------------------------------------
Epoch [42/45] Training loss: 1.2371	 Validation loss: 1.1590
--------------------------------------------------
Epoch [43/45] Training loss: 1.2182	 Validation loss: 1.1594
--------------------------------------------------
Epoch [44/45] Training loss: 1.2336	 Validation loss: 1.1597
--------------------------------------------------
[32m[I 2022-03-23 16:09:34,108][39m Trial 3 finished with value: 1.1599018573760986 and parameters: {'learning_rate': 3.8324757420279234e-05, 'num_hidden_units_per_layer': 64, 'weight_decay': 0.0757218005925166, 'kernel_size': 5, 'num_epochs': 45, 'drop_out': 0.4925924626071001, 'batch_size': 60, 'reduced_seq_length': 180}. Best is trial 1 with value: 1.143883506457011.
Epoch [45/45] Training loss: 1.2344	 Validation loss: 1.1599
--------------------------------------------------
TRAINING COMPLETE
Params: {'learning_rate': 0.0020715847633208453, 'num_hidden_units_per_layer': 256, 'weight_decay': 5.451868403511208e-06, 'kernel_size': 5, 'num_epochs': 30, 'drop_out': 0.4087620069452623, 'batch_size': 10, 'reduced_seq_length': 120, 'num_levels': 5, 'stride': 1, 'pos_weight': tensor([6.8261])}
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0
The number of rows with infinite numbers that will be replaced with zero is: 0
The number of rows with NA numbers that will be replaced with zero is: 0